---
title: "Эксплуатация без K8s"
date: 2022-06-14
description: "Практический опыт эксплуатации production-инфраструктуры без Kubernetes: как мы отказались от K8s и построили простую, надёжную и эффективную систему на базе systemd и пакетных менеджеров."
tags: ["kubernetes", "devops", "инфраструктура", "systemd", "ansible", "эксплуатация", "kinescope"]
---

В этом докладе я рассказываю о нашем опыте эксплуатации production-инфраструктуры без Kubernetes в Kinescope. Мы отказались от K8s около трёх лет назад и построили простую, надёжную и эффективную систему на базе стандартных инструментов Linux: systemd, пакетных менеджеров и Ansible.

Доклад охватывает причины отказа от Kubernetes, требования к системе, выбор решений и практический опыт эксплуатации более 50 серверов в 4 дата-центрах силами одного администратора.

{{< youtube id="e50e5CjsKlU" title="Эксплуатация без K8s / Кирилл Шваков, Kinescope" >}}

## TL;DR

Основные выводы из нашего опыта эксплуатации без Kubernetes:

- **Простота важнее сложности** — стандартные инструменты Linux (systemd, пакетные менеджеры) решают большинство задач без дополнительных слоёв абстракции
- **Один бинарник — один сервис** — все сервисы собираются в один бинарный файл, что упрощает доставку и эксплуатацию
- **Автоматизация через Ansible** — вся инфраструктура описывается кодом, разработчики не зависят от админов
- **Масштабирование через группы серверов** — простое горизонтальное масштабирование без оркестраторов
- **Отказоустойчивость через DNS и BGP** — маршрутизация трафика на уровне сети, а не приложений
- **Меньше компонентов — меньше проблем** — за три года ничего не упало по вине systemd или пакетных менеджеров

## Контекст: что было и что стало

Сейчас у нас нет Kubernetes и Docker в продакшене. Раньше они были, но мы не занимались их выпиливанием специально — просто так получилось. Сейчас у нас один админ, один DevOps-инженер, мы находимся в 4 дата-центрах (два в России, один в Европе, один в США, и в Азии тоже хотим), и чуть больше 50 серверов.

Когда-то давно у нас был Kubernetes, и мы без него живём уже около трёх лет (может быть чуть меньше). Он стоял, что-то делал, ел ресурсы, иногда ломался, и мы не понимали, что там сломалось. Вроде всё работало, но починить это было зачастую какой-то магией — админ занимался этим. У нас было тогда даже два админа.

Мне очень **не** нравилось то, что происходило, потому что не было никакого контроля. Всё усложнялось тем, что было два дата-центра — соответственно, несколько кластеров Kubernetes, и вот это всё.

Мы не хотели ни от чего отказываться, но хотели больше стабильности в системе.

## Что мы хотели от системы

Прежде чем решать проблемы с Kubernetes как таковым, мы хотели задаться вопросом: а что мы на самом деле хотим от наших систем?

### Требования эксплуатации

Инженер, который занимается эксплуатацией, — это не разработчик. Он не знает, что там находится в сервисе, и в принципе ему и не нужно знать, что сервис делает и как он живёт. У нас около 40 сервисов, может больше.

Эксплуатация хотела, чтобы сервис:

- Представлял какие-то порты наружу (если он работает по HTTP — это не так важно)
- Обязательно имел порт для метрик
- Хранил параметры через переменные окружения (все конфиги должны быть через переменные окружения, чтобы не было конфигурационных файлов по возможности)
- Не сильно отличался от других сервисов (зачем тебе платить кучу разных сервисов, чтобы они ещё по-разному настраивались и по-разному эксплуатировались — это будет сложно, дорого и неэффективно)

### Требования разработки

Разработка, естественно, хотела:

- Не зависеть от эксплуатации — не находиться в состоянии заложников
- Не просить добавить какой-то сервис или выкатить куда-то
- Не выпрашивать логи, мониторинг и всё остальное — обычные бытовые проблемы, которые у некоторых остаются проблемами

### Общие требования

Что мы хотели от системы в целом:

- **Автоматизация** — не то чтобы её не было, она была, но тем не менее хотелось больше
- **Масштабирование** — система должна масштабироваться
- **Отказоустойчивость** — система должна быть отказоустойчивой
- **Единый формат пакетов и доставки** — это важная часть: мы деплоим каждый день, бывает по 10–20 релизов
- **Персистентность сервиса** — мы хотим собрать сервис ровно в таком же состоянии, протестировать и потом выкатить на продакшн
- **Изоляция ресурсов** — на одной машине может быть более чем один сервис
- **Безопасность** — это важно
- **Производительность** — у нас были проблемы с производительностью Kubernetes, он ломался, это выходило дорого по железу

## Решение: один бинарник — один сервис

Мы пошли немного другим путём: мы стали не пытаться сделать платформу для сервисов, которая могла бы всё что угодно, а решили дотащить сами сервисы до нужного состояния.

### Требования к сервисам

Один сервис должен быть одним бинарником со стандартными метриками и всем остальным. У нас были сервисы, написанные на Ruby — «один сервис — один бинарник» им, соответственно, не подходил. Сервисы, которые оставались на Ruby, мы тоже переписали на Go[^go-choice], чтобы можно было их собирать.

Сейчас мы собираем не только сервисы, которые просто сервисы. У нас, например, есть плеер (это JS-файлики), у нас есть сайт, у нас есть админка — всё это мы тоже пакуем в один бинарник вместе со статикой. То есть у нас все сервисы одинаковые с точки зрения эксплуатации — неважно, что это: player, API или DNS-сервер. Это всё одинаково с точки зрения эксплуатации, никакой разницы нет, и с точки зрения доставки тоже.

### Единый формат метрик

Метрики, понятно, не могут быть «какие попало», но всегда должна быть как минимум одна, которая описывает приложение: версия, время сборки и название. Так мы его всегда видим.

В итоге мы пришли к тому, что все сервисы одинаковые — они никак не отличаются с точки зрения эксплуатации. На выходе у нас получился один бинарник, и жизнь стала с этим легче.

## Почему не Docker?

Плюсы не только в том, что бинарник можно запустить руками — ничего не произойдёт. Нужно доставить и запустить сервис. Для этого многие говорят, что нужен Docker: потому что Docker удобен, Docker «пакует», у Docker есть изоляция ресурсов и прочие штуки.

Но помимо всего прочего у Docker есть накладные расходы. Плюс усложняется сеть и диагностика. Нам нужно проверенное и надёжное решение, а Docker в нашем кейсе таким не показался: не то чтобы были какие-то конкретные «боли», скорее он слишком большой и не нужен, и даёт лишние потери производительности.

## Решение: пакетный менеджер и systemd

Чтобы что-то доставить надёжно и запустить, казалось, что всё есть в операционной системе. Мы работаем на Linux, у нас везде Ubuntu, и собственно как в любой операционной системе есть пакетный менеджер (у нас это самый распространённый пакетный менеджер, который существует уже достаточно давно) и systemd, который в принципе запускает любое приложение, которое есть в системе.

Эти штуки старые, надёжные и проверенные. Никаких дополнительных систем ставить не нужно — мы не тащим лишние сущности, у нас меньше частей, которые могут выйти из строя. Это прям профит.

При этом пакетный менеджер — это необязательно apt: может быть yum, может быть любой, в зависимости от вашей операционной системы. Если у нас Ubuntu, то apt. В целом разницы нет.

### Сборка пакетов: NFPM

Единственное, что для сборки мы используем [NFPM (Not FPM)](https://github.com/goreleaser/nfpm). Нам лень каждый раз писать файлик или править его руками для сборки пакетов, поэтому есть прекрасная штука NFPM от GoReleaser. Это простой инструмент для создания пакетов (deb, rpm, apk, ipk, arch linux), написанный на Go, без зависимостей. Он позволяет в YAML описать, что вы хотите видеть в пакете, и собирать под нужную операционку — а запускать уже через systemd.

## Преимущества systemd

### Видимость в системе

Во-первых, сервис виден системе, и мы это легко мониторим. Мы на машину закидываем экспортеры, и даже если разработчик вдруг не добавил мониторинг (например, не добавлен endpoint или мы его не добавили в Prometheus), мы всё равно увидим сервис, потому что он отдаёт стандартные метрики. Мы подхватываемся по названию — все сервисы видны в системе; упал или не упал — тоже видно.

### Изоляция ресурсов

Если кто-то говорит, что Docker нужен для изоляции ресурсов, это не совсем так. В systemd точно так же прописываются ограничения — там CPU, память и всё, что вы хотите. То есть там достаточно гибко сделано.

### Безопасность

Безопасность, естественно, есть: если сервис, например, не работает с какими-то устройствами, то он не сможет до них достучаться. Вы это всё прописываете там же, и это всё видно.

### Задачи по расписанию

Мы используем systemd для задач по расписанию. Если кто-то помнит cron — та же идея. У нас есть несколько задач, которые мы запускаем редко, поэтому нет смысла держать сервис запущенным всё оставшееся время. Через systemd мы просто ставим таймер/задачу — он запускает, отрабатывает и завершает.

### Производительность и надёжность

Если у нас ничего лишнего нет, то ломаться нечему, и ресурсы тратить некому. systemd работает стабильно. Да, я слышал жалобы на systemd, что он якобы потребляет много ресурсов, но в нашей практике его накладные расходы практически незаметны. Это надёжно: если systemd не работает — у нас ничего не работает, так что это базовая система, за которой следят все.

## Автоматизация через Ansible

Обычно все рассказывают про то, что что-то внедряют. Мы рассказываем про то, что мы, наоборот, «выпилили» и получили результат почти ничего не делая — даже никакого дополнительного софта не поставили. У нас получился единый формат пакетов, с доставкой всё ок, есть версионирование, изоляция — то есть почти серебряная пуля.

Однако у нас ещё были закрыты вопросы по автоматизации.

### Автоматизировать нужно всё

Обычно сейчас расскажу, наверно, такой капитан очевидность: автоматизировать нужно всё, даже если у вас есть один сервер. Это можно всё автоматизировать, потому что если он сгорит, потом вы руками ещё не сделаете — вы не восстановите то, что там было, окружение какое, там неважно почему, чем занимается.

### Почему Ansible?

Для автоматизации, естественно, мы выбрали Ansible. Он у нас уже был, поэтому выбор выглядел логичным. «Почему Ansible?» — а что ещё выбирать? Puppet мы использовали очень давно, много лет. Его можно расширять плагинами и в целом поддерживать, но про «легко поддерживать» я бы поставил звёздочку: на практике это не всегда так.

Если вы пользуетесь Ansible, у вас неизбежно появляется «мусор» и технический долг. Поэтому раз в какое-то время мы возвращаемся и чистим: переписываем playbook'и, удаляем ненужные роли/сервисы и всё, что накопилось.

### Как работает Ansible у нас

У нас всё очень просто. У нас есть две команды по большому счёту — разработчики и инженеры, которые поддерживают систему (админы, проще говоря).

Эксплуатация занимается базой: когда появляется сервер и к нему подведена сеть, на него накатывается базовая роль. Дальше сервер добавляется в inventory, отключается root-доступ, настраиваются доступы, и ставится мониторинг/логирование: например, node exporter и агент для сбора логов. Мы собираем все **логи** в системе — не только наши сервисы, а всё, что есть. Нужно это редко, но метко: можно одномоментно посмотреть, что происходило на хосте.

Для разработчиков Ansible тоже важен: playbook'и лежат в репозитории, и в него могут коммитить обе стороны — и разработчики, и админы. Разработчики полностью отвечают за свои сервисы. Поскольку сервисы у нас унифицированы, чаще всего достаточно скопировать «скелет», проставить нужные настройки — и всё. Правила роутинга в nginx/proxy тоже на стороне разработки: эксплуатация в это почти не лезет.

Соответственно разработчик может «с коммита» добавить свой сервис, собрать его и выкатить — админ для этого не нужен. Поэтому админ стал спать спокойнее и меньше дёргаться.

## Масштабирование и отказоустойчивость

### Что такое масштабирование?

Масштабирование — это была одна из задач: чтобы система масштабировалась и была отказоустойчивой. Что такое масштабирование? Когда в Kubernetes есть autoscaling: пришла нагрузка — «нарисовался» новый экземпляр сервиса. Создание экземпляров сервиса на лету нам казалось сомнительной идеей: это добавляет сложности и магии, а нам хотелось предсказуемости.

Если нужно, чтобы сервис обрабатывал больше трафика, мы хотели, чтобы он просто держал этот трафик при нормальном горизонтальном масштабировании по хостам/группам. Не хотелось городить отдельную «магическую» сущность, которая решает, когда и сколько экземпляров поднять. И отдельный «единственный» балансировщик — тоже точка отказа: где-то появляется условный master, значит появляется и риск отказа — такого допускать не хотелось.

### Простое решение: группы серверов

Вопрос масштабирования решился достаточно просто — «как в старые времена». Все серверы разделены на группы: application-сервера (простые дешёвые машины), CDN-сервера (мы занимаемся видео — там много трафика и диска), сервера транскодирования (другая конфигурация: сеть/CPU/GPU — под обработку видео) и т. п.

Серверы разной конфигурации, потому что решают разные задачи. Всё просто: в каждой группе больше одного сервера. Если одного не хватает — добавляем ещё. Обычно это актуально для CDN (чем больше трафика — тем больше серверов нужно) и для транскодирования (докидываем машины в группу, они забирают задачи из очереди).

### Отказоустойчивость через DNS и BGP

Отказоустойчивость — за счёт простых механизмов. Например, для фоновых задач: если один из серверов выпадает, задачи остаются в очереди и забираются другими — в целом всё продолжает работать.

Для HTTP-трафика у нас «двойная» схема. Первое — DNS: мы можем направить пользователя в нужный регион. Например, пользователи из России идут в Россию. Дальше уже внутри региона — балансировка по группам серверов: пользователь попадает либо в один, либо в другой дата-центр, а там — на конкретный сервер в группе.

Если сервер «сгорает» или с ним что-то случается, BGP отключается, и он выпадает из раздачи примерно за полторы секунды — нас это устраивает. Обратно включается так же: поднялся — добавился в роутинг. Работает это хорошо.

### Собственный DNS-сервер

Пойдём дальше: у нас свои DNS-сервера, и мы можем достаточно тонко настраивать роутинг. Да, здесь мы «завелосипедили» и написали свой DNS-сервер — зато можем очень точно задавать правила обработки трафика.

Это сильно помогает, потому что, например, одна из задач — масштабирование CDN. Есть крупные клиенты, под которых мы можем оптимизировать инфраструктуру, и DNS в этом сильно помогает. Из коробки такого решения нам никто не давал — пришлось запилить самим.

## Плюсы решения

Плюсы из того, что у нас получилось:

- **Почти ничего не пришлось делать** — обычно все рассказывают, что пришлось много «внедрять», а мы, наоборот, многое выкинули
- **Надёжно** — потому что мы вместо того, чтобы привносить что-то в систему, наоборот выкинули. Мы работаем на том, что даёт из коробки операционная система, больше ничего не ставим
- **Достаточно просто** — нет никаких накладных расходов: софт работает в окружении, просто поставил, запустил — и готово
- **Отлично мониторится** — мониторится не потому что мы такие умные что-то там написали, а потому что стандартизировали образ и подход к метрикам, логам и остальному. Все **логи** в одном месте — спасибо Loki: мы на него перешли в какой-то момент. Сейчас для эксплуатации много чего есть «из коробки» и бесплатно

## Минусы

Минусов для нас, по большому счёту, нет. Они могут быть для кого-то другого, но нас результат устраивает. И «улучшать» тут особо нечего: компонентов стало меньше, мы многое, наоборот, выкинули.

Если придумать, ну конечно они есть:

- **Нет autoscaling** — о котором я говорил в контексте Kubernetes. У нас своё железо, то есть мы не можем «хлопнуть в ладоши» и получить дополнительные ресурсы. В облаке это проще: большинство провайдеров предоставляют autoscaling — пришло больше трафика, запустилась виртуальная машина; трафик упал — машину можно удалить и сэкономить деньги
- **Может сломаться** — например, репозиторий: был, а потом перестал существовать, или нужно руками разбираться с пакетами. Поэтому почти весь софт, который мы используем дополнительно (Grafana, Loki, экспортеры, VictoriaMetrics, Prometheus и т. п.), мы стараемся держать у себя: пакуем и складываем в свой репозиторий. Внешний репозиторий используем по минимуму (например, nginx)
- **Нельзя локально поднять "всю систему одной командой"** — новичкам это иногда было бы удобно. Но по большому счёту и не нужно: сервисов много, а чтобы работать над конкретным сервисом, не надо поднимать всё. Обычно достаточно базы данных, nginx и самого сервиса
- **Нельзя загуглить готовый Helm chart и закрыть задачу** — иногда это удобно, но у этого есть обратная сторона: можно «поставить по умолчанию» и не понимать, как оно работает. У меня был реальный кейс: Kafka подняли с дефолтными путями в `/tmp`, и это вскрылось только когда начались проблемы. Поэтому мы предпочитаем, чтобы люди понимали, что именно они ставят и как это будет жить в проде

## Неочевидные плюсы

Плюс и неочевидные на самом деле ещё есть вот эти штуки:

- **Стала простой и надёжной** — за три года по вине условного systemd или пакетного менеджера у нас ни разу ничего не упало. Если что-то ломалось, то это были наши косяки (обычно на стороне сервиса). При этом всегда есть возможность откатиться назад. Самое страшное, как обычно, — это деплой: там действительно можно что-то сломать
- **Расслабились админы** — раньше админ жил в режиме 24/7: много алертов, постоянные разборы. Сейчас алертов меньше, и иногда это приводит к «расслабленности» — человек может ехать в электричке на дачу и отвечать “я через полчаса буду на связи”. Это, с одной стороны, хорошо (меньше выгорания), с другой — требует дисциплины

## Заключение

Мы показали, что можно успешно эксплуатировать production-инфраструктуру без Kubernetes и Docker, используя стандартные инструменты Linux: systemd, пакетные менеджеры и Ansible. Это решение оказалось проще, надёжнее и эффективнее для нашего случая.

Ключевые моменты:

1. **Простота важнее сложности** — стандартные инструменты решают большинство задач без дополнительных слоёв абстракции
2. **Один бинарник — один сервис** — упрощает доставку, версионирование и эксплуатацию
3. **Автоматизация через Ansible** — вся инфраструктура как код, разработчики не зависят от админов
4. **Масштабирование через группы серверов** — простое горизонтальное масштабирование без оркестраторов
5. **Отказоустойчивость через DNS и BGP** — маршрутизация трафика на уровне сети

За три года эксплуатации ничего не упало по вине systemd или пакетных менеджеров. Это говорит о том, что простое решение может быть более надёжным, чем сложное.

Важно понимать: это не значит, что Kubernetes плох или что его не нужно использовать. Это значит, что для нашего случая (своё железо, специфические требования, небольшая команда) простое решение оказалось более эффективным.

## Сноски

[^go-choice]: О том, почему Go стал основным языком в нашей инфраструктуре и какие преимущества это даёт бизнесу, см. [«Профит для компании от Go»]({{< relref "talks/profit-dlya-kompanii-ot-go.md" >}}). Похожая тема с другим фокусом — в [«Как мы не выбрали K8s»]({{< relref "talks/kak-my-ne-vybrali-k8s.md" >}}).

