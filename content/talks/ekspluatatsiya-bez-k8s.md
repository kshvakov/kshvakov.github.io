---
title: "Эксплуатация без K8s"
date: 2022-06-14
description: "Практический опыт эксплуатации production-инфраструктуры без Kubernetes: как мы отказались от K8s и построили простую, надёжную и эффективную систему на базе systemd и пакетных менеджеров."
tags: ["kubernetes", "devops", "инфраструктура", "systemd", "ansible", "эксплуатация", "kinescope"]
---

В этом докладе я рассказываю о нашем опыте эксплуатации production-инфраструктуры без Kubernetes в Kinescope. Мы отказались от K8s около трёх лет назад и построили простую, надёжную и эффективную систему на базе стандартных инструментов Linux: systemd, пакетных менеджеров и Ansible.

Доклад охватывает причины отказа от Kubernetes, требования к системе, выбор решений и практический опыт эксплуатации более 50 серверов в 4 дата-центрах силами одного администратора.

{{< youtube id="e50e5CjsKlU" title="Эксплуатация без K8s / Кирилл Шваков, Kinescope" >}}

## TL;DR

Основные выводы из нашего опыта эксплуатации без Kubernetes:

- **Простота важнее сложности** — стандартные инструменты Linux (systemd, пакетные менеджеры) решают большинство задач без дополнительных слоёв абстракции
- **Один бинарник — один сервис** — все сервисы собираются в один бинарный файл, что упрощает доставку и эксплуатацию
- **Автоматизация через Ansible** — вся инфраструктура описывается кодом, разработчики не зависят от админов
- **Масштабирование через группы серверов** — простое горизонтальное масштабирование без оркестраторов
- **Отказоустойчивость через DNS и BGP** — маршрутизация трафика на уровне сети, а не приложений
- **Меньше компонентов — меньше проблем** — за три года ничего не упало по вине systemd или пакетных менеджеров

## Контекст: что было и что стало

Сейчас у нас нет Kubernetes и Docker в продакшене. Раньше они были, но мы не занимались их выпиливанием специально — просто так получилось. Сейчас у нас один админ, один DevOps-инженер, мы находимся в 4 дата-центрах (два в России, один в Европе, один в США, и в Азии мы тоже хотим), и чуть больше 50 серверов.

Когда-то давно у нас был Kubernetes, и мы без него живём уже около трёх лет (может быть чуть меньше). Он стоял, что-то делал, ел ресурсы, иногда ломался, и мы не понимали, что там сломалось. Вроде всё работало, но починить это было зачастую какой-то магией — админ занимался этим. У нас было тогда даже два админа.

Мне очень нравилось то, что происходило, потому что не было никакого контроля. Всё усложнялось тем, что было два дата-центра, соответственно было несколько кластеров Kubernetes, и вот это всё.

Мы не хотели ничего отказываться, но хотели больше стабильности системы.

## Что мы хотели от системы

Прежде чем решать проблемы с Kubernetes как таковым, мы хотели задаться вопросом: а что мы на самом деле хотим от наших систем?

### Требования эксплуатации

Инженер, который занимается эксплуатацией, — это не разработчик. Он не знает, что там находится в сервисе, и в принципе ему и не нужно знать, что вообще-то сервис делает и как он живёт. У нас около 40 сервисов, может больше.

Эксплуатация хотела, чтобы сервис:

- Представлял какие-то порты наружу (если он работает по HTTP, это неважно)
- Обязательно имел порт для метрик
- Хранил параметры через переменные окружения (все конфиги должны быть через переменные окружения, чтобы не было конфигурационных файлов по возможности)
- Не сильно отличался от других сервисов (зачем тебе платить кучу разных сервисов, чтобы они ещё по-разному настраивались и по-разному эксплуатировались — это будет сложно, дорого и неэффективно)

### Требования разработки

Разработка естественно хотела:

- Не зависеть от эксплуатации — не находиться в состоянии заложников
- Не просить добавить какой-то сервис или выкатить куда-то
- Не выпрашивать логи, мониторинг и всё остальное — обычные бытовые проблемы, которые у некоторых остаются проблемами

### Общие требования

Что мы хотели от системы в целом:

- **Автоматизация** — не то чтобы её не было, она была, но тем не менее хотелось больше
- **Масштабирование** — система должна масштабироваться
- **Отказоустойчивость** — система должна быть отказоустойчивой
- **Единый формат пакетов и доставки** — это важная часть, мы деплоим сейчас, наверное, в день бывает, раскатываем всё по 10–20 куда-нибудь
- **Персистентность сервиса** — мы хотим собрать сервис ровно в таком же состоянии, протестировать и потом выкатить на продакшн
- **Изоляция ресурсов** — на одной машине может быть более чем один сервис
- **Безопасность** — это важно
- **Производительность** — у нас были проблемы с производительностью Kubernetes, он ломался, это выходило дорого по железу

## Решение: один бинарник — один сервис

Мы пошли немного с другого пути: мы стали не пытаться сделать платформу для сервисов, которая могла бы всё что угодно, а решили дотащить сами сервисы до нужного состояния.

### Требования к сервисам

Один сервис должен быть одним бинарником со стандартными метриками и всем остальным. У нас были сервисы, написанные на Ruby — один сервис — один бинарник соответственно не подходил. Сервисы, которые остались на Ruby, мы их тоже переписали на Go, чтобы можно было их собирать.

Сейчас мы собираем не только сервисы, которые просто сервисы. У нас, например, есть плеер (это JS-файлики), у нас есть сайт, у нас есть админка — всё это мы тоже пакуем в один бинарник вместе со статикой. То есть у нас все сервисы одинаковые с точки зрения эксплуатации — неважно, что это: player, API или DNS-сервер. Это всё одинаково с точки зрения эксплуатации, никакой разницы нет, и с точки зрения доставки тоже.

### Единый формат метрик

Метрики понятно не могут быть разные у приложения, но всегда должна быть как минимум одна, которая описывает приложение — это версия, когда он был собран, и название. Так мы его всегда видим.

В итоге мы пришли к тому, что все сервисы одинаковые — они никак не отличаются с точки зрения эксплуатации. На выходе у нас получился один бинарник, и жизнь стала с этим легче.

## Почему не Docker?

Плюсы не только в том, что бинарник можно запустить руками — ничего не произойдёт. Нужно доставить и запустить сервис. Для этого многие говорят, что нужен Docker, потому что Docker это удобно, Docker это пакует, у Docker есть изоляция ресурсов и прочие штуки.

Но помимо всего прочего у Docker есть некоторые overhead. Потому что там в строке мы работаем со стороной, с кем работаем сеть — это всё Google, или там проблемы Docker сети в любом случае. Нам нужно проверенное и надёжное решение, а Docker себя таким не показывал — не то чтобы были какие-то проблемы, скорее он слишком большой и не нужен, и у него есть проблема производительности, которая нам не нужна.

## Решение: пакетный менеджер и systemd

Чтобы что-то доставить надёжно и запустить, казалось, что всё есть в операционной системе. Мы работаем на Linux, у нас везде Ubuntu, и собственно как в любой операционной системе есть пакетный менеджер (у нас это самый распространённый пакетный менеджер, который существует уже достаточно давно) и systemd, который в принципе запускает любое приложение, которое есть в системе.

Эти штуки старые, надёжные и проверенные. Ещё ставить систему не нужны никакую дополнительную — мы не тащим средства, у нас меньше каких-то частей, которые могут выйти из строя — это прям профит.

При этом менеджер это необязательно apt — может быть yum, может быть любой, в зависимости от вашей операционной системы. Если у нас Ubuntu, то apt, или там ещё что-то — вы можете использовать, разница абсолютно никакой нет.

### Сборка пакетов: NFPM

Единственно что для сборки мы используем [NFPM (Not FPM)](https://github.com/goreleaser/nfpm). Нам лень писать каждый раз файлик или править их руками для сборки пакетов, поэтому есть прекрасная штука NFPM от GoReleaser. Это простой инструмент для создания пакетов (deb, rpm, apk, ipk, arch linux), написанный на Go, без зависимостей. Он позволяет очень просто в YAML описать, что вы хотите видеть в пакете, и он может собирать как раз под любую операционку — неважно, будет это apt, yum, rpm или systemd.

## Преимущества systemd

### Видимость в системе

Во-первых, сервис виден системе, и мы это легко мониторим. Мы на машину закидываем экспортеры, и даже если у нас разработчик вдруг не написал себе мониторинг куда-то (то есть у него не добавлен endpoint или мы его не добавили в Prometheus), мы его увидим, потому что он собирает стандартные метрики. Мы подхватываемся по названию всех видим в системе, и там упал — не упал тоже видим.

### Изоляция ресурсов

Если кто-то говорит, что Docker нужен для изоляции ресурсов, это не совсем так. В systemd точно так же прописываются ограничения — там CPU, память и всё, что вы хотите. То есть там достаточно гибко сделано.

### Безопасность

Безопасность естественно есть — если сервис, например, у нас не работает с девайсами какими-то, то он до них достучаться не сможет. Вы это всё прописываете там же, это всё видно.

### Задачи по расписанию

Мы используем systemd для задач по расписанию. Если кто-то помнит cron — штука есть. У нас есть несколько задач, которые мы запускаем редко, там на условном к этому расписанию, поэтому нет смысла висеть сервису всё оставшееся время. Поэтому также через systemd мы просто ставим какую-то задачу — он запускает, мы производительность получаем.

### Производительность и надёжность

Если у нас ничего нет, то у нас и ломаться нечему, и ресурсы есть тоже нечем. Systemd он и так работает, и я на самом деле где-то читал и слышал людей, которые там что-то делали — они тоже жаловались на systemd, что он ел там какое-то нереальное количество ресурсов. Но в принципе его практически нет, но это соответственно надёжно, потому что если эта штука не работает, то у нас вообще ничего не работает.

## Автоматизация через Ansible

Обычно все рассказывают про то, что что-то внедряют. Мы рассказываем про то, что мы как бы выпилили и получили в принципе ничего не делая — абсолютно ещё даже не кого софта поставили. У нас получилось, что у нас есть единый формат пакетов, и с доставкой тоже всё ок, у нас есть версионирование, изоляция — то есть практически серебряная пуля.

Однако у нас ещё были закрыты вопросы по автоматизации.

### Автоматизировать нужно всё

Обычно сейчас расскажу, наверно, такой капитан очевидность: автоматизировать нужно всё, даже если у вас есть один сервер. Это можно всё автоматизировать, потому что если он сгорит, потом вы руками ещё не сделаете — вы не восстановите то, что там было, окружение какое, там неважно почему, чем занимается.

### Почему Ansible?

Для автоматизации естественно мы выбрали Ansible. Он уже был в тот момент, потому что как-то выглядел немножко странно. Почему бы вы выбрали Ansible? А что ещё выбирать? Puppet мы пользуемся верно с самого момента того, как был первый камень, это Fancy был сделан — то есть там много лет. Его легко поддерживать и желание расширять плагинами. Про легко поддерживать как бы оставлю звёздочку, потому что всё на самом деле не очень так.

Если вы запустите Ansible, у вас будет отход — то есть поверьте, кого. Поэтому раз в какое-то время мы возвращаемся к тому, что мы его чистим — то есть переписываем playbook'и, удаляем всякого ненужную ерунду, которая там скопилась, ненужные там сервисы, ну и проще вот эту вот историю.

### Как работает Ansible у нас

У нас всё очень просто. У нас есть две команды по большому счёту — разработчики и инженеры, которые поддерживают систему (админы, проще говоря).

Эксплуатация чем занимается: когда у нас появляется сервер, какое-то приходит, и когда к нему подвели сеть, там просто накатывается базовая роль. До которой накатывается своя роль, подключают добавляют нашей базе, выключают root-доступ, коллаборацию до брата, сашки и на свои роли выключают доступ вообще всем. Вот и ставят для мониторинг — это node exporter, экспортер, кабель из той лодки для сбора логов. Собираем вообще все логе в системе — то есть не только наш сервис, вообще всё, что есть. Это бывает очень нужно, бывает нужно очень редко, но метко, потому что вы одномоментно можете посмотреть, что случилось в системе.

Для разработчиков Ansible тоже как и потому что отойти на репозиторий, и чтобы админы постоянно одни зависели от разработчиков, разработчики не зависеть от админов — админу тоже туда коммитить. Соответственно разработчики отвечают полностью за свои сервисы. Так сервиса одинаковые, все у нас. Вот твой ролику сервисов тоже все одинаковые — достаточно в принципе скопипастить, поставить там свои настройки, к тебе нужны, и в принципе всё. И соответственно различные правила роутинга в nginx или proxy как бы тоже отвечает разработчики — обмен туда даже не лезет.

Соответственно разработчик может от коммита добавить свой сервис, собрать его и сзади плоти админом для этого не нужен. Вот поэтому админ у нас стал спать спокойно, хотя бы и не дёргаться.

## Масштабирование и отказоустойчивость

### Что такое масштабирование?

Масштабирование — это была одна из задач системы, чтобы система масштабировалась и была отказоустойчивой. Что такое масштабирование? Когда отбирать как Kubernetes, потом autoscaling все дела — вот у вас там запустилась много сервисов, у вас пришло нагрузка, и у вас новый нарисовался. То есть создание экземпляров сервиса на лету — так вообще не серьёзно, то есть никакой не масштабирование.

Если вам нужно, чтобы один сервис обрабатывал больше трафика, то дайте мне больше трафика, и он должен держать его просто. То есть не нужно для этого создавать два экземпляра. И выделенный балансировщик тоже — отказа в любом случае у вас есть где-то в системе условной какой-то мастер, значит у вас есть отказ — такого тоже как бы допускать было нельзя.

### Простое решение: группы серверов

Про масштабированию решился вопрос достаточно просто — как в старые древние времена. То есть у нас все сервера разделены на группы — это application-сервера (очень простые дешёвые железяки, и мы ещё будем их удешевлять, потому что там не CPU, не память и тем более дисковая подсистема никак не тратятся), CDN-сервера (которые мы производим полностью, потому что мы занимаемся видео, соответственно там загружают видео), сервера транскодирования (совершенно другие сетевые карты и видеокарты, чтобы просканировать видео), и соответственно там match-сервера, из которых мы раздаём.

То есть это все сервера разной конфигурации, потому что разные задачи решают. Всё просто: в каждой группе больше, чем один сервер. Если один сервер, например, не справляется, дата как бы трафик будет ещё и на втором, соответственно может доставлять там до бесконечности, если это необходимо. Таковой необходимости нет как таковой — то есть только в некоторых группах серверов, например, CDN, потому что то силён как бы — то есть чем больше трафика, тем больше нам нужно серверов. И соответственно транскодирования то же самое — докидываем в группу, они забирают свою задачу.

### Отказоустойчивость через DNS и BGP

Отказоустойчивость за счёт чего? Собственно, если у нас один из серверов, который был никита задачу в фоне, то соответственно то очереди. Вот тут ещё другого нет как бы, и но всё хорошо работает.

Для HTTP-трафика у нас как бы такая двойная штука: первое — это DNS, мы можем загнать человека плюс-минус куда-то на точку. Например, там пользователи с России они пойдут в России. И уже на точке в России, например, в Москве до 2 дата-центра. Там уже балансировка на группах серверов — то есть, например, он пошёл по какому-то пичеру, и он попадает там либо в 1, либо в другой дата-центр, и соответственно там он попадает на какой-то сервер.

Если вдруг у нас сервер сгорит или что-то с ним случится, там BGP отключится, и соответственно он из раздачу выпадает там где-то за полторы секунды, что у нас в принципе устрою. То же самое как включается — если он там поднялся, он добавляется в роутинг, работает это хорошо.

### Собственный DNS-сервер

Больше вернёмся проделать DNS до г воды — у нас тоже свои DNS-сервера, и мы можем настраивать достаточно тонко роутинг именно по делу. Вот здесь мы кстати за велосипеде ли мы написали свой DNS-сервер, вот поэтому можем там очень тонко настраивать правила, как бы как обрабатывать трафик.

Это нам сильно помогает, потому что, например, у нас сейчас ещё одна из задач — масштабирование CDN. У нас есть крупные клиенты, для которых мы можем оптимизировать свою структуру инфраструктуры, и DNS в этом случае нам как бы сильно поможет. То есть из коробки такого решения никто не предоставляет, минус себя запилим.

## Плюсы решения

Плюсы из того, что у нас получилось:

- **Почти ничего не пришлось делать** — обычно все что-то не хотят делать, потому что что-то нужно делать, а мы наоборот ничего не делали
- **Надёжно** — потому что мы вместо того, чтобы привносить что-то в систему, наоборот выкинули. В принципе мы работаем на том, что даёт из коробки операционная система, больше ничего не ставим
- **Достаточно просто** — нет никакого overhead, потому что софт работает в окружении, просто поставил, запустил, как есть
- **Отлично мониторится** — опять же мониторится не потому что мы такие умные что-то там написали, сделали, а потому что образ стандартизировали, подход там к метрикам, к логам, ко всему остальному. Все логе в одном месте — это прям спасибо Loki сейчас, потому что мы на него перешли в какой-то момент. Для фанов Elasticsearch это прям не стоит сравнивать ситуацию на рынке условно говоря сейчас и то, что было десять лет назад. Сейчас для эксплуатации прям есть всё и бесплатно

## Минусы

Минусов для нас в принципе нет. Они могут быть для кого-то другого, но для нас здесь никаких минусов в том, что получилось нет, и нас это всё устраивает. У нас даже не что родом там через какой-то момент будем что-то улучшать — и улучшать тоже ничего, потому что в принципе ничего нет, мы все выкинули, наоборот они принесли.

Если придумать, ну конечно они есть:

- **Нет autoscaling** — которым я говорил в особенности Kubernetes. У нас своё железо, то есть мы не можем так хлопнуть в ладоши, у нас там появились какие-то дополнительные ресурсы. Но если вы, например, живете в каком-то cloud, то там так сделать можно. И в принципе сейчас, по-моему, все клауды представляют предоставляют autoscaling — то есть скважины пришло больше трафика, где-то запустит виртуальную машину, когда трафик упадёт, то машину можно удалить, и соответственно кабинета в силе сэкономить по ресурсам, ну по деньгам
- **Может сломаться** — ну как пакетный менеджер, система иногда бывают репозитории какой-то существовало, теперь он перестал существовать, да или там ещё что-то нужно руками заходить. По этому в принципе мы почти весь софт, который у нас используют дополнительно (это Grafana, Loki, вот эти экспортеры, там VictoriaMetrics, Prometheus, вот эти вот дополнительные софты), всё-таки у нас есть, который пишем нами, и мы его точно также пикируем в пакетах, если он даже без пакетов был, и складываем наш репозитории. То есть мы внешней репозитории там только nginx используем, и всё остальное всё лежит у нас
- **Нельзя локально сделать какой-то campus** — и у тебя вся система такая появилась. Особенным новичкам не очень, наверное, может быть это удобно. Действительно нельзя, но это в принципе не нужно никому не так уж по большому счёту. Во-первых, у нас действительно много сервисов, но для того чтобы на 1 работал конкретным там какой-то сервис, тебе не нужно поднимать абсолютно всё. То есть достаточно что прививала база данных, и достаточно того, что nginx был поднят, один сервис внутри его поделил, это за камень, и оно ушло, и где-то там на стоянке собралось. Она уже в окружении всех сервисов можно посмотреть — то есть такая проблема как бы не то чтобы проблемам, опять же для нас
- **Нельзя загуглить какой-нибудь Helm chart** — как бы закрыть задачи. То есть если она попала какая-то задача, то он действительно должен пойти что-то сделать, да, зайти настолько фол, скопировать, как бы сказать: "Вот смотрите, я вам поставил MongoDB, да, как отказоустойчивого". И потом пришёл кто-нибудь, шнур выдрал сервер обратно, ставила на вас больше никто не завелась. Вот кстати реальный случай из жизни: я раньше заводил и запускал, по-моему, Kafka в tmp. В них по умолчанию не знаю, как сейчас, конфигов пути были указаны в tmp. Вот и у нас был админ тогда, работал в другой компании. Вот у нас был обмен, он потом уехал работать в Facebook. И через какое-то время, как он уехал работать в Facebook, у нас три бутылки серверы — мы узнали, что у него все конфиги были по умолчанию, соответственно это всё хранилось в tmp. Вот я написал чувака в Kafka, они сказали мне не то, типа не проблема, потому что весь чтобы поставить Kafka, человек должен прочитать нашу инструкцию и книгу. Знаете, вы не все читают, они горят, не все нормально. Вот поэтому да, когда кто-то ставит Helm chart, там тоже может быть что-то написано не то, как бы и хотелось бы понимание, как что человек всё-таки делает. Так мы такую возможность человеку больше не даём — ничего не делать. Вот в принципе спокойно стала в 7, так это ты не только вот

## Неочевидные плюсы

Плюс и неочевидные на самом деле ещё есть вот эти штуки:

- **Стала простой и в принципе надёжной** — то есть за три года, условно говоря, что я скажу насчёт сломается. По вине условного там нашего systemd и ещё штуки, на которые мы условно работаем, до ни разу ничего не упало. Вот вообще ничего. То есть если мы где-то могли там задать томиться, как бы это чисто наши косяки — то есть это чисто вот руками разработчика либо там ну либо руками разработчика было что-то каабу сломано. И за тепло, ну вот. При этом как бы есть всегда возможность откатиться назад — как бы в принципе обычно ничего не происходит, и самое страшное, что может быть, это конечно deploy, как всегда там что-то могут сломать. Так оно в принципе не ломается — в этом есть минус
- **Расслаблены админы** — вот если раньше, например, админ был в состоянии дежурства 24 на 7, и каждый alert, а их было много, он видел, как бы он его там смотрел, как бы его можно было сюда спаситель, что-то тебе отвечал. Теперь наш админ там как бы машин днём позвонить, далее при этом написать ему такую не типа отстань, как бы я там в электричке еду на дачу. Вот едет человек на дачу, надо челки как бы 30 минут едет, а служба идёт. Вот поэтому есть некоторая расслабленность, и это иногда не очень хорошо. Ну как бы все люди поэтому нормально к этому относятся

## Заключение

Мы показали, что можно успешно эксплуатировать production-инфраструктуру без Kubernetes и Docker, используя стандартные инструменты Linux: systemd, пакетные менеджеры и Ansible. Это решение оказалось проще, надёжнее и эффективнее для нашего случая.

Ключевые моменты:

1. **Простота важнее сложности** — стандартные инструменты решают большинство задач без дополнительных слоёв абстракции
2. **Один бинарник — один сервис** — упрощает доставку, версионирование и эксплуатацию
3. **Автоматизация через Ansible** — вся инфраструктура как код, разработчики не зависят от админов
4. **Масштабирование через группы серверов** — простое горизонтальное масштабирование без оркестраторов
5. **Отказоустойчивость через DNS и BGP** — маршрутизация трафика на уровне сети

За три года эксплуатации ничего не упало по вине systemd или пакетных менеджеров. Это говорит о том, что простое решение может быть более надёжным, чем сложное.

Важно понимать: это не значит, что Kubernetes плох или что его не нужно использовать. Это значит, что для нашего случая (своё железо, специфические требования, небольшая команда) простое решение оказалось более эффективным.

