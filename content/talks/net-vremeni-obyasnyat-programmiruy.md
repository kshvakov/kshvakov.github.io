---
title: "Нет времени объяснять, программируй!"
date: 2024-10-29
description: "Практический опыт разработки собственных решений в Kinescope: когда и почему стоит писать свой софт вместо использования готовых продуктов, примеры из практики (CDN, DNS, хранение данных) и работа с Go."
tags: ["go", "golang", "разработка", "инфраструктура", "cdn", "производительность", "kinescope", "zero-copy", "tls"]
---

Расскажу про опыт разработки собственных решений в Kinescope: когда стоит писать свой софт, какие проблемы это решает и какие сложности возникают.

{{< youtube id="ZC2RviwLgdo" title="Нет времени объяснять, программируй! / Кирилл Шваков, Kinescope" >}}

## TL;DR

- **Сначала используйте готовое, потом пишите своё**: на старте проекта важны сроки, не стоит начинать с разработки с нуля.
- **Реальная необходимость — главный критерий**: пишите свой софт, когда существующие решения не решают ваши конкретные проблемы и вы не можете их исправить.
- **Понимание текущего решения обязательно**: если не понимаете, как работает то, что используете, не сможете написать лучше.
- **Ограничения — это хорошо**: они помогают фокусироваться на том, что действительно нужно, и не реализовывать лишнее.
- **Метрики и профилирование критичны**: без них невозможно понять, что происходит и где проблемы.

## Вступление: про что этот доклад

Доклад должен был быть про технологии, но получился больше про процессы и решения. В Kinescope мы пишем очень много софта сами — иногда даже того, который, казалось бы, писать не нужно, потому что он уже есть.

Сейчас у нас много собственных решений: DNS, CDN, система хранения контента, различные библиотеки для работы с медиаформатами. Это всё написано либо полностью с нуля, либо используя какие-то библиотеки, но не коробочные продукты.

## Контекст: откуда мы стартовали

Так было не всегда. Когда проект только разрабатывается, не стоит начинать делать что-то из головы — мы так не делали.

Если вернуться назад, то был 2020 год. Все ждали Олимпиаду в Токио, кто-то сходил с ума, а мы начинали писать Kinescope. В тот год все сидели по домам, и мы писали.

### Что важно на старте проекта

При запуске проекта важны **сроки**. Мы были в состоянии стартапа, нам нужно было быстро запуститься, и точно мы не будем что-то ставить сами.

Как этого добиться? Достаточно просто:

1. **Понятные цели и задачи** — с этим у нас проблем не было, потому что мы прекрасно понимали, какой должен быть продукт и что он должен делать. У нас было понимание задач, потому что мы и до Kinescope занимались чем-то похожим.

2. **Надёжная опытная команда** — у нас не было с этим проблем. Команда была до Kinescope, и мы двинулись в этот проект с надёжными проверенными людьми.

3. **Проверенные технологии** — мы не стали ничего думать, посмотрели, с чем работали до этого, что хорошо знаем, и стали это использовать.

### Наш начальный стек

Если говорить про команду, я уже сказал — она у нас была. Но если у вас надёжная команда, это не значит, что не будет косяков. У нас есть архитектурные косяки, кто-то что-то забыл, не подумал, что-то сделал. Но самое главное по опыту — с чем мы сталкиваемся:

**Разработчики не знают SQL и не умеют думать о базе данных.** Из этого вылезает самое большое количество проблем. Поэтому хотелось бы, помимо знания какого-то языка программирования, чтобы знали что-то ещё.

Мы взяли проверенные технологии. DNS — естественно нужен был какой-то гео-DNS, мы взяли Google DNS. У нас сразу же оговорюсь: у нас своё железо было изначально, то есть мы не используем никакой cloud. У нас своя железная платформа, мы находимся в нескольких дата-центрах, и это было практически с самого старта проекта.

Поэтому у нас BGP/anycast на точках, на машинах, которые анонсируют, стоят Bird, под ними стоит nginx, под nginx написаны какие-то приложения на Go. Это общается с PostgreSQL для аналитики, у нас был ClickHouse для хранения логов. И понятно, у нас есть очереди и прочая история.

Достаточно классический стек, с которым мы работали и до этого. Это FreeBSD и nginx — это хорошая связка, её в своё время использовал Netflix. Сейчас есть компания, недавно смотрел доклад, не помню кто, российская большая, тоже занимается чем-то с видео связанным, тоже пытаются сейчас делать FreeBSD.

## Что получилось

Всё получилось — факапа не было.

Если отмотать в 2020 год и чуть позже, мы рассказывали, что мы платформа для интернета, объединяем технологии. Сейчас мы выглядим так: у нас большое количество клиентов, в 2023 году нас очень многие используют. Если вы пользуетесь интернетом, то так или иначе, скорее всего, с вероятностью 99.99% вы пользуетесь нами — не только нами, но где-то видите видео, которое раздаётся, где-то смотрите онлайн-трансляции, которые раздаются через нас.

## Рост и новые задачи

Как все поняли, мы начали расти. Рост бывает разный, и у нас он случился. У нас начали появляться новые клиенты, какая-то база сформировалась. Вместе с клиентами к нам пришла нагрузка, больше она начала расти.

У нас практически не поменялась команда — не сильно. Стало больше разработчиков, которые занимаются фронтендом и плеерами, стало больше дизайнеров. Но команда как таковая не сильно росла. Она выросла в очень хорошем направлении: появился человек, который занимается медиаформатами на Go. Это всё хорошо, это нам плюс.

Задачи стали расти. Бизнес растёт, поддержка нужна. Вроде бы всё хорошо, но времени не хватает — что-то пилим, задачи, клиенты.

## Где взять время и зачем что-то переписывать

Где в этом месте взять время или вообще зачем что-то переписывать? Если оно в принципе работает, работает относительно неплохо, приносит деньги — зачем ввязываться в разработку какого-то кастома, который можно взять и поставить?

### Почему появляется необходимость писать свой софт

Зачем вообще появляется необходимость что-то написать? Это может быть хобби, обучение, развитие — чем заняться. Иногда так и делают просто потому, что могут. С этим мы тоже сталкиваемся, причём не только в российском сообществе, но и с иностранными компаниями, даже очень большими.

**Реальная необходимость** у нас была. Реальная необходимость возникает не только у нас. Иногда из этого вырастают очень хорошие серьёзные продукты, которыми мы пользуемся, а потом отказываемся и пишем что-то своё.

Хорошие примеры: Nginx появился под реальные задачи, писался людьми, которые сталкивались с проблемами и решали их. ClickHouse — та же история. ScyllaDB и InnoDB — отличные штуки, их любят все, даже те, кто пользуется PostgreSQL, потому что это произведение искусства. Советую почитать код, если интересно занимаетесь базами данных или работой с дисками — хорошая штука для погружения.

ScyllaDB тоже образец инженерного искусства, как и многое, что они делают, включая фреймворки, которые выпускают.

## Как понять, что время пришло

Как понять, что время-то пришло что-то взять и переписать? Понятно, то есть у вас должна быть какая-то проблема, и существующее решение не устраивает.

Нельзя сказать «он меня не устраивает, мне не нравится, потому что у него логотип зелёный» — не прокатит. Нужно назвать конкретные проблемы, с которыми вы столкнулись, и главное — вы не можете это решить никаким способом. Компетенции не хватает, например, в языке или экосистеме. Вы не можете там что-то сделать, не можете поправить, потому что архитектурно это не проблема софта, который вы используете — архитектура не позволяет внести коррективы, которые нужны только вам, нет API.

Ещё один фактор: огромное количество интересных решений забрасывают, потому что это реально сложно поддерживать. Мы сейчас ничего не открываем по одной простой причине: мы просто не вытянем поддержку. Хотя нам есть что открыть, возможно, когда-то придёт время, но нет человека, которого можно было бы найти, чтобы он что-то переписал или сделал для вас.

Удалённая команда — это тоже хорошее решение. Мы очень долгое время, когда у нас не было инженеров, которые занимаются форматом, у нас были ребята из Нидерландов, которые решали нам проблемы с форматом. Они пишут Ceph. И в какой-то момент даже они столкнулись с проблемой, которую невозможно решить, поэтому мы теперь смотрим на Ceph косо — в какой-то момент мы его тоже заменим.

### Что должно быть на момент принятия решения

**Понимание, как работает текущее решение.** Если вы не понимаете, как работает текущее какое-то решение, софт, который вы используете, то вы не сможете написать что-то лучше, изменить, поправить. Это логично, но не всегда это так на удивление.

> **Практическая заметка.** Перед тем как писать собственное решение, важно глубоко понять текущее. Это не только про чтение документации, но и про изучение исходного кода, профилирование и понимание архитектурных решений. Без этого понимания легко создать решение, которое будет хуже существующего. Источник: опыт разработки собственных решений в Kinescope.

**Понятный список требований** — описание того, что должно получиться. ТЗ и документация не должны появиться только после того, как вы что-то разрабатываете. Это комплексный процесс — нельзя просто сидеть вечером и писать с нуля. У вас всегда есть зарисовки на салфетке, планы, диаграммы — это нормально.

**Должен быть список ограничений.** Когда вы разрабатываете технологию под бизнес, у вас должно быть понимание, что решение может не решить, или что можно выкинуть. Ограничения — это хорошо, и мы ими активно пользуемся в наших решениях, потому что выкидываем много того, что нам не нужно, и не реализуем лишнее.

## Реальная история номер один: CDN

У нас есть CDN. Казалось бы, простая штука — поставили nginx, и оно работает. Мы поставили nginx, поставили FreeBSD, и это всё работает. Проблем нет почти. Стандарт на то время, просто надёжно, производительно, можно допиливать при желании.

Для видеоконтента, которым мы занимаемся, у нас так и было: поставили nginx, поставили модули, всё работало. Но в какой-то момент нам стало этого не хватать[^cdn-details].

Новые клиенты появились, появились новые потребности, и хочешь этого не хочешь, так как ты находишься в бизнесе, это нужно решать и услужить всем.

### Что нужно от CDN

Что нужно от CDN:

- **Производительность** — сколько трафика он может прокачать
- **Латентность** — об этом чуть позже
- **Масштабируемость** — у нас очень много объектов на ноду, даже сейчас, потому что мы храним не только свой контент, который транскодируем, постоянный кэш — в один сервер это реально не влезает
- **Подсчёт трафика** — это тоже интересная история, потому что подсчёт трафика оказался нетривиальной задачей

### Проблемы с nginx

С чем мы столкнулись с nginx после того, как начали писать всё это дело на Go:

- **Проблемы с ростом количества объектов в кэше** — особенно если вы используете его просто как прокси-кэш, оно сойдёт с ума. Это неплохой nginx, просто он не под эти задачи заточен — у него другой профиль.

- **Решаемо с костылями** — ничего страшного, так многие работают, но сегментировать трафик сложно.

- **Сложно отправлять поток метрик и логов** — запросы мы должны знать о них: сколько данных мы передали, какой это был клиент, какой это его проект, что это за медиаформат. Нужные метрики тоже сложно добавить.

### Альтернативы

Стали искать альтернативы. Альтернатива есть — Varnish, его используют Fastly, сильно допилили, штука реально хорошая, особенно для лайва.

Вроде бы ничего, но у Varnish нет хорошего движка хранения, он использует mmap со своими проблемами. Если у вас контента больше, чем оперативной памяти, то у вас проблемы. Вопрос с метриками и логами — он достаточно открыт, но нужно допиливать.

Он написан на C, а у нас команда пишет на Go, у нас всё написано на Go. Были бы специалисты, которые его допиливают — это размытие стека технологий, риски удорожания проекта. Поэтому берём, пишем свой.

### Почему бы и нет

Одна из главных задач в нашем случае разработки была — в том случае, наверное любой — что решение, которое вы пишете, оно должно решать проблемы, а не создавать их. Потому что бывает наоборот: вы что-то написали, а потом чините с этим годами или ещё пытаетесь, не только мучиться, но и продать. Есть такие решения и в open source, и в коммерческой разработке.

### Что мы сделали

Чтобы решить нашу проблему, мы разделили муху от котлет. У нас есть серверы, которые умеют читать с диска и отдавать контент (если утрированно).

Есть прокси-серверы, которые принимают трафик. Есть менеджер, с которым общаются и получают информацию, зоны, настройки — чтобы всё обновлялось. И есть коллектор, который принимает поток логов.

Прокси принимает трафик и отправляет в нужный шард. Она умеет разобрать HTTP и направить туда, куда нужно. Умеет делать феры нормально, потому что есть различные правила, куда мы должны отправить трафик, если, например, под нами сервер лежит.

И есть метрики — мы понимаем, что происходит, и можем сразу вклиниться, если наш софт как-то ведёт себя не так, то мы сразу запиливаем и решаем. На метриках можем повесить алерты. У нас есть дашборд на весь наш софт, который мы пишем, есть там алерты и прочее.

#### Архитектура собственной CDN

```text
client request
   |
   v
proxy servers (edge)
   |      |
   |      +---> parse HTTP
   |      +---> routing rules
   |      +---> sharding
   |
   +---> storage servers (shards)
   |      |
   |      +---> read from disk
   |      +---> serve content
   |
   +---> manager
   |      |
   |      +---> zones/config
   |      +---> updates
   |
   +---> log collector
          |
          +---> metrics
          +---> dashboards
          +---> alerts
```

Разделение ответственности: прокси — маршрутизация, storage — чтение с диска, manager — конфигурация, collector — метрики и логи.

### Хранение данных

Само хранилище — достаточно простая штука, написано на Go.

Что мы сделали, чтобы решить проблемы с мелкими файлами: мы решили для себя, что каждый диск у нас по большому счёту — это просто блочное устройство, на котором один файл. Там несколько терабайт.

У нас есть индексы в памяти, чтобы можно было быстро понять, на каком диске это лежит, открыть файл и отправить его — открыть нужное место в файле, сделать seek и отдать.

Это общая очередь на запись — это важно, чтобы уметь работать с HDD. У нас это очень просто сделано — вот прелесть Go, что там есть очень простые решения, которые на других языках сложно реализовать.

Здесь хорошо, что в Go есть горутины — это очень сильно. Когда мы поднимаем какой-то файл: у нас есть он, например, в кэше, его нет на сервере, пришёл запрос. Мы видим, что нет, начинаем его скачивать, скачали, помещаем его в рутину — это общая очередь. Каждое устройство слушает эту рутину, какое из них свободно, то начинает писать, чтобы уметь работать с обычными дисками.

Почему SSD: потому что это дешевле. Если использовать SSD, мы будем работать лучше. Если не использовать SSD, всё равно всё работает хорошо. У нас на рынке один из самых низких latency-расходов.

Мы умеем делать batch из chunks, потому что у нас бывает поток, например, лайва, которая сейчас идёт — это поток маленьких файлов. Чтобы не было рандомного чтения слишком большого, мы пересунули, немножко храним в памяти, потом их склеиваем и одним batch пишем на диск. Получается неплохо — мы сильно оптимизировали историю с рандомным чтением диска.

Мы умеем раздавать из памяти. Казалось бы тоже хорошая история, но чуть позже вернёмся — не всегда то, что кажется хорошо.

### Логи

Логи — обычные, мы собираем. У нас есть очередь на запись логов в памяти, та же самая рутина. Мы либо в какой-то момент делаем flush, либо делаем flush, если набрали batch больше определённого количества запросов, собираем и отправляем на сервер, чтобы он принял и записал.

### Метаинформация

Мы умеем хранить метаинформацию для файлов. Это оказалось неожиданно полезно. Мы думали: обычный файл, пришёл, записали, и всё, здорово. А оказалось: раз уж мы его запилили, у нас стали появляться задачи — почему бы файлам не записать дополнительную метаинформацию, чтобы потом её где-то не искать. Например, где этот файл был приостановлен, на какого клиента, чтобы не искать это в домене, не искать это в URL — всю нужную нам метаинформацию прямо пишем её.

Это нас отчасти сильно выручает, и мы этим активно пользуемся.

### Метрики

Мы видим все метрики системы, потому что метрики реально выручают. Если у вас нет метрик, если вы не видите, что происходит внутри вашего ПО — это одна из многих задач, почему мы решаем некоторые вещи, потому что непонятно, что происходит.

Это очень круто: помимо простых алертов, которые есть, иногда можно посмотреть глазами и увидеть проблему, которые возникают периодически. Можно из этого наблюдать аномалии, потому что не всегда понятно, что происходит.

Например, если мы просто собираем метрики операционной системы, там может быть всё очень хорошо. У нас такой случай был раньше: мы покупали железо обычно одинаковое, когда можно было покупать железо. Потом начались проблемы с закупками, это было до 2022 года, проблемы с железом начались гораздо раньше у всех, потому что стала его нехватка. Поэтому потом это всё усугубляется.

Если раньше мы покупали серверы одного типа, их одинаково настраивали. Теперь у нас появились старые, разные серверы, разные жёсткие диски. Хорошо, что это на софте, поэтому можно использовать оборудование разных вендоров.

Всё хорошо, но один сервер у нас настроили как-то криво. Потому что мы не используем рейды — они нам во-первых не нужны, во-вторых от них большой overhead. Но у нас умудрились при настройке, при setup нового сервера настроить его так, что мы стали использовать историю с RAID-контроллером, который находился на нём.

И если трафик на сервер стал около 10 гигабит, что в принципе немного для нас, серверы отдавать начинались чудеса. Чудеса проявлялись совершенно другим образом: клиент написал, говорит, у меня какие-то проблемы с таймаутами, у меня контент долго отдаётся.

На сервере полно свободной памяти, всё нормально по CPU, но ползёт I/O, и мы видим, что скорость I/O на этом сервере плавает. Мы коррелируем с трафиком и понимаем, что так быть не должно.

В итоге в чём была история: мы давали на конкретный диск системы нагрузку, эти 10 гигабит давались большей части с одного диска. Понятно, что с диска столько не отдать, он отдавался из операционной системы, тем не менее, но эта хардварная штуковина, которая была настроена, она это дело не тянула и выбивала вообще весь сервер. У нас начинались проблемы с сетевой подсистемой, с дисковой подсистемой.

В итоге перестали его использовать, поставили как всё стало нормально. Поэтому метрики важны.

## Возвращаемся к Go

Вернёмся к Go, потому что конференция про Go, а не только про интересные штуки.

### Почему не стандартный HTTP-сервер

Когда мы начинали проектировать нашу систему, мы сразу же отказались от стандартного HTTP-сервера. Он в Go очень неплохой, как и многое из стандартной библиотеки. Что очень хорошего есть в Go — у него очень хорошая стандартная библиотека, и она реально крутые интерфейсы. Когда ты пишешь потом свой код, ты не хочешь делать сильно хуже. Поэтому зачастую получается неплохо, с разным переменным успехом, но тем не менее.

Почему мы не использовали стандартный HTTP-сервер? Он не имел возможностей для наших задач. Количество RPS у нас не такое большое — сервер может обработать пару десятков тысяч, стандартный, вероятно, выдержит.

Но у нас очень много контента, который мы передаём. Соответственно нам нужно практически на всё CPU. Это кстати Go — если у него была другая модель работы с памятью, такой бы истории не было, но что есть, то есть.

Мы шируем TCP-коннекты. У нас своя логика, просто у нас пул открытых коннектов, таймауты свои, и проще нам, мы понимаем, как их лучше подстроить, и стандартно этого точно не даст.

У нас естественно кэш открытых файлов, потому что файлы открывать туда-сюда очень дорого, особенно когда у вас 1000 запросов могут прийти.

И у нас есть zero-copy. Про zero-copy будет отдельный доклад, здесь не будем углубляться, но давайте расскажу историю затравки.

### Прокси и zero-copy

У нас есть прокси. Что делает прокси? Он принимает трафик, разбирает HTTP-запрос, отправляет его по TCP, берёт nginx и отправляет его выше. Казалось бы просто[^zero-copy-details].

Парсеры в стандартной библиотеке неплохие, но нас напрягала история: нам важно не только много контента, нам важно отдать его быстро, и тем более получить первый байт клиенту — за скорость. Медленный CDN мало кому нужен, даже если через него можно отдать много трафика.

Смотрим на реквесты и понимаем, что у нас что-то не так. Много — 200 миллисекунд по децилям процентили, много.

Используем pprof, смотрим. Потом смотрим глазами, что мы делали. У нас свой веб-сервер простой написанный, потому что мы видео отдаём по HTTP 1.1, там никакого блокирования запросов нет — пришёл коннект, открыли, начали лить туда контент, всё просто.

Приходит запрос, мы обычно стандартным разбираем HTTP, парсим, получаем его, выбираем по какой-то логике backend, TCP-соединение, и в это соединение пишем. Здесь проблем нет.

Запросы обычно приходят очень маленькие, заголовки и всё, больше ничего нет. Мы получаем response и просто делаем response, который есть, у него есть метод Write, и мы пишем в Connect, и в принципе всё здорово.

Мы получили response, получили с него данные, сняли метрики, записали нужную нам историю, которая там с него была нужна, и отправили клиенту и забыли. И вот 200 миллисекунд — это кстати если вы используете какой-то сервер, написанный на Go, особенно который говорит, что он очень производительный, там трафик, они используют стандартные из Go, этот прокси, это можете потом кстати сделать, если захотите.

Одна проблема: стандартный не отправляет, условно то, копирует в Connect данные из-под себя. Он копирует их, копирует сначала в память, то есть из user space мы поднимаем, обычный подход. Такого можно избежать.

В Go есть интерфейс `io.Reader`, который может реализовывать дополнительные методы. Это либо `Seek`, если мы работаем с файлами, либо `WriteTo`, если мы работаем с сетью. Внутри Go проверяет интерфейс, и если он совпадает, использует оптимизированный путь отправки.

Но в HTTP ResponseWriter стандартном настолько далеко Body во что-то запихнуть, что до него не достучаться, что он соответствует этому интерфейсу. Поэтому там идёт стандартный Read loop, и мы получаем эту историю.

Насколько я помню. У нас прокси выглядит так, когда он передаёт несколько гигабит в секунду — это потребление памяти приложения и его response, после особенно zero-copy мы память практически не используем.

При zero-copy мы говорим операционной системе: вот один дескриптор, вот другой дескриптор, сама разберись. Мы так делаем и для файлов, и для соединений. Поэтому здесь мы не попадаем под влияние Go runtime — не боремся с garbage collector, не создаём лишних объектов. Отдали и забыли.

Если нет бизнес-логики, то же самое. Если мы знаем, сколько нам нужно данных прочитать, лучше прочитать сразу столько. Потому что если мы читаем по чуть-чуть, то это огромное количество syscall'ов. Так только последняя запись на диск уже говорил, пишем только последовательно, поэтому мы можем использовать HDD, поэтому у нас стоимость решения в деньгах сильно ниже. Поэтому можем потратить эти деньги на костыли решения, а дальше их масштабировать просто в такие машинки. Получается выгодно и походили в удовольствие, и компания получила деньги.

## Сложности

Сложности — куда уж без них. Если мы говорим о Go, краеугольный камень — это работа с памятью в Go.

### Работа с памятью

В Go мы руками не работаем с памятью, почти, но сейчас арены появились. Но это нельзя сказать, что это работа с памятью — идея на самом деле старая, давно висело, чтобы можно было выделить область памяти, куда всё запихать, и чтобы garbage collector на неё не ходил, а потом разом всё хлопнуть. Для ряда вещей О'кей.

Но собственно Garbage Collector — это такая круговая штука, из-за которой идут потом все проблемы. Никаких сложных структур в памяти в нашем случае сразу же говорю. Вполне себе для ваших решений это может подойти.

Когда мы стартовали, у нас было много объектов в памяти — десятки миллионов. Мы написали дерево, чтобы хранить индекс в памяти. Всё работало достаточно быстро.

Количество объектов в памяти увеличилось, увеличилось, увеличилось, потом прошёл GC, бум, и нам ударило по CPU, и паузы пошли, и соответственно всё это работать перестало.

Самое смешное: пытались инженерить сначала и подумать, как ещё там, на самом деле простой был, как с этим быть, и пытались там написать на C, потом забить, но это неудобно деплоить и ещё всякие истории.

В итоге просто взяли обычный `map` и записали ключ-значение — и всё заработало.

Нужен `sync.Pool`: мы выделяем память и не отдаём её сразу. Если у нас есть объект или байты, которые можно переиспользовать, храним их в `sync.Pool`, чтобы garbage collector не пытался их вычищать — мы переиспользуем их постоянно.

Поэтому у нас каких таких больших проблем с памятью нет.

## TLS и производительность

С какого-то момента весь трафик передаётся шифрованный, и соответственно мы написали своё решение. Хотелось бы подключить сертификат и поехать — мы всё равно бы написали свой веб-сервер, написали там работу с этой штукой, и почему бы нет, попробовали, всё работает с коробки, прям хорошо, отличный интерфейс, касаемо именно стандартной библиотеки интерфейсов[^tls-performance].

Причём не только стандартная библиотека, но на самом деле много библиотек, которые основаны, они очень хорошо сделаны. Я не имею в виду внутренность, именно интерфейс очень круто, с ним приятно работать, и там видно опыт. Например мне кажется, пак занимался, насколько я не помню, по большей части, у чувака дофига опыта, поэтому он опыт взял туда перенёс, это реально круто сделано.

Динамический выбор сертификатов — мы реально можем написать хранилище какой-то сертификат и без всяких перезагрузок подменять сертификаты, это прямо очень удобно было бы для нас, и прямо прекрасно.

Но есть некоторые проблемы: это очень медленно. Это реально очень медленно, если брать любые другие решения, то есть поставить терминатор, nginx-прокси либо ещё что-нибудь, Go проиграет, причём проиграет очень сильно.

Если вы занимаетесь, если вы пытаетесь отдать много трафика, это будет плохо, там даже не какие-то проценты, это прямо разы может быть, у вас съест весь CPU, совсем.

Всё у нас было плохо, потому что если по профилировать, то опять же там пошли бинты, пошло куча памяти, к вам пришёл GC, он вам помог.

### Решение: kTLS

Есть решение — если мы говорили о копиях, и соответственно когда можем что-то делегировать операционной системе, то в какой-то момент в Linux, и не только в Linux, появилась история с kTLS. TLS тоже самое, ядро сейчас понимает, как работать с TLS.

Там достаточно современная версия, там 13, это нормально уже, там ещё лет восемь назад было не очень, сейчас совсем всё хорошо, практически у всех есть. Соответственно вы покрываете клиентов, причём подавляющее большинство.

Как это работает: у вас открывается socket, тестовый, внутри ядра, вы работаете с ним как обычно, вы ничего не видите. Вы просто скормили там сертификат, сертификат — набор байт, и он умеет. Причём настолько умеет хорошо, что если у вас, например, нормальные сетевые карты, там какие-то Intel, то вы можете терминатор не только в ядре, но вы можете терминатор трафик на сетевой карте.

Жутко производительно, если вам нужно дофига трафика обрабатывать. На самом деле там всё очень просто, там есть API, просто прилеп к сетевой карте, и тоже умеет TLS.

Казалось бы, вот оно счастье, и оно было очень близко, но его нет в Go. Мы первые озаботились с этой проблемой, есть issue на GitHub, причём самое смешное, что issue сделали чуваки из Google, которые написали другим из Google, которые пишут Go, они такие.

В общем, сейчас висит, если оно появится в Go, это будет всем прям профит, на самом деле, то есть одна из больших проблем, это решит кучу проблем для тех, кто занимается балансировкой трафика, а кто как и мы, например, занимается отдачей трафика, и это было бы прямо очень круто, но нет, и нет.

Притом есть на just for fun, попробовать, там человек в тот момент занимался как раз Go-разработкой, именно TLS, он у себя там в блоге выложил, что в принципе это работает, можно сделать, но production решения нет.

## Отдача из памяти: не всегда то, что кажется

Вернёмся к отдаче с памяти. У нас иногда возникают нестандартные ситуации.

Если обычно у нас есть некоторая сезонность трафика, в том числе по дням, по времени суток, то иногда возникают события большие, например, лайв-трансляции. Когда в тебя пролетает плюс 150 гигабит, например, это видно.

Бывает такое, что вот прилетела трансляция, а в этот момент ещё какая-то рекламная сетка начала раздавать трафик. Вот тебе ещё, например, 100.

И тут можно посмотреть интересное, когда такое случается. Такие случаи бывают, можно взять, включить pprof, потому что в Go одна из самых прекрасных штук — это профилирование, всё работает с коробки, взял, включил, ещё картинку вывел и прекрасно.

В этот момент мы примерно отдавали из памяти и из диска одинаковое количество данных. Но насколько мы видим, из памяти мы сильно провисали. Казалось бы, из памяти быстро, а но не всегда то, что кажется, на самом деле так и есть.

Мы очень сильно провесали, где если мы отдаём из памяти, то мы копируем из памяти Go, из user space памяти в kernel space, дальше отдаём, оно там пишется. В случае отдачи с диска мы опять же используем zero-copy. Он кстати даже здесь есть, мы используем zero-copy и не тащим себе в память данные, чтобы потом снова их куда-то отдать.

Поняли свой косяк, поэтому сейчас как у нас будут выделены серверы, которые как раз для отдачи лайва, они стали ещё проще. Это опять же об ограничениях: мы из HTTP выкинули даже поддержку Range, то есть он вообще ничего не умеет, умеет взять запрос, никак не думать, что там Range пришёл, не Range пришёл, там какую-то часть файлика и какую-то часть файлика он хочет, прям взяли, отдали то, что есть, потому что мы понимаем, что там будет маленький кусочек лежать, который нужно отдать весь.

Сильно упростили. У нас нет persistent cache — при перезагрузке есть файл на диске. Кольцевой буфер: пишем с начала до конца, когда заканчивается, начинаем писать с начала и затираем старое. Вот и вытеснение, всё просто. Нет шардирования, очередей на запись — максимально простое решение.

## Итоги

Подведём итоги.

Если у нас получилось, то и у вас получится. На самом деле сложного нет, обычно проблемы, которые инженер встречает, они очень простые — какие-то базовые вещи.

Например, что нужно уметь: данные должны быть сортированы, окей, вы можете в них быстро найти. Данные должны быть фиксированного размера, поэтому вы можете эффективно их хранить на диске, там или в памяти, либо ещё где-то, быстро к ним получить доступ.

Вот ещё банально: любое решение, которое вы делаете, там должно быть аргументировано, нужно разбираться в том, что ты делаешь тоже. Казалось бы банально.

Нерешаемых задач на самом деле не существует. Мы пробовали сами — если есть какая-то задача, мы её решим, это может занять больше времени, иногда сильно больше времени. Иногда некоторые задачи не делаются за день, иногда за месяц, иногда даже за год, и это вполне себе нормально.

Если ценность решения есть, то можно его делать и два года. А если что-то не работает, это не всегда означает, что проблема в вас. Нужно профилировать — можно иметь огромный опыт и ошибиться на простейшем, это нормально.

В этом нас спасает, что с такими косяками метрики, которые мы собираем, у нас их много, и на всё профилирование, это всё видно. В Go это прям даёт огромный профит.

Все врут, нужно понимать: когда вы приходите на конференцию, читаете статьи, смотрите бенчмарки либо ещё какая-то история, зачастую там неправда, причём неправда может быть от начала и до конца. Нужно всё проверять, нельзя бы в что-то поставить, оно начнёт у вас работать, взять какую-то библиотеку и у вас там полетело, всегда встречаются какие-то косяки.

Встречается не то, как это работает, как это описано, и так далее. Опыт и понимание того, что если вы что-то к себе внедряете, можно выстрелить в ногу, причём даже об этом рассказали, что все у всех всё хорошо, не так, и потом придётся это править.

## Полезные материалы

- [Zero-copy в Linux: sendfile и splice](https://www.kernel.org/doc/ols/2005/ols2005v1-pages-19-28.pdf) — техническая статья о механизмах zero-copy и их применении для раздачи файлов
- [Linux Network Performance Ultimate Guide](https://ntk148v.github.io/posts/linux-network-performance-ultimate-guide/) — полное руководство по тюнингу сетевой производительности: настройки ядра, TCP, буферов и драйверов
- [HTTP/2 Prioritization with NGINX](https://blog.cloudflare.com/http-2-prioritization-with-nginx/) — как Cloudflare решает проблемы приоритизации HTTP/2 и оптимизирует раздачу контента
- [The Story of One Latency Spike](https://blog.cloudflare.com/the-story-of-one-latency-spike/) — практический пример диагностики проблем производительности: как искать узкие места в системе
- [Go pprof: профилирование производительности](https://go.dev/blog/pprof) — официальное руководство по использованию pprof для профилирования Go-приложений
- [Работа с памятью в Go: GC и оптимизации](https://go.dev/doc/gc-guide) — руководство по пониманию работы garbage collector и оптимизации использования памяти
- [ScyllaDB: работа с дисками в Linux](https://www.scylladb.com/2016/09/15/io-access-methods-scylla/) — практические советы по работе с дисками, mmap и его trade-offs от команды ScyllaDB
- [kTLS: Kernel TLS для Linux](https://www.kernel.org/doc/html/latest/networking/tls.html) — документация по kTLS, которая помогает решить проблемы производительности TLS в Go
- [Когда писать свой софт, а когда использовать готовый](https://blog.cloudflare.com/cloudflare-outage/) — размышления о балансе между собственными решениями и готовыми продуктами
- [DNS: основы и гео-маршрутизация](https://www.cloudflare.com/learning/dns/what-is-dns/) — как использовать DNS для маршрутизации трафика и построения CDN

> **Практическая заметка.** При разработке собственных решений важно понимать текущее решение и иметь чёткий список требований. Ограничения — это хорошо: они помогают фокусироваться на том, что действительно нужно, и не реализовывать лишнее. Метрики и профилирование критичны: без них невозможно понять, что происходит в системе. Источник: опыт разработки CDN, DNS и систем хранения данных.

## Сноски

[^cdn-details]: Подробнее о том, как мы строили CDN для раздачи контента с HDD и какие проблемы пришлось решать, см. [«Раздача контента с HDD»]({{< relref "talks/razdacha-kontenta-s-hdd.md" >}}).

[^zero-copy-details]: О том, как zero-copy работает в Linux и почему это критично для производительности, см. [«Разгоняем Go TLS до 100 Gbps»]({{< relref "talks/razgonyaem-go-tls-do-100-gbps.md" >}}) и [«Раздача контента с HDD»]({{< relref "talks/razdacha-kontenta-s-hdd.md" >}}).

[^tls-performance]: О проблемах производительности TLS в Go и решении через kTLS см. [«Разгоняем Go TLS до 100 Gbps»]({{< relref "talks/razgonyaem-go-tls-do-100-gbps.md" >}}). О проблемах с TLS в контексте раздачи контента см. также [«Раздача контента с HDD»]({{< relref "talks/razdacha-kontenta-s-hdd.md" >}}).
