---
title: "Нет времени объяснять, программируй!"
date: 2024-10-29
description: "Практический опыт разработки собственных решений в Kinescope: когда и почему стоит писать свой софт вместо использования готовых продуктов, примеры из практики (CDN, DNS, хранение данных) и работа с Go."
tags: ["go", "golang", "разработка", "инфраструктура", "cdn", "производительность", "kinescope", "zero-copy", "tls"]
---

Расскажу про опыт разработки собственных решений в Kinescope: когда стоит писать свой софт, какие проблемы это решает и какие сложности возникают.

{{< youtube id="ZC2RviwLgdo" title="Нет времени объяснять, программируй! / Кирилл Шваков, Kinescope" >}}

## TL;DR

- **Сначала используйте готовое, потом пишите своё**: на старте проекта важны сроки, не стоит начинать с разработки с нуля.
- **Реальная необходимость — главный критерий**: пишите свой софт, когда существующие решения не решают ваши конкретные проблемы и вы не можете их исправить.
- **Понимание текущего решения обязательно**: если не понимаете, как работает то, что используете, не сможете написать лучше.
- **Ограничения — это хорошо**: они помогают фокусироваться на том, что действительно нужно, и не реализовывать лишнее.
- **Метрики и профилирование критичны**: без них невозможно понять, что происходит и где проблемы.
- **Стандартизация — ключ к масштабированию**: единые шаблоны, библиотеки и практики позволяют быстро создавать новые сервисы без изобретения велосипедов.

## Вступление: что означает «нет времени объяснять»

Доклад должен был быть про технологии, но получился больше про процессы и решения. В Kinescope мы пишем очень много софта сами — иногда даже того, который, казалось бы, писать не нужно, потому что он уже есть.

Сейчас у нас много собственных решений: DNS, CDN, система хранения контента, различные библиотеки для работы с медиаформатами, шаблоны сервисов, утилиты для работы с секретами. Это всё написано либо полностью с нуля, либо используя какие-то библиотеки, но не коробочные продукты.

**«Нет времени объяснять»** — это не про хаос и спешку. Это про скорость через ясность: когда вы понимаете проблему настолько глубоко, что объяснение займёт больше времени, чем решение. Когда у вас есть экспертиза, команда и понимание ограничений — можно просто взять и сделать.

Это не значит, что мы пишем всё подряд. Наоборот: мы очень консервативны в выборе того, что стоит делать самим. Но когда решение действительно нужно и готовое не подходит — мы не тратим время на долгие обсуждения, а просто делаем.

## Контекст: откуда мы стартовали

Так было не всегда. Когда проект только разрабатывается, не стоит начинать делать что-то из головы — мы так не делали.

Если вернуться назад, то был 2020 год. Все ждали Олимпиаду в Токио, а мы начинали писать Kinescope. В тот год все сидели по домам, и мы писали.

### Что важно на старте проекта

При запуске проекта важны **сроки**. Мы были в состоянии стартапа, нам нужно было быстро запуститься, и точно мы не будем что-то ставить сами.

Как этого добиться? Достаточно просто:

1. **Понятные цели и задачи** — мы прекрасно понимали, какой должен быть продукт и что он должен делать. У нас было понимание задач, потому что мы и до Kinescope занимались чем-то похожим.

2. **Надёжная опытная команда** — команда была до Kinescope, и мы двинулись в этот проект с надёжными проверенными людьми.

3. **Проверенные технологии** — мы не стали ничего думать, посмотрели, с чем работали до этого, что хорошо знаем, и стали это использовать.

### Наш начальный стек

Если говорить про команду, я уже сказал — она у нас была. Но если у вас надёжная команда, это не значит, что не будет проблем. У нас есть архитектурные проблемы, кто-то что-то забыл, не подумал, что-то сделал. Но самое главное по опыту — с чем мы сталкиваемся:

**Разработчики не знают SQL и не умеют думать о базе данных.** Из этого вылезает самое большое количество проблем. Поэтому хотелось бы, помимо знания какого-то языка программирования, чтобы знали что-то ещё.

Мы взяли проверенные технологии. DNS — естественно нужен был какой-то гео-DNS, мы взяли Google DNS. Важное уточнение: у нас своё железо было изначально, то есть мы не используем никакой cloud. У нас своя железная платформа, мы находимся в нескольких дата-центрах, и это было практически с самого старта проекта.

Поэтому у нас BGP/anycast на точках, на машинах, которые анонсируют, стоят Bird, под ними стоит nginx, под nginx написаны приложения на Go. Это общается с PostgreSQL для аналитики, у нас был ClickHouse для хранения логов. Также у нас есть очереди и другие компоненты.

Достаточно классический стек, с которым мы работали и до этого. Это FreeBSD и nginx — это хорошая связка, её в своё время использовал Netflix. Сейчас есть компании, которые тоже занимаются видео, и они тоже используют FreeBSD.

## Что получилось

Всё получилось — серьёзных проблем не было.

Если отмотать в 2020 год и чуть позже, мы рассказывали, что мы платформа для интернета, объединяем технологии. Сейчас мы выглядим так: у нас большое количество клиентов, в 2023 году нас очень многие используют. Если вы пользуетесь интернетом, то с высокой вероятностью вы так или иначе пользуетесь нами — не только нами, но где-то видите видео, которое раздаётся, где-то смотрите онлайн-трансляции, которые раздаются через нас.

## Рост и новые задачи

Мы начали расти. Рост бывает разный, и у нас он случился. У нас начали появляться новые клиенты, сформировалась база. Вместе с клиентами к нам пришла нагрузка, и она начала расти.

У нас практически не поменялась команда — не сильно. Стало больше разработчиков, которые занимаются фронтендом и плеерами, стало больше дизайнеров. Но команда как таковая не сильно росла. Она выросла в очень хорошем направлении: появился человек, который занимается медиаформатами на Go. Это нам на пользу.

Задачи стали расти. Бизнес растёт, поддержка нужна. Вроде бы всё хорошо, но времени не хватает — работаем над задачами, обслуживаем клиентов.

## Когда писать своё: decision framework

Где в этом месте взять время или зачем что-то переписывать? Если оно работает, работает относительно неплохо, приносит деньги — зачем ввязываться в разработку какого-то кастома, который можно взять и поставить?

### Почему появляется необходимость писать свой софт

Зачем вообще появляется необходимость что-то написать? Это может быть хобби, обучение, развитие. Иногда так и делают просто потому, что могут. С этим мы тоже сталкиваемся, причём не только в российском сообществе, но и с иностранными компаниями, даже очень большими.

**Реальная необходимость** у нас была. Реальная необходимость возникает не только у нас. Иногда из этого вырастают очень хорошие серьёзные продукты, которыми мы пользуемся, а потом отказываемся и пишем что-то своё.

Хорошие примеры: Nginx появился под реальные задачи, писался людьми, которые сталкивались с проблемами и решали их. ClickHouse — та же история. ScyllaDB и InnoDB — отличные решения, их любят все, даже те, кто пользуется PostgreSQL, потому что это произведение искусства. Советую почитать код, если интересно занимаетесь базами данных или работой с дисками — это хороший материал для изучения.

ScyllaDB тоже образец инженерного искусства, как и многое, что они делают, включая фреймворки, которые выпускают.

### Критерии принятия решения

Как понять, что время пришло что-то взять и переписать? У вас должна быть какая-то проблема, и существующее решение не устраивает.

Нельзя сказать «он меня не устраивает, мне не нравится, потому что у него логотип зелёный» — это не аргумент. Нужно назвать конкретные проблемы, с которыми вы столкнулись, и главное — вы не можете это решить никаким способом. Компетенции не хватает, например, в языке или экосистеме. Вы не можете там что-то сделать, не можете поправить, потому что архитектурно это не проблема софта, который вы используете — архитектура не позволяет внести коррективы, которые нужны только вам, нет API.

**Критерии, которые мы используем:**

1. **Нагрузка и производительность**: существующее решение не справляется с вашей нагрузкой, и оптимизация не помогает.
2. **Латентность**: требования к задержкам не выполняются, и это критично для бизнеса.
3. **Стоимость**: готовое решение слишком дорогое (лицензии, инфраструктура, поддержка).
4. **Экспертиза**: у вас есть команда, которая может написать лучше или адаптировать под ваши нужды.
5. **Риски**: зависимость от внешнего решения создаёт риски (vendor lock-in, изменения в API, прекращение поддержки).
6. **Уникальные требования**: вам нужна функциональность, которой нет в готовых решениях и которую нельзя добавить.

**Красные флаги (когда НЕ стоит писать своё):**

- Нет конкретной проблемы — просто «хочется попробовать».
- Нет экспертизы в области — вы не понимаете, как работает текущее решение.
- Нет времени на поддержку — написать проще, чем поддерживать.
- Готовое решение покрывает 90%+ ваших потребностей — остальное можно решить костылями.
- Команда слишком маленькая — не хватит ресурсов на разработку и поддержку.

### Trade-offs: build vs buy

```text
┌──────────────────────────────────────────────────────────────┐
│                    Build vs Buy                              │
├──────────────────────────────────────────────────────────────┤
│                                                              │
│  Писать своё, если:              Использовать готовое, если: │
│                                                              │
│  ✓ Уникальные требования          ✓ Стандартные задачи       │
│  ✓ Критичная производительность   ✓ Время важнее             │
│  ✓ Нет подходящего решения        ✓ Есть проверенное         │
│  ✓ Есть экспертиза                ✓ Нет экспертизы           │
│  ✓ Долгосрочная перспектива       ✓ Быстрый прототип         │
│  ✓ Контроль критичен              ✓ Готовы к компромиссам    │
│                                                              │
└──────────────────────────────────────────────────────────────┘
```

**Важно**: решение не всегда бинарное. Часто правильный подход — взять готовое и адаптировать, или написать только критичную часть, используя готовые компоненты.

### Что должно быть на момент принятия решения

**Понимание, как работает текущее решение.** Если вы не понимаете, как работает текущее какое-то решение, софт, который вы используете, то вы не сможете написать что-то лучше, изменить, поправить. Это логично, но не всегда это так на удивление.

> **Практическая заметка.** Перед тем как писать собственное решение, важно глубоко понять текущее. Это не только про чтение документации, но и про изучение исходного кода, профилирование и понимание архитектурных решений. Без этого понимания легко создать решение, которое будет хуже существующего. Источник: опыт разработки собственных решений в Kinescope.

**Понятный список требований** — описание того, что должно получиться. ТЗ и документация не должны появиться только после того, как вы что-то разрабатываете. Это комплексный процесс — нельзя просто сидеть вечером и писать с нуля. У вас всегда есть зарисовки на салфетке, планы, диаграммы — это нормально.

**Должен быть список ограничений.** Когда вы разрабатываете технологию под бизнес, у вас должно быть понимание, что решение может не решить, или что можно выкинуть. Ограничения — это хорошо, и мы ими активно пользуемся в наших решениях, потому что выкидываем много того, что нам не нужно, и не реализуем лишнее.

## Принципы инженерии: как мы строим решения

Когда мы пишем своё, мы следуем нескольким ключевым принципам, которые помогают создавать решения, которые действительно решают проблемы, а не создают новые.

### Унификация: один сервис — один бинарник

Один из самых важных принципов — **унификация**. Каждый сервис — это один бинарный файл, который содержит всё необходимое. Нет зависимостей от интерпретаторов, библиотек или конфигурационных файлов, которые нужно устанавливать отдельно.

Это не только про простоту деплоя, но и про предсказуемость: если сервис работает на одной машине, он будет работать и на другой. Если вы знаете, как работает один сервис, вы понимаете, как работают все остальные.

### Минимизация слоёв и точек отказа

Каждый дополнительный слой — это дополнительная точка отказа, дополнительная задержка, дополнительная сложность в отладке. Мы стараемся минимизировать количество слоёв между клиентом и данными.

Это не значит, что мы отказываемся от балансировщиков или прокси — они нужны. Но мы не добавляем их просто так, «на всякий случай». Каждый компонент должен решать конкретную задачу, и если его можно убрать без потери функциональности — мы его убираем.

### Наблюдаемость как контракт

Если вы не видите, что происходит внутри вашего сервиса, вы не можете понять, почему он работает медленно или падает. Поэтому **наблюдаемость** — это не опция, а обязательное требование.

Каждый сервис должен экспортировать:
- **Метрики** (Prometheus) — производительность, ошибки, использование ресурсов
- **Логи** (структурированные) — что происходит, с каким контекстом
- **Health checks** — готов ли сервис принимать трафик

Без этого вы летите вслепую. Подробнее о том, как мы строим наблюдаемость, см. в статье [«Эксплуатация без K8s»]({{< relref "talks/ekspluatatsiya-bez-k8s.md" >}}).

### Ограничения как преимущество

Ограничения — это не недостаток, а преимущество. Когда вы знаете, что ваше решение НЕ делает, вы можете:
- Упростить код, убрав ненужную функциональность
- Оптимизировать под конкретные сценарии использования
- Сделать решение быстрее и надёжнее

Например, наш CDN для лайва не поддерживает HTTP Range — потому что нам это не нужно. Это позволило упростить код и сделать его быстрее.

## Кейсы: что мы пишем сами и почему

Теперь расскажу про конкретные примеры того, что мы написали сами, какие проблемы это решало и какие уроки мы извлекли.

### Кейс 1: Шаблоны сервисов — стандартизация как основа масштабирования

**Проблема**: когда у вас десятки сервисов, каждый из которых делает что-то своё по-своему, поддержка превращается в кошмар. Разные подходы к конфигурации, логированию, метрикам, обработке ошибок — всё это усложняет жизнь и разработчикам, и операторам.

**Почему готовое не подошло**: готовых шаблонов для Go-сервисов много, но они либо слишком общие (не учитывают наши практики), либо слишком специфичные (заточены под конкретный фреймворк). Нам нужен был баланс: достаточно гибкий, чтобы покрыть разные типы сервисов, но достаточно стандартизированный, чтобы все сервисы работали одинаково.

**Решение**: мы создали набор шаблонов сервисов (`dev/templates`), которые стандартизируют:
- Структуру проекта (handler → service → module)
- CLI флаги и конфигурацию (через `urfave/cli`)
- Работу с секретами (через `go/vault`)
- Метрики и логирование (Prometheus, Logrus)
- Сборку и деплой (Makefile, `spec.yml`)

У нас есть три типа шаблонов:
- **HTTP Service** — для REST API
- **gRPC Service** — для gRPC сервисов
- **Common Service** — для фоновых задач и workers

Каждый шаблон включает:
- Готовую структуру проекта
- Примеры обработчиков и бизнес-логики
- Интеграцию с базой данных (PostgreSQL, ClickHouse)
- Метрики и health checks
- Makefile для сборки и тестирования
- `spec.yml` для описания деплоя

**Эксплуатация**: когда нужно создать новый сервис, разработчик просто клонирует шаблон, запускает bootstrap-скрипт, и получает готовый каркас со всеми стандартными практиками. Это экономит время и гарантирует, что все сервисы работают одинаково.

**Цена решения**: поддержка шаблонов требует времени, но это время окупается за счёт того, что новые сервисы создаются быстрее и работают предсказуемее. Когда мы обновляем шаблоны (например, добавляем новую практику), все новые сервисы автоматически получают эти улучшения.

### Кейс 2: Секреты через Vault + env — безопасность без сложности

**Проблема**: секреты (пароли, API ключи, токены) нужно хранить безопасно, но при этом они должны быть доступны приложению при запуске. Классические подходы (хранить в файлах, передавать через переменные окружения в открытом виде) небезопасны. Использование внешних систем типа HashiCorp Vault добавляет сложность и зависимость.

**Почему готовое не подошло**: готовые решения либо слишком сложные (требуют отдельной инфраструктуры), либо слишком простые (не решают проблему безопасности). Нам нужно было что-то среднее: безопасно, но без лишних зависимостей.

**Решение**: мы используем **Ansible Vault** для шифрования секретов и библиотеку `go/vault` для их расшифровки в приложении. Вот как это работает:

1. **Шифрование**: секреты шифруются через Ansible Vault и кодируются в base64 для безопасной передачи через переменные окружения.
2. **Встраивание пароля**: при сборке бинарника пароль для расшифровки вшивается в бинарник через `-ldflags`.
3. **Расшифровка**: при запуске приложение автоматически расшифровывает переменные окружения, используя вшитый пароль.

Пример использования:

```go
package main

import (
    "os"
    "strconv"
    
    vault "gitlab.kinescope.dev/go/vault"
    "github.com/urfave/cli/v2"
)

var vaultPassword = "" // Вшивается при сборке через -ldflags

func main() {
    skipDecrypt, _ := strconv.ParseBool(os.Getenv("SKIP_DECRYPT"))
    
    app := &cli.App{
        Flags: []cli.Flag{
            vault.DSNFlag{
                Name:        "postgres-dsn",
                EnvVar:      "POSTGRES_DSN",
                Value:       "postgres://{{encrypted_username}}@host:5432/db",
                Password:    vaultPassword,
                SkipDecrypt: skipDecrypt, // Для локальной разработки
            },
        },
        // ...
    }
}
```

В `spec.yml` зашифрованные секреты записываются прямо в `environments`:

```yaml
environments: |
  POSTGRES_DSN=postgres://{{vault_encrypted_base64}}@host:5432/db
  API_KEY={{vault_encrypted_base64}}
```

При сборке через Makefile пароль передаётся через `ldflags`:

```makefile
VAULT_PASSWORD ?=""
LDFLAGS := -X 'package/action.vaultPassword=$(VAULT_PASSWORD)'
```

**Эксплуатация**: секреты хранятся в зашифрованном виде в Ansible inventory, при деплое они подставляются в `spec.yml`, а приложение автоматически их расшифровывает. Для локальной разработки можно использовать `SKIP_DECRYPT=true`, чтобы работать с незашифрованными значениями.

**Цена решения**: библиотека `go/vault` простая и поддерживается нами же. Интеграция с Ansible Vault позволяет использовать существующую инфраструктуру для управления секретами без добавления новых зависимостей.

Подробнее о работе с секретами см. в статье [«Эксплуатация без K8s»]({{< relref "talks/ekspluatatsiya-bez-k8s.md" >}}).

### Кейс 3: CDN — когда nginx перестал справляться

У нас есть CDN. Казалось бы, простая штука — поставили nginx, и оно работает. Мы поставили nginx, поставили FreeBSD, и это всё работает. Проблем нет почти. Стандарт на то время, просто надёжно, производительно, можно допиливать при желании.

Для видеоконтента, которым мы занимаемся, у нас так и было: поставили nginx, поставили модули, всё работало. Но в какой-то момент нам стало этого не хватать[^cdn-details].

Новые клиенты появились, появились новые потребности, и хочешь этого не хочешь, так как ты находишься в бизнесе, это нужно решать и услужить всем.

#### Проблемы с nginx

С чем мы столкнулись с nginx после того, как начали писать всё это дело на Go:

- **Проблемы с ростом количества объектов в кэше** — особенно если вы используете его просто как прокси-кэш, оно сойдёт с ума. Это неплохой nginx, просто он не под эти задачи заточен — у него другой профиль.

- **Решаемо с костылями** — ничего страшного, так многие работают, но сегментировать трафик сложно.

- **Сложно отправлять поток метрик и логов** — запросы мы должны знать о них: сколько данных мы передали, какой это был клиент, какой это его проект, что это за медиаформат. Нужные метрики тоже сложно добавить.

#### Альтернативы

Стали искать альтернативы. Альтернатива есть — Varnish, его используют Fastly, сильно допилили, штука реально хорошая, особенно для лайва.

Вроде бы ничего, но у Varnish нет хорошего движка хранения, он использует mmap со своими проблемами. Если у вас контента больше, чем оперативной памяти, то у вас проблемы. Вопрос с метриками и логами — он достаточно открыт, но нужно допиливать.

Он написан на C, а у нас команда пишет на Go, у нас всё написано на Go. Были бы специалисты, которые его допиливают — это размытие стека технологий, риски удорожания проекта. Поэтому берём, пишем свой.

#### Что мы сделали

Чтобы решить нашу проблему, мы разделили муху от котлет. У нас есть серверы, которые умеют читать с диска и отдавать контент (если утрированно).

Есть прокси-серверы, которые принимают трафик. Есть менеджер, с которым общаются и получают информацию, зоны, настройки — чтобы всё обновлялось. И есть коллектор, который принимает поток логов.

Прокси принимает трафик и отправляет в нужный шард. Она умеет разобрать HTTP и направить туда, куда нужно. Умеет делать феры нормально, потому что есть различные правила, куда мы должны отправить трафик, если, например, под нами сервер лежит.

И есть метрики — мы понимаем, что происходит, и можем сразу вклиниться, если наш софт как-то ведёт себя не так, то мы сразу запиливаем и решаем. На метриках можем повесить алерты. У нас есть дашборд на весь наш софт, который мы пишем, есть там алерты и прочее.

#### Архитектура собственной CDN

```text
                    ┌─────────────┐
                    │   Client    │
                    └──────┬──────┘
                           │
                           v
              ┌─────────────────────┐
              │  Proxy (Edge)       │
              │  - HTTP parsing     │
              │  - Routing rules    │
              │  - Sharding         │
              └──────┬──────────────┘
                     │
        ┌────────────┼────────────┐
        │            │            │
        v            v            v
┌─────────────┐ ┌──────────┐ ┌───────────┐
│  Storage    │ │ Manager  │ │ Collector │
│  (Shards)   │ │          │ │           │
│             │ │ - Zones  │ │ - Metrics │
│ - Read disk │ │ - Config │ │ - Logs    │
│ - Serve     │ │ - Updates│ │ - Alerts  │
└─────────────┘ └──────────┘ └───────────┘
```

Разделение ответственности: прокси — маршрутизация, storage — чтение с диска, manager — конфигурация, collector — метрики и логи.

#### Хранение данных

Само хранилище — достаточно простая штука, написано на Go.

Что мы сделали, чтобы решить проблемы с мелкими файлами: мы решили для себя, что каждый диск у нас по большому счёту — это просто блочное устройство, на котором один файл. Там несколько терабайт.

У нас есть индексы в памяти, чтобы можно было быстро понять, на каком диске это лежит, открыть файл и отправить его — открыть нужное место в файле, сделать seek и отдать.

Это общая очередь на запись — это важно, чтобы уметь работать с HDD. У нас это очень просто сделано — вот прелесть Go, что там есть очень простые решения, которые на других языках сложно реализовать.

Здесь хорошо, что в Go есть горутины — это очень сильно. Когда мы поднимаем какой-то файл: у нас есть он, например, в кэше, его нет на сервере, пришёл запрос. Мы видим, что нет, начинаем его скачивать, скачали, помещаем его в рутину — это общая очередь. Каждое устройство слушает эту рутину, какое из них свободно, то начинает писать, чтобы уметь работать с обычными дисками.

Почему SSD: потому что это дешевле. Если использовать SSD, мы будем работать лучше. Если не использовать SSD, всё равно всё работает хорошо. У нас на рынке один из самых низких latency-расходов.

Мы умеем делать batch из chunks, потому что у нас бывает поток, например, лайва, которая сейчас идёт — это поток маленьких файлов. Чтобы не было рандомного чтения слишком большого, мы пересунули, немножко храним в памяти, потом их склеиваем и одним batch пишем на диск. Получается неплохо — мы сильно оптимизировали историю с рандомным чтением диска.

Мы умеем раздавать из памяти. Казалось бы тоже хорошая история, но чуть позже вернёмся — не всегда то, что кажется хорошо.

Подробнее о том, как мы строили CDN для раздачи контента с HDD, см. в статье [«Раздача контента с HDD»]({{< relref "talks/razdacha-kontenta-s-hdd.md" >}}).

### Кейс 4: Storage — доменная сложность и управляемость

**Проблема**: нам нужна система хранения файлов, которая умеет работать с большими объёмами данных, автоматически балансировать нагрузку между дисками, обрабатывать отказы дисков и обеспечивать высокую доступность. Готовые решения (Ceph, MinIO) либо слишком сложные для наших задач, либо не дают нужной управляемости.

**Почему готовое не подошло**: Ceph — отличная система, но она решает задачи, которые нам не нужны (распределённое хранение с репликацией между серверами). Нам нужна более простая модель: каждый сервер хранит свои файлы локально, а балансировка идёт на уровне приложения. MinIO ближе, но у него другие приоритеты (S3-совместимость), и нам нужны специфичные оптимизации для нашего случая.

**Решение**: мы написали свой storage-сервис (`kineceph`), который:
- Автоматически обнаруживает и монтирует диски
- Использует алгоритм взвешенной случайности для выбора диска при записи
- Обрабатывает отказы дисков и автоматически переподключает их
- Хранит метаданные в PostgreSQL
- Поддерживает объединение видео и аудио дорожек
- Имеет отдельные backend и frontend API (frontend только для чтения, с CORS)

**Алгоритм выбора диска**: система использует взвешенную случайность, где вес диска рассчитывается на основе свободного места и текущей нагрузки. Это обеспечивает равномерное распределение нагрузки и быстрое использование новых дисков.

**Эксплуатация**: сервис автоматически управляет дисками, не требуя ручного вмешательства. Метрики показывают состояние каждого диска, что позволяет быстро диагностировать проблемы.

**Цена решения**: разработка заняла время, но результат даёт нам полный контроль над системой хранения и возможность оптимизировать под наши конкретные задачи.

### Кейс 5: DNS — гео-балансировка и автоматизация

**Проблема**: нам нужен DNS-сервер, который умеет:
- Гео-балансировку на основе местоположения клиента
- Health checks для автоматического исключения неработающих серверов
- Failover groups для переключения на резервные записи
- Автоматическую выдачу сертификатов Let's Encrypt через DNS-01

Готовые решения (BIND, PowerDNS) либо не поддерживают нужную функциональность из коробки, либо требуют сложной настройки и интеграции.

**Почему готовое не подошло**: BIND — классический DNS-сервер, но он не умеет гео-балансировку и health checks без сложных плагинов. PowerDNS ближе, но интеграция с нашей инфраструктурой (PostgreSQL, метрики) требует дополнительной работы. Нам нужен был сервер, который работает именно так, как нам нужно, без лишней сложности.

**Решение**: мы написали свой DNS-сервер (`kinescope/dns`), который:
- Поддерживает гео-записи на основе MaxMind GeoIP2-City
- Выполняет health checks и автоматически исключает неработающие серверы
- Поддерживает failover groups для переключения на резервные записи
- Автоматически обрабатывает DNS-01 челленджи для Let's Encrypt
- Экспортирует метрики в Prometheus
- Поддерживает UDP, TCP и DNS-over-TLS

**Конфигурация через HCL**: зоны описываются в HCL-файле, что позволяет легко управлять конфигурацией и версионировать её.

**Эксплуатация**: сервер автоматически обновляет конфигурацию, выполняет health checks и управляет сертификатами. Метрики показывают распределение запросов по гео-регионам и состояние серверов.

**Цена решения**: разработка заняла время, но результат даёт нам полный контроль над DNS и возможность быстро адаптировать его под новые требования.

### Кейс 6: Go-библиотеки — платформенные решения

**Проблема**: когда у вас много сервисов, повторяющаяся функциональность (HTTP-сервер, работа с сетью, валидация, рендеринг) реализуется по-разному в каждом сервисе. Это приводит к:
- Дублированию кода
- Разным подходам к решению одинаковых задач
- Сложности в поддержке и обновлении

**Почему готовое не подошло**: стандартная библиотека Go хорошая, но не всегда покрывает наши потребности. Сторонние библиотеки часто решают только часть задачи или имеют другой подход. Нам нужны были библиотеки, которые работают именно так, как мы хотим, и интегрируются с нашей инфраструктурой.

**Решение**: мы создали набор библиотек (`go/*`), которые стандартизируют работу с:
- **HTTP** (`go/http`) — высокопроизводительный HTTP-сервер и транспорт с DNS-кешированием, балансировкой нагрузки и метриками
- **Vault** (`go/vault`) — работа с зашифрованными секретами через Ansible Vault
- **UUID** (`go/uuid`) — генерация и работа с UUID для разных контекстов (SQL, JSON, медиа)
- **Validate** (`go/validate`) — валидация данных (email, домены, коды стран)
- **Render** (`go/render`) — рендеринг JSON и XML ответов
- **Geo** (`go/geo`) — работа с геолокацией через MaxMind

Каждая библиотека:
- Решает конкретную задачу хорошо
- Интегрируется с нашей инфраструктурой (метрики, логирование)
- Имеет понятный API
- Покрыта тестами

**Эксплуатация**: все сервисы используют одни и те же библиотеки, что упрощает поддержку и обновление. Когда мы улучшаем библиотеку, все сервисы автоматически получают эти улучшения.

**Цена решения**: поддержка библиотек требует времени, но это время окупается за счёт того, что сервисы пишутся быстрее и работают одинаково.

## Возвращаемся к Go: технические детали

Вернёмся к Go, потому что конференция про Go, а не только про интересные штуки.

### Почему не стандартный HTTP-сервер

Когда мы начинали проектировать нашу систему, мы сразу же отказались от стандартного HTTP-сервера. Он в Go очень неплохой, как и многое из стандартной библиотеки. Что очень хорошего есть в Go — у него очень хорошая стандартная библиотека, и она реально крутые интерфейсы. Когда ты пишешь потом свой код, ты не хочешь делать сильно хуже. Поэтому зачастую получается неплохо, с разным переменным успехом, но тем не менее.

Почему мы не использовали стандартный HTTP-сервер? Он не имел возможностей для наших задач. Количество RPS у нас не такое большое — сервер может обработать пару десятков тысяч, стандартный, вероятно, выдержит.

Но у нас очень много контента, который мы передаём. Соответственно нам нужно практически на всё CPU. Это кстати Go — если у него была другая модель работы с памятью, такой бы истории не было, но что есть, то есть.

Мы шируем TCP-коннекты. У нас своя логика, просто у нас пул открытых коннектов, таймауты свои, и проще нам, мы понимаем, как их лучше подстроить, и стандартно этого точно не даст.

У нас естественно кэш открытых файлов, потому что файлы открывать туда-сюда очень дорого, особенно когда у вас 1000 запросов могут прийти.

И у нас есть zero-copy. Про zero-copy будет отдельный доклад, здесь не будем углубляться, но давайте расскажу историю затравки.

### Прокси и zero-copy

У нас есть прокси. Что делает прокси? Он принимает трафик, разбирает HTTP-запрос, отправляет его по TCP, берёт nginx и отправляет его выше. Казалось бы просто[^zero-copy-details].

Парсеры в стандартной библиотеке неплохие, но нас напрягала история: нам важно не только много контента, нам важно отдать его быстро, и тем более получить первый байт клиенту — за скорость. Медленный CDN мало кому нужен, даже если через него можно отдать много трафика.

Смотрим на реквесты и понимаем, что у нас что-то не так. Много — 200 миллисекунд по децилям процентили, много.

Используем pprof, смотрим. Потом смотрим глазами, что мы делали. У нас свой веб-сервер простой написанный, потому что мы видео отдаём по HTTP 1.1, там никакого блокирования запросов нет — пришёл коннект, открыли, начали лить туда контент, всё просто.

Приходит запрос, мы обычно стандартным разбираем HTTP, парсим, получаем его, выбираем по какой-то логике backend, TCP-соединение, и в это соединение пишем. Здесь проблем нет.

Запросы обычно приходят очень маленькие, заголовки и всё, больше ничего нет. Мы получаем response и просто делаем response, который есть, у него есть метод Write, и мы пишем в Connect, и в принципе всё здорово.

Мы получили response, получили с него данные, сняли метрики, записали нужную нам историю, которая там с него была нужна, и отправили клиенту и забыли. И вот 200 миллисекунд — это кстати если вы используете какой-то сервер, написанный на Go, особенно который говорит, что он очень производительный, там трафик, они используют стандартные из Go, этот прокси, это можете потом кстати сделать, если захотите.

Одна проблема: стандартный не отправляет, условно то, копирует в Connect данные из-под себя. Он копирует их, копирует сначала в память, то есть из user space мы поднимаем, обычный подход. Такого можно избежать.

В Go есть интерфейс `io.Reader`, который может реализовывать дополнительные методы. Это либо `Seek`, если мы работаем с файлами, либо `WriteTo`, если мы работаем с сетью. Внутри Go проверяет интерфейс, и если он совпадает, использует оптимизированный путь отправки.

Но в HTTP ResponseWriter стандартном настолько далеко Body во что-то запихнуть, что до него не достучаться, что он соответствует этому интерфейсу. Поэтому там идёт стандартный Read loop, и мы получаем эту историю.

Насколько я помню. У нас прокси выглядит так, когда он передаёт несколько гигабит в секунду — это потребление памяти приложения и его response, после особенно zero-copy мы память практически не используем.

При zero-copy мы говорим операционной системе: вот один дескриптор, вот другой дескриптор, сама разберись. Мы так делаем и для файлов, и для соединений. Поэтому здесь мы не попадаем под влияние Go runtime — не боремся с garbage collector, не создаём лишних объектов. Отдали и забыли.

Если нет бизнес-логики, то же самое. Если мы знаем, сколько нам нужно данных прочитать, лучше прочитать сразу столько. Потому что если мы читаем по чуть-чуть, то это огромное количество syscall'ов. Так только последняя запись на диск уже говорил, пишем только последовательно, поэтому мы можем использовать HDD, поэтому у нас стоимость решения в деньгах сильно ниже. Поэтому можем потратить эти деньги на костыли решения, а дальше их масштабировать просто в такие машинки. Получается выгодно и походили в удовольствие, и компания получила деньги.

## Сложности

Сложности — куда уж без них. Если мы говорим о Go, краеугольный камень — это работа с памятью в Go.

### Работа с памятью

В Go мы руками не работаем с памятью, почти, но сейчас арены появились. Но это нельзя сказать, что это работа с памятью — идея на самом деле старая, давно висело, чтобы можно было выделить область памяти, куда всё запихать, и чтобы garbage collector на неё не ходил, а потом разом всё хлопнуть. Для ряда вещей О'кей.

Но собственно Garbage Collector — это такая круговая штука, из-за которой идут потом все проблемы. Никаких сложных структур в памяти в нашем случае сразу же говорю. Вполне себе для ваших решений это может подойти.

Когда мы стартовали, у нас было много объектов в памяти — десятки миллионов. Мы написали дерево, чтобы хранить индекс в памяти. Всё работало достаточно быстро.

Количество объектов в памяти увеличилось, увеличилось, увеличилось, потом прошёл GC, бум, и нам ударило по CPU, и паузы пошли, и соответственно всё это работать перестало.

Самое смешное: пытались инженерить сначала и подумать, как ещё там, на самом деле простой был, как с этим быть, и пытались там написать на C, потом забить, но это неудобно деплоить и ещё всякие истории.

В итоге просто взяли обычный `map` и записали ключ-значение — и всё заработало.

Нужен `sync.Pool`: мы выделяем память и не отдаём её сразу. Если у нас есть объект или байты, которые можно переиспользовать, храним их в `sync.Pool`, чтобы garbage collector не пытался их вычищать — мы переиспользуем их постоянно.

Поэтому у нас каких таких больших проблем с памятью нет.

## TLS и производительность

С какого-то момента весь трафик передаётся шифрованный, и соответственно мы написали своё решение. Хотелось бы подключить сертификат и поехать — мы всё равно бы написали свой веб-сервер, написали там работу с этой штукой, и почему бы нет, попробовали, всё работает с коробки, прям хорошо, отличный интерфейс, касаемо именно стандартной библиотеки интерфейсов[^tls-performance].

Причём не только стандартная библиотека, но на самом деле много библиотек, которые основаны, они очень хорошо сделаны. Я не имею в виду внутренность, именно интерфейс очень круто, с ним приятно работать, и там видно опыт. Например мне кажется, пак занимался, насколько я не помню, по большей части, у чувака дофига опыта, поэтому он опыт взял туда перенёс, это реально круто сделано.

Динамический выбор сертификатов — мы реально можем написать хранилище какой-то сертификат и без всяких перезагрузок подменять сертификаты, это прямо очень удобно было бы для нас, и прямо прекрасно.

Но есть некоторые проблемы: это очень медленно. Это реально очень медленно, если брать любые другие решения, то есть поставить терминатор, nginx-прокси либо ещё что-нибудь, Go проиграет, причём проиграет очень сильно.

Если вы занимаетесь, если вы пытаетесь отдать много трафика, это будет плохо, там даже не какие-то проценты, это прямо разы может быть, у вас съест весь CPU, совсем.

Всё у нас было плохо, потому что если по профилировать, то опять же там пошли бинты, пошло куча памяти, к вам пришёл GC, он вам помог.

### Решение: kTLS

Есть решение — если мы говорили о копиях, и соответственно когда можем что-то делегировать операционной системе, то в какой-то момент в Linux, и не только в Linux, появилась история с kTLS. TLS тоже самое, ядро сейчас понимает, как работать с TLS.

Там достаточно современная версия, там 13, это нормально уже, там ещё лет восемь назад было не очень, сейчас совсем всё хорошо, практически у всех есть. Соответственно вы покрываете клиентов, причём подавляющее большинство.

Как это работает: у вас открывается socket, тестовый, внутри ядра, вы работаете с ним как обычно, вы ничего не видите. Вы просто скормили там сертификат, сертификат — набор байт, и он умеет. Причём настолько умеет хорошо, что если у вас, например, нормальные сетевые карты, там какие-то Intel, то вы можете терминатор не только в ядре, но вы можете терминатор трафик на сетевой карте.

Жутко производительно, если вам нужно дофига трафика обрабатывать. На самом деле там всё очень просто, там есть API, просто прилеп к сетевой карте, и тоже умеет TLS.

Казалось бы, вот оно счастье, и оно было очень близко, но его нет в Go. Мы первые озаботились с этой проблемой, есть issue на GitHub, причём самое смешное, что issue сделали чуваки из Google, которые написали другим из Google, которые пишут Go, они такие.

В общем, сейчас висит, если оно появится в Go, это будет всем прям профит, на самом деле, то есть одна из больших проблем, это решит кучу проблем для тех, кто занимается балансировкой трафика, а кто как и мы, например, занимается отдачей трафика, и это было бы прямо очень круто, но нет, и нет.

Притом есть на just for fun, попробовать, там человек в тот момент занимался как раз Go-разработкой, именно TLS, он у себя там в блоге выложил, что в принципе это работает, можно сделать, но production решения нет.

Мы написали свою реализацию kTLS для Go, которая позволяет использовать kernel TLS для терминации TLS-трафика. Подробнее см. в статье [«Разгоняем Go TLS до 100 Gbps»]({{< relref "talks/razgonyaem-go-tls-do-100-gbps.md" >}}).

## Отдача из памяти: не всегда то, что кажется

Вернёмся к отдаче с памяти. У нас иногда возникают нестандартные ситуации.

Если обычно у нас есть некоторая сезонность трафика, в том числе по дням, по времени суток, то иногда возникают события большие, например, лайв-трансляции. Когда в тебя пролетает плюс 150 гигабит, например, это видно.

Бывает такое, что вот прилетела трансляция, а в этот момент ещё какая-то рекламная сетка начала раздавать трафик. Вот тебе ещё, например, 100.

И тут можно посмотреть интересное, когда такое случается. Такие случаи бывают, можно взять, включить pprof, потому что в Go одна из самых прекрасных штук — это профилирование, всё работает с коробки, взял, включил, ещё картинку вывел и прекрасно.

В этот момент мы примерно отдавали из памяти и из диска одинаковое количество данных. Но насколько мы видим, из памяти мы сильно провисали. Казалось бы, из памяти быстро, а но не всегда то, что кажется, на самом деле так и есть.

Мы очень сильно провесали, где если мы отдаём из памяти, то мы копируем из памяти Go, из user space памяти в kernel space, дальше отдаём, оно там пишется. В случае отдачи с диска мы опять же используем zero-copy. Он кстати даже здесь есть, мы используем zero-copy и не тащим себе в память данные, чтобы потом снова их куда-то отдать.

Поняли свой косяк, поэтому сейчас как у нас будут выделены серверы, которые как раз для отдачи лайва, они стали ещё проще. Это опять же об ограничениях: мы из HTTP выкинули даже поддержку Range, то есть он вообще ничего не умеет, умеет взять запрос, никак не думать, что там Range пришёл, не Range пришёл, там какую-то часть файлика и какую-то часть файлика он хочет, прям взяли, отдали то, что есть, потому что мы понимаем, что там будет маленький кусочек лежать, который нужно отдать весь.

Сильно упростили. У нас нет persistent cache — при перезагрузке есть файл на диске. Кольцевой буфер: пишем с начала до конца, когда заканчивается, начинаем писать с начала и затираем старое. Вот и вытеснение, всё просто. Нет шардирования, очередей на запись — максимально простое решение.

## Чеклисты: готовность к продакшену

Когда мы создаём новый сервис, мы проверяем его по нескольким чеклистам, чтобы убедиться, что он готов к продакшену. Подробнее о том, как мы эксплуатируем сервисы без Kubernetes, см. в статье [«Эксплуатация без K8s»]({{< relref "talks/ekspluatatsiya-bez-k8s.md" >}}).

### Чеклист: готов ли сервис к продакшену без кубера

- [ ] **Один бинарник**: сервис собирается в один бинарный файл без внешних зависимостей
- [ ] **Systemd unit**: есть systemd unit файл с правильными настройками (restart, limits, security)
- [ ] **Health checks**: сервис экспортирует `/health` или `/ping` endpoint
- [ ] **Метрики**: сервис экспортирует метрики Prometheus на `/metrics`
- [ ] **Логирование**: логи структурированные (JSON) и отправляются в централизованную систему
- [ ] **Graceful shutdown**: сервис корректно обрабатывает SIGTERM/SIGINT
- [ ] **Конфигурация**: конфигурация через переменные окружения или CLI флаги
- [ ] **Секреты**: секреты передаются безопасно (через vault или переменные окружения)
- [ ] **Мониторинг**: настроены алерты на критические метрики
- [ ] **Документация**: есть документация по деплою и эксплуатации

### Чеклист: что обязательно стандартизировать

Когда создаёте новый сервис, убедитесь, что он следует стандартам:

- [ ] **Порты**: используйте стандартные порты (HTTP: 8000+, мониторинг: 9000+)
- [ ] **Метрики**: все метрики в формате Prometheus с единым namespace
- [ ] **Логирование**: структурированные логи с единым форматом (JSON)
- [ ] **Build info**: версия, коммит, дата сборки доступны через метрики или `/version`
- [ ] **Rollback**: можно откатиться к предыдущей версии без проблем
- [ ] **Спецификация**: есть `spec.yml` с описанием деплоя (порты, лимиты, зависимости)

## Итоги

Подведём итоги.

Если у нас получилось, то и у вас получится. На самом деле сложного нет, обычно проблемы, которые инженер встречает, они очень простые — какие-то базовые вещи.

Например, что нужно уметь: данные должны быть сортированы, окей, вы можете в них быстро найти. Данные должны быть фиксированного размера, поэтому вы можете эффективно их хранить на диске, там или в памяти, либо ещё где-то, быстро к ним получить доступ.

Вот ещё банально: любое решение, которое вы делаете, там должно быть аргументировано, нужно разбираться в том, что ты делаешь тоже. Казалось бы банально.

Нерешаемых задач на самом деле не существует. Мы пробовали сами — если есть какая-то задача, мы её решим, это может занять больше времени, иногда сильно больше времени. Иногда некоторые задачи не делаются за день, иногда за месяц, иногда даже за год, и это вполне себе нормально.

Если ценность решения есть, то можно его делать и два года. А если что-то не работает, это не всегда означает, что проблема в вас. Нужно профилировать — можно иметь огромный опыт и ошибиться на простейшем, это нормально.

В этом нас спасает, что с такими косяками метрики, которые мы собираем, у нас их много, и на всё профилирование, это всё видно. В Go это прям даёт огромный профит.

Все врут, нужно понимать: когда вы приходите на конференцию, читаете статьи, смотрите бенчмарки либо ещё какая-то история, зачастую там неправда, причём неправда может быть от начала и до конца. Нужно всё проверять, нельзя бы в что-то поставить, оно начнёт у вас работать, взять какую-то библиотеку и у вас там полетело, всегда встречаются какие-то косяки.

Встречается не то, как это работает, как это описано, и так далее. Опыт и понимание того, что если вы что-то к себе внедряете, можно выстрелить в ногу, причём даже об этом рассказали, что все у всех всё хорошо, не так, и потом придётся это править.

**Главный урок**: пишите своё только тогда, когда это действительно нужно и вы понимаете, почему готовое не подходит. Стандартизируйте всё, что можно стандартизировать. Инвестируйте в платформенные решения (библиотеки, шаблоны), которые упростят жизнь всем. И всегда помните: ограничения — это хорошо, они помогают фокусироваться на том, что действительно важно.

## Полезные материалы

- [Zero-copy в Linux: sendfile и splice](https://www.kernel.org/doc/ols/2005/ols2005v1-pages-19-28.pdf) — техническая статья о механизмах zero-copy и их применении для раздачи файлов
- [Linux Network Performance Ultimate Guide](https://ntk148v.github.io/posts/linux-network-performance-ultimate-guide/) — полное руководство по тюнингу сетевой производительности: настройки ядра, TCP, буферов и драйверов
- [HTTP/2 Prioritization with NGINX](https://blog.cloudflare.com/http-2-prioritization-with-nginx/) — как Cloudflare решает проблемы приоритизации HTTP/2 и оптимизирует раздачу контента
- [The Story of One Latency Spike](https://blog.cloudflare.com/the-story-of-one-latency-spike/) — практический пример диагностики проблем производительности: как искать узкие места в системе
- [Go pprof: профилирование производительности](https://go.dev/blog/pprof) — официальное руководство по использованию pprof для профилирования Go-приложений
- [Работа с памятью в Go: GC и оптимизации](https://go.dev/doc/gc-guide) — руководство по пониманию работы garbage collector и оптимизации использования памяти
- [ScyllaDB: работа с дисками в Linux](https://www.scylladb.com/2016/09/15/io-access-methods-scylla/) — практические советы по работе с дисками, mmap и его trade-offs от команды ScyllaDB
- [kTLS: Kernel TLS для Linux](https://www.kernel.org/doc/html/latest/networking/tls.html) — документация по kTLS, которая помогает решить проблемы производительности TLS в Go
- [Когда писать свой софт, а когда использовать готовый](https://blog.cloudflare.com/cloudflare-outage/) — размышления о балансе между собственными решениями и готовыми продуктами
- [DNS: основы и гео-маршрутизация](https://www.cloudflare.com/learning/dns/what-is-dns/) — как использовать DNS для маршрутизации трафика и построения CDN

> **Практическая заметка.** При разработке собственных решений важно понимать текущее решение и иметь чёткий список требований. Ограничения — это хорошо: они помогают фокусироваться на том, что действительно нужно, и не реализовывать лишнее. Метрики и профилирование критичны: без них невозможно понять, что происходит в системе. Стандартизация — ключ к масштабированию: единые шаблоны, библиотеки и практики позволяют быстро создавать новые сервисы без изобретения велосипедов. Источник: опыт разработки CDN, DNS и систем хранения данных.

## Сноски

[^cdn-details]: Подробнее о том, как мы строили CDN для раздачи контента с HDD и какие проблемы пришлось решать, см. [«Раздача контента с HDD»]({{< relref "talks/razdacha-kontenta-s-hdd.md" >}}).

[^zero-copy-details]: О том, как zero-copy работает в Linux и почему это критично для производительности, см. [«Разгоняем Go TLS до 100 Gbps»]({{< relref "talks/razgonyaem-go-tls-do-100-gbps.md" >}}) и [«Раздача контента с HDD»]({{< relref "talks/razdacha-kontenta-s-hdd.md" >}}).

[^tls-performance]: О проблемах производительности TLS в Go и решении через kTLS см. [«Разгоняем Go TLS до 100 Gbps»]({{< relref "talks/razgonyaem-go-tls-do-100-gbps.md" >}}). О проблемах с TLS в контексте раздачи контента см. также [«Раздача контента с HDD»]({{< relref "talks/razdacha-kontenta-s-hdd.md" >}}).
