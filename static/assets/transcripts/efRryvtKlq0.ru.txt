значит

чем почему доклад нужно сказать да все

еще 2 год

два с половиной никто не знал что такое

кликал узнали там в яндексе наверно вот

и сейчас нем знают все и все

рассказывать истории успеха я расскажу

историю успеха с одной стороны я вам

расскажу как мы сделали систему плохую

накликал вот доклад немножко другого

планировался но все бы не вместилось

поэтому

с организаторами решили что будет так и

так погнали в россии ли факт чеки

некоторые всё такое я я значит не

являюсь аналитиком

админом дебаты в общем я просто

разработчика на гол в компании трафик

stars трафик stars это рекламная сетка и

наша реклама вы видели вот мы в секунду

получаем до 70 корп с на наши бренды

у нас два дата-центра в европе сша у нас

все это дело обслуживает но вчера

applications 2312 серверов доставки

события это кафка у нас и 12 рон

хранение данных cliff house

это 2018 году то есть сейчас у нас

примерно так плюс-минус трафик stars

твинхаус у нас примерно 500 запросах

статистики в пиках ну там плавает до

который мы получаем на pr примерно 50

терабайтов данных и вот эти 500 запросов

без учета работы аналитиков вообще щенок

аналитических дашбордов для менеджеров

которые там аналитик строят там немножко

другие запросы мы как бы с ним

по-другому работаем но тот же кластер их

обрабатывает особенности хранить как бы

данных которые у нас есть и почему мы

свою статистику считаем складываем

именно так как мы сейчас ее складом и

раньше складываю нас есть крупные

клиенты которые крупный клиент скажем

так физически плавает разное которые

могут приносить нам до сорока процентов

трафика

то есть они очень удобно размазывать то

есть там всегда будет очень много данных

считать возможны резкие всплески трафика

когда заходит нас новый publisher мы

легко поднимается на 5 10 corps

он может а там уйти может остаться

капотом меньше трафика больше давать

поэтому мы должны быть к этому готовы и

задержка статистике должна быть

минимальной почему а должна быть

минимальный мужик зачем актуальные

данные ну как бы самое первое что нам

нужно почему нам нужны точные данные

котором повышаем от событий это точный

расчет баланс пользователей и тут как бы

две причины первая причина товар спринт

когда мы у клиента больше денег списали

и от плохо к плохо для клиента плохо для

нас там и денег все равно вернем но

длятся не очень хорошо потому что в этом

publish нам должны и так же наш клиент

часто ходит по пьяни корректировать

каким-то образом рекламной кампании

поэтому тоже очень важно получать данные

в реал тайме ну или близком к real time

on данным я пришел 2016 году в компанию

компания с офис разработки на кипре и

все начиналось примерно так вот хранения

событий как у нас был организован нас

уже было капкану от в компании или когда

я пришел к будем гореть у нас было кафка

у нас скольки все данные писались верху

были worker наговор написано

версия хранила сырые данные она хранил

их какое-то количество времени не очень

большой несколько дней сверчки данные и

company начинал приходить на цветов то

есть искали решение какое-то

вот была какая-то агрегация данных

vertica мы считали эту статистику и

потом все это по счету на 100 леску

писали в cytus цвету сохранил уже как

долговременное хранилище там

агрегированных данных и чё там вы там

отгружали в сыром виде в ходу для того

чтобы можно было строить там большие

отчеты там за мести за два мясника

считают как будто все лежал и все

считалось потом все было как бы хорошо

потом у нас появился вот этот центр мы

начали реплицировать и данные сказки это

здорово для пациентов другой чтобы

считать к сожалению у нас стандартная

репликация картине заработал там который

миру maker вот на наших каналах то что

сучкой очень плохо все как бы мы

написали свой вот о нём сейчас и живем

как все было с cytus дебету любимого

ошибка в колонну базу данных там было

все очень хорошо на первый взгляд мы

спали там все ставки до в шар нирования

нашего кота блистала было 29 колонок

сейчас смешно уж 29 но тем не менее и мы

с этим как-то начали жить вот так вот

так она примерно выглядит таблицы там

было как бы ой привет лишь я думал тебя

не будет так бы назвал заказа по другому

что не тормозить никогда вот и у нас

была одна широкая таблица в цитрусе мы

посчитали статистику отдавали

пользователям было все примерно

более-менее ровно но у нас начали

проблемы роста и текуч конфигурация в

которой

забывай как мы хранили начала

исправляться то есть простые запросы у

нас выполнять полторы секунды там и выше

потом в среднем до там давно было

сложные запросы в принципе от 30 секунд

и до бесконечности то есть она не

считалась вообще простые запросы были

такие примеры считаем queen там

количество кликов там денег по какому-то

клиенту в какой-то диапазон дат более

сложное тогда мы считаем там делом

группировку по некоторым там по

нескольким атрибутом и

запросе фильтрацию 2 там тоже некоторые

много атрибутов использовать таки к

ственные фильтры

вот как сделать быстро было в той

ситуации то есть такой наш опыт был

первое можно было добавить сироп мы

добавили не помогло вот второе такой

агрессивной агрегация ч то есть мы взяли

и на делали табличек это стало выглядеть

вот так вот эту в деве версию номер два

у нас были какие-то показы мы это дело

агрегирование у нас появились маленькие

отчеты по операционным системам по

браузером на по языкам дела и так далее

то есть отдельные таблицы плюс нас

осталась одна большая широкая таблица

чтобы мыло можно было считать кастом и

отчета и мы с ним продолжили жить в

принципе все работало неплохо то есть

базовые отчеты которые были нужно быстро

они считали стану показывать в 3 на 150

миллисекунд такая в принципе было да и

часто хорошо то есть это не очень

критично для интерфейс вот освободились

ресурсов для выполнения сложных запросов

как бы теперь уже там 10 секунд более

менее все могут подождать все это там

понимали такие вот считая много данных

как бы все хорошо но у нас неплохо

работает силы

вот и они могут нагнать нам трафик они

могут нагнать к нам клиентов и это всё

превращается в данное

опять же горизонтальное масштабирование

кто вам чего не говорил она выглядит так

то есть мы берем и забиваем что деньгами

то есть хорошо когда сбиваем карманы

свои деньгами а тут мы как бы таким куда

так спускаем а потом нас косо смотрят и

хорошо вот не требует ничего но екософт

уже смотрят как будто с неправильно

нужно новое решение вот такое то есть

нам нужно все и сразу

но по другому не бывает мышь подумали

мыть их на реках бы нам бы надо бы чего

не такой правления масштабируем

отказоустойчивая низкая стоимость

владения опять же повторюсь unesco

стоимость владения я не админ

бог знает как бы вначале говорил ему

стать магом все были такие вот клик

house к нам пришел то есть втыкалась

появился приходилось обещал что все

будет быстро и мы в него вошли вошли мы

достаточно шустро потому что все таки

стоит владение действительно как бы там

простая то есть это даже я смог его

развернуть мы смогли это налить данных

даже написали драйвер для того чтобы

попрощаться по нативного протокола опять

же потому что нас нет денег на много

сервировкой бы так было проще вот и

стали использовать для всего то есть мы

убрали вертик у мы брали cytus в

какой-то медали за человек и все оставил

складировать в клик хаусе

мы сделали прототип такую модель как

которые у нас было

и загрузились и туда данные которые у

нас были в примерно в том же виде то мы

взяли схему которая была в цитате

положив кликал все прям взялись

несколько запросов прям летает как

классно вот и такие радостные сидим но

мышь как будет расти роще ко мне всякие

со проверяем вот и поэтому решили

попробовать другие запросы и там все

было плохо и плохо было вот почему то

есть у нас есть две категории большие

которые существуют людей

сущность удар системе это рекламодатели

которые это рекламной кампании по

большому счету датомира лeтyчиe и

рекламная площадка inx всего один

яндексе немножко позже на как бы честно

вот один и поэтому как бы часть запросы

у нас работали супер быстрый хорошо

часть они работали как бы не очень вот

проблему доступа в чем у кликала supply

co один индексом назовем кластерный

даешь как правильно вот классно

index.dat еще одет он на самом деле

берет данной и сортирует их согласно

ордер buy if not который там час

написано сейчас много схеме то удобнее

стало

вот согласно ключу сортировке эти данные

отсортированы то есть он берет первичный

ключ к двери до как как как и calls

доступ к данным получает оси он берет за

примером пишем там какое-то условие он

встречала смотрит по ключу парте

цианирования мин-макс вообще портится

входит нет он достает эту партицию

доставят первичный ключ к смотря какие

там есть строчки уже к ним бежит вот он

получаем например у нас индекс был по

publisher у а нам нужно посмотреть в

компании соответственно и можно очень

много скользит по большому счету

посмотреть поискать и

было неудобно то есть очень большое

количество данных затрагивать с насчет

работали медленно и

на 100 не устроило мы решили что как бы

а давайте мы сделаем отдельные таблицы

отчетов до рекламодатель не рекламных

площадок не влезло буква там как ничего

страшного вот и у нас все хорошо

заработала в этом плане у нас получилось

что у нас правильно индекс для

рекламодателей

правильно индекс для рекламных площадок

и это было приятно в это было быстро и

все хорошо так как мы хранили данную же

включалась у нас не было отдельного

хранилища и сырых событий отдельного

хранилище для легированных и так как бы

отчетов уже там подумали а почему бы нам

не использовать матери зова на и видео и

раз в этом какое-то количество времени

обсчитывать события которые мы не можем

посчитать вас быть реализованы явью

самом деле моторизованную греха вас

больше наверно смерти к работал очень

хорошая проекция чем натали гаваны и

view можешь поиграть потому что они как

бы налитую ситуации то все как бы хорошо

это что транзакции нет нормальность вот

и вызваны представления от чего не

делают на самом деле например надо что

то делать они создают триггер на запись

условный триггер до который там есть

создает или использует обычном таблетку

для хранения отчетов вот и с этим

вылезли в продакшн это было все

прекрасно то есть когда мы нажимали на и

в 50 мм это как было нам и поигрались

перестали нажимать и наш менеджер

ежемалина 5 носи довели обновление

счетчиков все были довольно

любой счет считалось не более секунды

кастомный лекарственный без разницы

базовые отчет вообще 30 миллисекунд

красотища как бы -20 сервер tickets и

туса и все это на 4 hire откликался у

нас запас по мощности к классу прекрасно

все работает красота вот потом мы

добавили еще два по простой причине у

нас какая конфигурация у нас ребекка

решит фактор 3 так удобнее обслуживать

то есть нам как бы это по ресурсам не

сильно нас affected к то есть там

немного такого количества машин проще

обслуживать класс стр ну там выключать

из пистолета память реально удобнее вот

но было минус такое большое количество

таблиц и как бы он был такой вот типа

есть и есть то что он немножко стал

вырастать

постепенно начались сложности в

изменении схемы но то есть мы не можем

взять и там некоторых случаях там

поменять что такое бы добавить это можно

добавлять во все отчеты если у нас

ключик меняется сортировки первичный

ключ

путаницы вот первичный ключ и lustrarte

ровки у меня это нам нужно переливать

таблиц то есть мы не можем потому что

это изменение физического

у порядочности дано х равно что

переливать таблицу множество одинаковых

колонок в разных таблицах но the

overhead на хранилище данных и множество

правильных медленно сколько множество

кликов по умолчанию 16 потоков нами же

использовал убирая не на бирже вообще бы

galant пулу не 16 потоков как вы ему

финские все занимали вас пустоту мир

жилось то есть у нас не было такого что

чуть не меньше у вас нежилась всегда вот

и это было бы наверное терпимо как бы

система работает но сложно нам как бы ну

ладно мы привыкли как бы нам за это

платят то есть там не подняться что он

был просто как разработчики вот средстве

на бизнес и стоял на месте мы добавляли

новые колонки новые отчеты мы доверяли

как бы новые таблицы матери как бы

добавляешь но в отчеты добавляешь новую

таблицу добавляешь новых матери зоны

представления что кто-то счет был реал

тайме

вот и в какой-то момент как бы

учу у нас у нас все было хорошо ты с

внешней стороны нас был любой счет также

остался не более одной секунды базовая

чудо 30 миллисекунд красота но высокий

расход памяти циклу пищу пересчете

статистике потому что нужно много

посчитать много куда влить как бы этот

какой-то момент туда стоят пересчетом из

сервера так хорошо по памяти особенного

укладывали вот и медленная запись данных

вот мы же говорим про тормозит значит

медленно запись что ты нас медленная

запись медленно запись для нас это

убийство но в прямом смысле потому что

если мы не успеем учитывается ли события

то мы понимаем что мы не успеваем

актуальный баланс считать наши

пользователь не считают ну как бы не

могут быстро реагировать на изменение

компании могут ее сделать как бы плохо

вот чем стали делать мы попытались

писать несколько реплик потому что клика

асад определенная система у нее нет

принципе никакого мастера все сервера

равнозначно можно писать любой вот мы

попробовали писать какой-то момент

несколько реплик

это принципе работающая схема нормально

но из за того что у нас было очень много

таблиц и у нас пошли мир же постоянно мы

просто не успевали между куски и

вываливались потом они парс как бы мог

recall сацуки как у меня больше не

пишите как бы хватит горшочек не вари

вот мы стали думать но почему бы нет

когда то когда то нужно это было делать

.

либо раньше либо позже вот мы как бы

пришли немножко позже мы попробовали нам

понравилось как раз мы решили что мы с

него выходить не будем мы решили

посмотреть что же у нас не так вот если

вспоминаете как бы как мы примерно как

бы пишем туда данные то у нас есть

worker на голову на сначала как

происходят события у нас происходит

событие в системе кидаем афк афк у

сказки у нас worker и нагов учитывают

эти данные по большому счету не

формирует блок данных то что муж

бинарным протокол используем и пишем от

блок-хаус казалось бы должна быть быстро

вот такой блок на самом деле да там если

некоторый блок информации там 29 бойцам

количество колонок там количество строк

а там переменной длины как бы циферка

вот и дальше эти колонки просто

записанных бинарном виде то есть там

идет название колонки тип колонки дальше

тут данный

просто одни за другим это очень

эффективна как бы очень удобный к классу

самом деле клиент клика us

когда из консольки точно так же работает

и в особенность мы поговорим в кулуарах

об этом как работ протокол от интересно

кстати вот там есть ещё такие штуки

прикольные вот сколько у нас колонок да

если посмотреть час нашей таблице то

есть там 63 если прочитать про моему

колонки и выглядят они так то есть на

сперва лада и тенты что-то у нас строчки

у нас достаточно большой на самом деле

получает строка по размеру но тем не

менее как бы должен был отправляться

все хорошо вспоминаем что нас есть

что-то в реальном времени

ну как бы я продолжаю после того как мы

думали да как вы пытаетесь следить за

май называется что у нас есть в реальном

времени отчетом моих построили матери

зон их представлениях помню что они

создают триггер на запись создают или

использую какую-то там таблицу и пишут

туда данные вот как создавать мир зоны

представлениям все знают да мы сожмём к

томате рисованное представления если мы

указываем ту

нет указке пальцем не буду тыкать

буковка ты это таблица то он просто

использует табличку которая уже создан

было заранее если это создает табличку

in our как бы использует ее

вот эти зоны представлений внутри она

выглядит больше как бы но вот что

интересно да вот есть ли на этом кавере

это запрос который мы создавали на

прошлом сайтом select каллум там фронтом

то близким человеком есть вот их srt

и то есть это внутри на табличка или нет

то есть если у нас inner таблиц то

сейчас различные там запросто optima из

той болтанка it удаление портится не

просто какой-то таблицы применяется

раньше не применялся ругала сейчас

применяются вот это как бы как она

внутри стоит и что он получаем мы

получаем амплификации на запись когда мы

вставляли

данные в таблицу сырых событий мы на

самом деле не одну ставку то есть мы

формируем блок например 33 записи

ну или там 50 тысяч или возьмем более

что проще считать например там конь

круглое число там круглый стол да кто-то

просто толи тысячу

вот на самом деле что тот момент делает

cliff house он берет табличку куда мы

вставляем смотрит у неё какие есть

зависимые table

но не таблица от которой из которых к

сушками являются он их вытаскивает и в

цикле просто блок данных применяет и тут

важно понимать что прекрасно самом деле

когда вот напишем запрос там celik

чего-то там во вью он применяя этот

запрос никто blitz который там будет

написано она применяет блоку данных

которые которые мы вставляем то есть там

не очень будь то есть вы не можете

посчитать но макс как бы просто его

сохранить нам будет этот макс не от всех

данных таблицы которые думать он будет

макс от этого блока

вот и вот так вот он крутится тестом мы

получили в результате что мы пишем у нас

тот момент был уже очень много отчет в

толстом было там условно в этом не знает

30 хрюшка там было написано то есть мы

пишем ни в одну таблицу а еще плюс 30

как бы естественно как бы же железо

ничего как half не тянул проблема была в

том что как бы последовательная запись

вот вот тут раньше ножка рассказал но

последняя запись она в последних релизах

с этим делом все поправили потом школа

player тоже в это вошел как бы и они

входят хорошо если учет не нравится не

правит приходит это очень удобно как бы

классные ребята сейчас можно

распараллелить запись во вью мы это

используем но используем не для этой

статистики потому что она очень старой

версии сидим для местных метрики мы

также храним вот соответственно это

параллели c относительно ускоряет запись

эти пользуетесь хорошо вот пример что

запрос применяется ник таблица блоку

данных тоже нужно знать олюшка как бы и

при записи мастер но сортируем данных

тоже тратится время то есть у нас у всех

таблиц которые были под ним у них был

разные ключ сортировки мы должны эта

рыбка будут просто время тратил нужно

понимать и в итоге мы себе

амплифицировали сами-то они партс как бы

у нас была одна проблема тут трачу

проблема вылезла мер 3 ну и такой на

самый используемый движок в cliff house

он выглядит примерно внутрях ваши данные

выглядит так то есть у нас есть

partition все данные из партиции

хранятся в кусках портах в этой в этом

порты лежат колонки так как как есть да

просто файлик и миллера там где дан один

за другим записано но еще торчать

служебных какой-то информации там ключи

файлы засечек там ну и так далее это

может быть глазами посмотреть там ничего

сложного нет вот и проблема в чем когда

мы пишем клика услыхал всегда создает

новый парк новый part новый part новый

парк на и так далее и можешь говорить

что проблеме доступа что к house нужно

седан отсортировано и что быстрее

работать взять чем больше parties вообще

у тебя будет большой как у вас у тебя

вас будет больше операций с диском то у

нас будет больше проблем вас будет не

совсем так как нужно отсортировано по

накликал фоне их мир постоянно это

делает и он делает из них меньше меньше

меньше как вы постоянно склеивает и в

какой-то момент мы стали не успевать их

между ним и стали какого столах не

успевать держите

проблем было в чем мы писали в разные

реплики но несмотря на это например мы

берем конфигурацию сервера что у меня

есть какой-то сервер да и у него есть 33

реплики вроде 3 реплики пишем это

получается разные куски данных и crack

house принципе там многие слияния

которые идут они идут у него последовать

с у тебя есть реплики как бы делать

через гипер и он водил оркестре большому

счету этого весь процесс выстроить всу

на линии zolan и не получается так что

тебе 140 держит меньше там какие-то дни

кусочки данных гидру гептана это

обмениваются и типа распараллелить

работу нет это все дело последовательно

достаточно выстроена не успевали то есть

если я не было много тратилось память о

ее этом дисковое пространство потому что

что встреть два куска соответственно

нужно сначала сделать еще один 3 данных

двух детских большим все могут 1 а потом

старенькие удалить то есть это больше

нужно проявление слияние городище нужно

помнить как бы размер площади под 16

увеличивать нет смысла ну как бы сразу

говорю как в большинстве случаев всем да

как вам ноги увеличивать нет смысла

потому что вы больше попадете на расход

памяти скорее всего у вас не хватит нам

нужно другими путями эти потому что

увеличение размера как бы ни к чему не

приводит хорошему та же самая не

увеличит увеличение просто количество

таблиц после которого клика суда

совершать больше не пиши меня тоже все

не очень хорошо это вот в этом месте

было все так и это было это был еще один

вызов опять пришлось что-то думать

думать пришлось опять же проще добавляет

серверов ну как то как то мы уже

говорили это деньги как бы это еще что

то не очень уменьшать количество таблиц

это как бы это было решением правильным

она была только чему нужно идти но

вопрос был как уменьшает количество

таблиц вот еще чтобы было важно да мы не

хотели потерять функциональностью но не

мы даже до наш бизнес хотел потерять

функциональности скоростью потому что во

первых к ней привыкли of tanks она нужна

вот мы посмотрели и решили использовать

массивы для хранения отчетов то есть как

это выглядит то есть кто не cipa gres

там работает вот я смотрел снова

работает антифа поставили вот пола

примерно также хранит данные то есть мы

храним данные в массивах один массив у

нас ты фиксатора колонок на примерах

идут один другой массив это просто кино

значение к нему и мы можем включался

сделать там рей join и по большому счёту

нас получается есть строчка а к ней мы

храним еще а набор строчек виде массивов

если мы jonim почаевская бы такая

табличка на строчку вот получается в

одной таблице можем хранить сразу же

большое количество отчетов но вот этих

вот мелких которые у нас были

соответственно эти отчеты никак нельзя

будет нельзя будет между собой эти

данные в отчетах

пример же да там настроить фильтр

какой-то но если ножки это базовая чё то

там операционной системы browsers такое

это все легко ложится в одну таблицу мы

структуры это та же самая фабрика массе

внутри храма к ним пришли чуть позже

раньше как реагировали статистику вы

просто брали описали какой-то запрос

агрегация делали там группировку и уже

чет сгруппировано введен писал столицу

мираж-3 и мы не хотели этого уходить не

хотели уходить на саммит меж 3 сами h3

как работает мы там немножко чуть дальше

перо по большому счету нам нужен

первичный ключ по которому крика а сам

будет сгруппировать эти данные и

приходится писать очень много колонок

которые не нужны для поиска не нужно для

фильтрации и это полбеды да то есть мы

их много написали но как бы хорошо не

требуется память так это первичный ключ

он дело как бы памяти держит это очень

не удобно вот и поэтому сами прямо за

час не хотели использовать мы

попробовали сгруппировать это так и у

нас не получилось мы упали по памяти то

есть мы сначала попробовали

у нас все было хорошо и мы такие как эти

розовые пони скакали и подумали что как

бы все

жизнь жизнь удалась как бы и после

завтра мы уйдем в продакшен налили чуть

больше данных упали по памяти вот как

als умеет делать группировки во внешней

памяти на диске давайте снять куски

но в случае с массивами это не прокатило

не прокатил это по причине потому что

когда происходит группировка насколько я

правильно помню

memory tracker пишется значение просто

это

ну то есть от массива не знает какая там

длина или чем-то при что он просто там

толпа пихает да я же без нет почти чем я

не трафик природа вот есть тонкости

хорошо о тонкостях мы спим наверно

поговорить сейчас по территориям еще

немножко и будем говорить о тонкостях

вот мы посмотрели что можно для этого

сделать руки коласа есть место структур

на структур и как бы a map до запомните

cmos вы ведет жирненьким очень удобная

штука на самом деле да вот напрягаем на

структуру у нас другой браузер на пытать

четко браузером айди это диктаторы

браузеров каунта там кино там этой бреши

на клики там все что угодно может быть

прайс это но колонки к нему идем и

получается что каждый индикатор если и

важно да как бы все длины вот этих

колоннах должны быть одинаковые

получается на каждый индикатор у нас

есть кое-то значению с тем же индексом

выглядит на самом деле это примерно вот

так то есть на самом деле структуру этом

а сила внутри и мы получаем такое

огромное количество массивов то есть

сейчас в отчете которые не общие

докторат идет

который хранит все отчеты в себе в

табличке там где-то там сто пятьдесят

наверно колонок может чуть больше если

интересно мне с собой ноутбук а там

посмотрим если пьянках продакшна

собственно в чем магия такая зачем нам

нужно эти были место тракторы почему мы

к ней обратились то есть увлекался есть

h 3 o на самом деле да давай давайте не

будем брать приходилось большое

количество семейства движков да у него

есть которые хранят в памяти у него есть

движки которые там хранятся лоб дали еще

что-то не просто файлики хранят как бы

есть муж tracktor называется продвинутым

и у него есть там 5 место collapsing

между replacing the с вами при этом

агрегате -3 вычеркну потому что потому

что потому что как бы он нужен был для

того чтоб агрегировать состоянии

агрегатных функций но часто умеет делать

сами h3 вот опять же подклад flare

пролетела вот и он позволяет в некоторых

случаях не хранить избыточные агрегатов

например там для просто какой-то суммы

еще чего-то просто может хранить циферка

нормально цитируют это будет просто

работать быстрее вы храните как агрегат

только то что вам нужно

место слияния где все таки магии это на

самом деле всех этих движков

а не работает все одинаково когда пишем

данные попадают блок данных фунтам

попадает на диск там все это дело

мертвом все это происходит и вот здесь

вот пролетает фея во время magic как бы

она делает магия

магию как она делает то есть у нас есть

первичный ключ к сердцу лишь как-то дали

бы там еще какие-то там значение типа

там сайна еще что-нибудь и просто для

строк которые мы отсортировали в блоках

они идут последователи мы можем это маги

применить можем их просуммировать

мы можем выкинуть там дубликат условно

говоря да там еще что то но это не

происходит вот прям сейчас давали алтай

это происходит умерших только для биржи

и нужно понимать то что у нас part of

много и мы можем в один записать что-то

в другой потом сделать там пропуск

суппортов еще в другой записать и в

одномоментно вас там дубликат не

пропадут 1 момент 2 ст и мне все это

дело не просто миру и ться на это нужно

время и не всегда это будет вообще

происходить то есть он может просто их

не смешивать на место у вас нету еще

что-нибудь

всегда нужно что-то либо до агрегировать

либо либо доделать ручками но эти штуки

сильно помогает то есть мер 3 до как мы

там происходит с беретом табличку то

выбирает кусочки для мерса если данных

колонки нет тоже важным это используем

то берет 2 отвели его там материализует

просто на диске например мы там колонку

добавили да только что либо там удалили

и

и физических ролика на диске нет просто

к его на биты данных есть вот в полик

как пишет вот по первичному ключу мы

меняем какую томатную магию и склеиваем

куски вагину все здорово вот

соответственно

рано руки соответственно для колонок

если мы используем мест от типа да если

мы прописываем map в конце этого костыль

он только стали называть уже вот crack

house видеть что это как бы на 100

структура она помечена как map и он эти

массивы тоже суммирует если мы запишем

the browser 123 к нему таки до значения

следующая строчка пойдут нам браузер там

235 то 23 он их просто миру такие

значения как бы страничек все будь

компактнее но эти тоже как свалит в одну

строчку это очень удобно очень уменьшает

количество строк которые есть в отчетах

это здорово

вот потом и как бы уменьшили количество

таблицу чем как бы сильно мы выкинули

все отчеты которые были у нас посчитаны

вот эти вот которые были там кусковых и

зато по браузером еще почему-то вообще

были отчеты по часовым их тоже выкинули

раньше еще вот на все то что у нас была

сверху какой-то момент мы стали делать

почасовые отчета мы не должны хранить

там очень долго потому что там данных

очень много мы храним их там условно в

этом два месяца после это мы их удаляем

удаляли

сейчас мы не удаляем очень спешим все в

одну и ту же таблицу просто у нас есть

дополнительное поле которая там action

time к нему есть первичный ключ есть

записал не забыл вот соответственно

action дейт идет там да то какая то

текущая в экшен time идут там дата и там

частом там сегодняшнее число там часа

ночи там сегодняшний два часа ночи так

далее 24 значение вот из какой-то момент

мы просто удаляем эту колонку номер

неудаляемые чистым и делом clear колом

crack house берет удаляет эту колонку

там насчет на что дефолт его и значение

из-под action дует вот ты house

физически удаляют просто файлик с диска

потом приходит мир такой смотрит

ага колонка так как юнит можно и

материализовать смотрят у меня есть 10 и

значение так шин бет и вместо 24 разных

значения делает одно и еще раз хлопковые

данные ну то есть мы просто берем через

к месяцев эту колонку чистим окликал в

том сам поддержит эти данные очень очень

помогает нам вот как итог чем получили

мы получили сейчас на системе где то в

среднем так идет там два внутри может

надо параллельных мирах вместо постоянно

этом 16 до момента плавает 5 таблиц

отчетов вместо 30 иметь

количество нечетная потому что у нас как

у нас есть две категории у нас есть

паблишеры у нас есть 4 зиры и у нас еще

есть табличка комом в которой мы храним

просто данные почти как есть практически

без агрегацию поэтому плюс одна табличка

и в реал тайме мы не пишем она нужна вот

ждем было хорошо на что-то должно было

не так должно было пойти не так 8192

вот это такое число она туда пошло мы

примерно понимали как это все работает

мы везде где можно себе под стиль или но

не везде у нас нашелся клиент часа хотел

в глаза посмотреть человека вот у нас

нашелся клиент который стал вот эти вот

массивы который мы храним да вот эти вот

уникальные значения там

идентификаторы сущности которые там есть

у него раньше их было там несколько

тысяч в день вышла там десятки миллионов

вот соответственно массив у нас немножко

раздулся и мы упали по памяти на вернее

мы упали как в это было неприятно то

есть запроса к таблицам которые

выбирались этих где были эти данные по

этим колонкам они стали падать по памяти

и

неприятность была в том что неприятность

была в том что а не затрагивали не

только этого клиента то есть если у нас

был клиент один плохой

идентификатор в 1a был клиент 10 который

был хороший которые там заходил свои там

5 значение в день которые там то запросы

которые касались этого клиента они тоже

падали по памяти вот это было связано с

особенностями индексации клип хаоса то

есть хаоса есть понятие гранулярный

яндекса и так как обычно как aus пишут

много данных мы не знаем мы пишем много

данных может немного пишет

снасти тоже много пишут и поэтому не

очень выгодно индексировать каждую

строчку то есть просто яндекс не влезет

никуда

поэтому он индексирует каждую какую-то

там строчку по умолчанию до 8000 до 92

строчку индексе ртс хранит ее значение и

соответственно когда он читает данные с

диска данные на диске хранятся в

колонках там хранятся не в блоках

что ты мог ему вытащить распаковать их

памяти ему нужно

рядышком посчитать ну как бы прочитать

все другие блоки дополнительно там ну

худшем случае в два раза больше чем

верность яндекса и беда в том что они

потом она это просто фильтр и

накладывают как бы от этого на то что

нужно

потом можно будет пойти есть яндекс hand

он показывает как на самом деле что он

выберет без

из пограничья вот и получилась такая

ситуация что у нас был плохой клиент у

нас был хороший коля плохим он назвать

взял хороший был просто он дело мишка не

так рассчитывали и соответственно мы

когда клиент у которого было мало данных

ему клика вас читала все соседние соседи

изначально средние блоки он доставал

распаковала в память и память не хватало

запрос падали выглядит это тогда почему

потому что в массивах быть может быть

неконтролируемое количество значений

лучшего контролировать там как тут мы

этого не сделали и мы на этом обожглись

соответственно решение в этом случае

было достаточно простое мы уменьшили гр

аккуратно с яндекса и поэтому сильно

уменьшили это нас не сильно за эффект

его по памяти

ну что инси рамбла маленький ног и хаус

стал мы очень на самом деле выиграли

полотна что запросу стал реально быстрее

работать все которые там были

вот и свет стали попадать по памяти

потому что они стали просто влезать как

бы все стало хватать клиента читали

данных гораздо меньше как бы всем стало

хорошо вам с ним клиентам по другому

разобрались немножко структуры

переделать на самом деле вот оно потому

что такие только такое количество

массива хранить нельзя потому что это

реального зафером цените хоть память

проблема достройка сна толще и завтра

даже не сочетается больше строк чем

необходимо посчитай блоки нужно стукать

памяти все мы в него попали как было

неприятно и это был такой неприятный для

нас сюрприз которому даже в которой мы

наступили и о нем стоит помнить так

хотела с ним еще раз напомнить всем

потому что обычно говорят что гранаты

индексов стандартных хватит всем вот нам

не хватило возможно вам не хватит

смотрите в ту сторону это это так все

равно тормозит даже чего бы мы ни делали

на самом деле как бы но тормозило то

есть и отчеты которые мы сделали не

работали реально быстро то есть как вот

вообще быстро хорошо и прекрасно как бы

а часть нет то есть как у нас сделано в

кликал с ручками никто кроме нас и

аналитика не ходят все клиенты которые

есть а не хочет языке и клиенты не

только наши клиенты которые люди которые

смотрят на это и программные комплексы

которые там используя в том числе наш

какие-то софтины которые там считают что

то не ходит в кликал столько через api

вот мы обычно когда что-то делаем это

дело вкладываем метриками

но чтобы хоть что-то понимаешь у нас

происходит вот и в этом случае он

посмотрели да у нас часть как бы

запросов действительно работает очень

хорошо и быстро а часть не очень хорошо

и не очень быстро и нам это было

неприятно вот потому что говорят что

быстро у нас не быстро и это как бы

обидно мы тоже решили подумать почему вы

посмотрели и опять же это все индексы

вот яндекс один из одним индексом жить

не всегда хорошо то есть эти посмотрим

так как бы эта сортировка данных отсеке

друг друга и вот у нас например есть

индексом 9 ноября 2018 года пользователи

номер один мы как бы там сортируем эти

данные в компании номер то было пять

яблок

при условии что мы поставили вот такой

то яндекс по компании например да

сколько яблок было у пользователя номер

два

вот полторы минуты ну потому что

некоторые счет реально считаются долго

то есть этого поля нет в яндексе какого

пола как бы положительным наверняка есть

дан они там как бы да то есть как бы на

двух стульях тут вроде как не усидишь и

его ты снова как бы благо ему немножко

инженеры мы поменяли индекс давали за 4

zero этого же запрос реально стала

работать быстрее часть медленно

бисера тормозит то кивнул мне дело вот

нам все-таки за это платят как бы и мы

не должны делать что было медленно то

есть ну и самим обидно то же как у всех

быстро нас нет вот то есть мы подумали

что как бы есть индекса так как был пик

хауса вот данные в таблицы связаны как

это подходит компании можешь сказать

компании с баннером ему ничего мне не

придумали просто начальство оптимизатор

запросов но как мы его назвали

оптимизатор запрос на кабан такой уж

простой как бы вам это же так дело

обвесили метриками то есть в какое-то

время была то это к снята когда делал

презентацию дополни вчера кстати вот и

тут видно что часть запроса у нас

действительно оптимизируется нашим

оптимизаторам лет нам помогаем как он

работает он держит связи между объектами

в памяти периодически загружаем выпив я

не загружает себя связи между объектом

которые есть если у нас есть какой-то

объект в условия но понимаем что по нему

яндекс тоже есть и что он был бы более

эффективен

ну добавить этот и днище котором запрос

мы просто добавляем этот индикатор в

условиям фильтрации как бы и жить на

стало легче

то есть до 30 процентов запросов

оптимизируются вот почти не евро ну тут

меньше чуть но

но тем ни менее бывает что 30 бывает

больше даже ноты зависит от всего и

средние за время запросов пола где-то в

200 50 миллисекунд нам примерно до 250

был ночью больше чуть меньше

сейчас у нас 55 миллисекунд тоже иногда

она больше иногда меньше там зависеть и

от того как систему наши работает время

вот к этому значит пришли и того почему

в конце концов получили когда все дела

переделали мы получили все таки более

простые поддерживаю систему это самый

большой профит а то есть для любой

систем которые пишут люди там люди

программисты не люди программисты кто

угодно 2 чтобы с тем было поддерживаем

она важна не только программистам

который любит курить тыкать в кнопки как

бы то есть это все здорово это важно ещё

и бизнесу тестовая система не

поддерживая

бизнес с этим плохо если плохо бизнесу

вам тоже на самом деле вко в какой-то

момент будет не очень хорошо о том же

железе мы можем хранить и обрабатывать

больше данных что как бы для нас профит

вот прям очень хороший как бы

и все то есть мы в принципе как бы взяли

немножко переделали стали больше хранить

лучше обрабатывать все у нас стал летать

ну а чего там не хватает чтоб это было

совсем хорошо то есть мы не совсем

перфекциониста на самом деле мы

работаем до как бы над этим над собой

работаем работаем над нашей системой

чего нам не хватает нам не хватает

транзакций не хватает их потому что у

нас опять же не одна табличка их

несколько и это грозит нам потери

связанности данных никак не связности

данных таблицах могут разным транзакции

не потому что туда записали чудо не

понятно то есть мы как можем себе

пастила им там мы считаем значит и

отчеты в копиях таблиц после того как мы

все обсчитали

сверяемся данные после только этом не

тащим таблички партиции перетаскивать

другие таблички целевые делаем этаж и в

этот момент тоже что-то может пойти не

так вот это как бы не хорошо вот мы уже

говорили об этом в принципе тоже то даже

в хаосе то реально сделать два не

зарезать транзакция москит атомарные

операции просто что обкакался когда у

каждого куска дан куска который есть у

него и состоянии просто всем в какой-то

момент вернуть ручку что как бы все ок и

как бы это будет работать ни для одной

таблица для нескольких вот изменения

ключа сортировки не хватает но как бы

она на этой неделе обещали выкатить

не лёша говорил вот такая ситуация да

почему то как бы важно для нас важно для

вас тоже

упрекал сейчас есть первичный ключ он же

ключ сортировки сейчас появится третий

вот на самом деле все не так да сейчас

будет как у тебя у нас будет увлекалась

и будет первичный ключ который

обязательно будет индексировать строчки

до будет будет ключ сортировки которые

можно будет менять

как раз вам будет вот вот эту штуку

отвечать это будет метаданным это можно

будет его в принципе достаточно легко во

первых это позволит изменять и

ключ скажем так на ли туда альтера мне

нужно будет переливаться лишний раз и

второе это память так девушка что все

что мы индексируем и храним в памяти все

строчки который индексируется средства

из точек не будет как бы мы мы можем

обратно нашим хостом отдать их палочки с

памяти как бы сказать спасибо больше не

надо к еще и ножка сэкономить вот 2 и 3

до чего не хватает индекс их структуру

данных для доступа

вот я видел тоже в разработке

я просто читаю

есть на самом деле нужно было вписать

где скади смотреть на самом деле лишь 10

просто ведет то что они делают как бы

ногинске ладно окей

можно потом будет вырезать да но они не

знают не все хорошо я тоже не скажу вот

до догадываетесь

вот спасибо всем спасибо всем вам забыл

написать это потому что это вчера ночью

писала чипсов наелся и начал писать вот

и спасибо всем кто делает crack house

все кто делает crack house есть на

гитхабе сейчас просто как бы разработках

кого-то мент вышла вопрос о спасибо

yandex за это и спасибо всем людям

которые как бы у него вносит вклад то

есть их становится с каждым разом все

больше и больше и прям которая дает

вопросы вопросы можно отправлять мне

я себе домен прикупил вот можно

отправлять telegram на него отвечает это

еще один очень хороший + crack house у

него внезапно вырос то хорошее большое

сообщество

потом стал учиться небольшое хорошая и

есть ряд специалиста сейчас которые прям

реально шарит в этом они реально

помогают не за деньги из за деньги есть

не за деньги в телеграме вы можете

задавать вопросы и за это вас не

попросят денег если попросят вы можете

отказать вот и соответственно crack

house yandex.ru есть документация я тоже

в самолете летела началось снова

перечитывать потому что она обновляется

иногда появляется вещи которые ты просто

не знала то есть проект очень динамично

развивается настолько же быстро

насколько он сам и самом деле есть да .

хаус быстро развитие очень быстро и

очень много в чипе лица и

прям реально очень круто открытый

исходный код еще что позволяет делать

например почему как бы для нас это плюс

потому что мы можем взять учета написать

руками и парик вас даже примут то есть

мы можем закрыть какие-то баги там у нас

были мы можем там давать какой-то хочу

как-бы и

это эти штуки реально быстрее если мы

раньше работали например с другими

базами данных тип игры то там причина

request и могут висеть годами привет

подброс

вот соответственно вот такие вот дела

если советовать или не советовать

советую но советую понимать что это

немножко другая база данных и не пихать

и везде

то есть как бы лучше чтобы у вас был уже

опыт либо понимание как это работает и

как это должно работать мы мы примерно

понимали и даже мы вляпались вот поэтому

был рассказ теперь вопросы если есть

кстати по времени уложился 45 минут

сорок три да а дайте человеку микрофон

потому что либо я могу причем тогда

слушай бы только его спасибо но можно

просто громко говорить я повторю

пожалуйста просто ближе подойду что

слышит

да с переполнением и простая съели всю

конечно особенно по первости просто не

делаем так есть лимиты

да конечно ну смотри нет у нас все очень

просто у нас есть несколько

пользователей нас есть пользователи

пьянь через который работает все системы

да он очень жестко лимитирован как бы в

принципе запроса тут у него там там нет

нежданчик а там свой как бы конструктор

запросов который делается то есть у нас

есть живые данные у нас уже пересчитаны

и данные он смотрит какие данные

актуальность стоят эти запросы с union

ими сделаю китай оптимизация все это

балалайку то есть там примерно

контролируемая все

то есть мы понимаем как это есть есть

отдельно про файлы для аналитиков и есть

отдельный profile для маркеров которые

пишут в него и в принципе ума в это не

упираемся мы иногда

чего делаем у нас у нас очень старая

версия поэтому нас дефолт юзера до сих

пор есть мы его тоже не коктейль

имитировали особо в этом чем делаем

иногда руками действительно нас бывает

проблема кто не сможет написать запрос

такой

я например могу написать запрос и он

действительно что-то съедает и в этом

ничего страшного нет у нас вот возникает

проблема когда мы летит в систему куча

параллельно тяжелых запросов то есть вот

лимиты

я так понял ставится на одного

пользователя в клика вы можете устремил

на память поставить как параметр

называется общего лимита на память до

для всех запросов и люс начинают протерм

оживать то есть вообще не связаны с

исходным запросам конечно роста потому

что с ресурсов нет обучиться но так было

до вас не очень слышно нужно подойдут

если вы не очень хорошо да

мы правда и не пользуемся не

пользоваться и потому что она не

работать потому что у нас и так всем

файлам разделено как бы магистрали

пролетал ими пользуемся

как леша лишь предстоит могу я повторить

да я не знаю что добавить эта ставьте

очень услышал что-то на то есть есть

несколько параметров которые можно

потянуть потрогай дата приоритета

запросов которые но чтобы понятно если

вы понимаете что вас из тяжелые запросы

вам все равно нужно понимать раньше да

тут вы не должны через одну точку

пускать всех то есть вы понимаете что

вот этой штуки будут пролетать тяжелых

запросы вот вы им прийти и то там

понижаете в их там по лимитам зажимаете

спасибо но даже других вариантов нет

если вас есть запросы которые прилетают

в систему и как бы их никак не

контролирует в любой системе полет на

самом деле другие варианты есть есть

сейчас действительно очень много всяких

настроек можно это ограничить эта

ограничить и и все граничит но

приходится выбирать и ставить кучу этих

мелких настроек но хотелось бы сделать

так чтобы всё работало как бы

автоматически то есть

задать какой-то mare pool на одного

пользователя но другого и чтобы она по

часто выделила память такая татария

такая этого сейчас нет но это у нас

запланировано как один из крупных

пунктов нашего road map а этот рыбные

котлеты можно посмотреть обычно 30 все

либо в пятницу он нигде за посмотреть

нет в декабре этого еще не будет смысле

там будет и хотя бы леди злобе какие ты

не знаю или знают и они пока еще нет

только наполовину царский спасибо да

давайте вы я просто а потом вы а потом

добрый спасибо вопрос чисто риторический

наверно если бы у вас была возможность

искать отмотать время назад и вернуться

к тому стайку технологии на котором мы

были изначально вы бы стали наступать на

те же грабли снова кликал сходить да да

кафка + клик да конечно а что бы вы

могли посоветовать то сказать тем кто

собирается наступить на эти грабли но 1

документацию прочитать вот вторая в

давай под второй понимать что система ну

как бы это такой тоже рид и 1 вопрос

риторический то второе понимать что

система скажем так достаточно уникально

то есть оно не совсем привычно для если

вы переходите на вскоре другой базы

данных у нее свой томас quelle а

по-другому работает у неё там вот это

вот все и нужно понимать что если вы в

этом вляпаетесь к силе то хорошо по

первости точно не будет но как бы без

обид ясна задача серьезная проблема у

вас обязательно будут так что не бойтесь

но да я сейчас так встаешь на комете

очень хорошего можете в него писать и

многие вопросы разбираются то есть даже

если вы задаете дурацкие вопросы кто из

документации вам все равно них ответил

да

здравствуйте спасибо за доклад очень

интересный вопрос такой когда вы

отказывались от первоначальной схемы вот

с вертикаль какими ключевыми

требованиями вы руководствовались что вы

были выбрали именно cliff house там

давние друзья нос до хороший вопрос мы

отказывались не отверстие мы

отказываемся cytus а верх экрана со всем

устраивала кроме одной маленькой штуке

дорого то есть если бы наверное у нас

был бы большой класс траверсе кита мы бы

в хаос может быть даже не зашли бы вот

ну то есть мы думали бы об этом далее бы

начали выдумать особенно пример существу

бесплатный тариф и open source

в первую очередь мы отказывались от

cytus а мы на тот момент уже

рассматривали ряд решений то есть crack

house

первый раз рассматривался еще примерно

раз тот момент когда cytus только

начиналась тоже внедряться и

и вот это только за в конце салли была

статья на хабре wax к хаосу было совсем

ужине то есть он равен вы подсос не буду

там пару недель мы его попробовали он

несколько раз нас упал вот ну реально он

был быстрый вы попробовали сколь а как

люди которые все время были в прогрессе

и вертите как бы потом потом в cytus

тоже вроде как соску или им как бы и к

хаус-музыке нет вот и потом впоследствии

дома стали него заходить мы понимали как

он примерно работает - мы в какой-то

момент моего правого ряда постоянно

смотрели что как как что с ним мы 1

перевели на него наши метрики то есть у

нас как сделал нас есть вот основной

кластер 12 машин видимо там хранятся

данные считаем там все у нас есть сервер

с восьмью

4s гипер трейдингом ядра там чуть-чуть

памяти и мы с той же каски считаем

абсолютно те же данные мы правда пишем

их не все то есть мы более меньше

гораздо данных то есть у нас астана

таблицы вернувшись от чем-то колонок эти

матери зова набивки нет у нас есть

табличка там ну с движком ну то есть мы

просто у него пишем какие-то данные

но я визита в несколько мотивированных

view который делает нам эти

отчеты в реальном времени вот то есть

метрики собирает там этого сервера вот

так хватает то есть реально очень

производительны просто не всегда даже

нужно как большой железо и мы перешли

сначала метрики попробовали вы

посмотрели как это работает вы смотрели

его скорость посмотрели что драйвер

который мы написали тоже в принципе на

тот момент нас устраивает мы посмотрели

что эти данные туда которые у нас были в

тот момент и сейчас они помещаются и вот

и мы их можем записать туда мы их то

думаешь прочитать в этом объеме дай на

этом железе мы понимали что это реально

парк машин нас сильного как бы

уменьшиться он уменьшим количество денег

которые мы тратим и мы выбрали его о нам

как-то был ближе тот момент родне да

прям сроднились с точки зрения затрат и

ресурсов он был оптимальным для выбора

да он был очень оптимально повторюсь да

я там не давал сне не обмен и все такое

у нас тот момент в принципе ситуация

была такая это частности хороший админ

как бы мы разрываем уже как бы и тогда

мы очень легко вошли приказу чем

достаточно просто сделан вот завтра

попытаемся данном этапе об этом

поговорить да что там и репликация это

масштабировать это очень просто на самом

деле как бы просто за счет того что

например с трудом берем чувство стальная

у меня даже нет никаких сыров там

хранить метаданных то еще что то общее

нужна вся машина одинаковые если вам

нужен какой то там масштабировать что-то

еще никакой интеллектуальной нет по

стручками что нужно вписывать это

работать как вам надо этого конструктору

можете снова собрать любую систему вот

например сейчас будем делать из за

выпуск совсем эту штуку мы будем

переводить полоса своей метрики который

бы там пишут influx там еще куда-то

накликал стал более-менее нормальным

интерфейсом чтоб можно было так чтоб

тегировать все остальное делать и это

все будет накликал всем посмотрели да

там метрику нас много и нам нужно

реально будет опять какой сервер возьмет

с 8 ядрами как бы все но хватит там

писали там 300 тысяч метров в секунду но

спасибо


