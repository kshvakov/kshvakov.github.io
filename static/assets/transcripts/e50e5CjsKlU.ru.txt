так действительно у нас не губерн эти

сани докеров продакшене вот но раньше он

был мы не занимались перенаправлю

выпиливанием но получилось то получилось

сейчас у нас из если мы говорим про

эксплуатацию это один админ сегодняшние

сторож инженеры мы находитесь 4 дата

центрах два из них в россии один в

европе в сша и вот в азии мы тоже хотим

вот и чуть больше пятидесяти серверов

железных у нас находится сейчас паркер

купюрница у нас нет совсем

когда-то давно на самом деле у нас кубер

notice был и мы без него живем наверно

года 3 ну может быть чуть меньше да но

он находилась стоит он что-то делал ел

ресурсы иногда он ломался мы не понимали

что там сломалась все мужчине вроде всё

работало вот и починить это было

зачастую какой-то магии админ занимался

у нас было тогда даже два по моему вот и

собственно то что происходило мне очень

нравилось потому что не было никакого

контроля все услаждал с тем что он все

было два дата-центра соответственно это

было несколько кластеров кубер на часу

ну и вот это вот все

хотелось чего не хотелось ничего

отказываться но хотелось больше

стабильности системы

вот и собственно прежде чем решать

проблемы с кубер на эти сам как таковым

мы хотели вообще задаться вопросом а что

мы на самом деле хотим вот наши системы

да я имею ввиду как

инженерная да там сервисы которые

работают он кто программирует с ну и в

общем целиком то есть хотелось

автоматизации диплом ну не то чтобы ее

не было она была но тем не менее

хотелось масштабирование от системы мы

это ринг и отказоустойчивость в принципе

что еще

хотели единый формат пакетов сохранить и

собственно доставки потому что это

важная часть мы диплом сейчас-то и

наверное в день бывает там раскатываем

все 1 по 20 куда нибудь вот хотелось

перси они рование сервис потому что мы

хотим его собрать ровно в таком же

состоянии вот тестировать и потом

выкатить на пробу

вот неизменным его состояние хотелось

изоляции ресурсов потому что на одной

машине может быть более чем один сервис

тут очевидно хотелось безопасность

потому что это важно и хотелось

соответственно производительность

казалось бы все это есть кубер найтись и

но что-то у нас были проблемы с

производительностью ну примет росла

ломался вот и соответственно это

выходило немножко дорого по железу как

нет тогда казалось на тот момент это

было over price вот сейчас это

подтверждается как бы и мы тратим сильно

меньше ресурсов что важно последние года

два все понимают проблему с процессором

всему сталина нужно

где-то долго едет

вот соответственно q вернитесь нас

немножко не устраивал вот все это было

кто

наивно полагать что он бы там спал

совсем еще не нужно было делать

что делать до как искать аналоги это

место смарфон вот это вот все swarm или

писать самим ну как бы аналоги оказались

еще хуже чайку вернетесь вот поэтому и

не такие популярные он все-таки

популярны писать самим это какая-то

утопия как бы и собственно это может

отважится только не знаю

в свободное от работы время потому что

это в принципе никакого толка не имеет

вот

собственно что у нас есть на тот момент

было да у нас были разработчики у нас

были инженеры админы у нас везде linux у

нас тот момент было два дата-центра у

нас был каберне this и сервисы написано

о и руби вот мы пошли немножко с другого

пути мы стали не пытаться

сделать платформу для сервисов да как бы

вот чтоб она могла все что угодно мы

немножко решили дотащить и сами сервиса

то есть чтобы было дотащить до нужного

состояния можно было узнать собственно

эксплуатации чего они хотят как бы от

сервис увидеть потому что в принципе

инженер который занимается эксплуатации

это не разработчики он не знаю что там

находится и в принципе ему и не нужно

знать это зачастую что вообще-то сервис

делает как он живет

слишком лишние потому что сервис у нас

там не знаю что 40 наверно может больше

вот собственно щитах тело эксплуатации

она хотела чтобы сервис представлял

какие-то порты наружу если он работает

темпах ттп этом типе неважно как бы

египет должны быть обязательно порту для

метрик мы храним их параметры вася вот

все конфиги должны быть через перемен

окружения создаваться чтоб не было

каких-то конфигурационных файлов по

возможности ну и собственно как бы

сильно париться об схотел потому что

ну зачем тебе платить кучу разных

сервисов чтоб они еще по-разному

настраивались по-разному

эксплуатировались это будет как бы

сложно дорого и не эффективно

вот что хотела разработка разработка

естественно хотела не зависеть от

эксплуатации что постоянно не находиться

в состоянии заложников и не просить

добавить какой-то сервис там выкатить у

куда-то ну и собственно не выпрашивать

логин мониторинг все остальное то есть

как бы такие обычные бытовые проблемы

которые все-таки у некоторых остаются

проблемами

собственно задач какая была к сервисам

что один сервис должен быть одним бинар

ником ну вот это 100 стандартные метрики

и все остальное так у нас были сервис

еще написано на рубит то один сервис

один бинарник соответственно не подходил

и сервисы которые стали оставались нас

наруби мы их тоже переписали на год чтоб

можно было их собирать и

собственно мы собираем так сейчас не

только сервисы которые просто сервис да

у нас например есть там мы занимались

видео у нас есть плеер то есть это джесс

файлики у нас есть там сайт у нас есть

админка собственно это все мы тоже

пакуем в один бин аль в вместе со

статикой лампах т поет дает то есть у

нас все сервисы одинаковые то есть не

важно что это там например там player

api

либо там dns-сервер как бы это все

одинаковы с точки зрения эксплуатации

там никакой разницы нет и собственно с

точки зрения доставки тоже конец

единый формат метрик тоже все очень

просто мы

метрики понятно не могут быть разные да

там у приложения ну всегда должна быть

как минимум одна которая описывает

приложение то есть эта версия когда он

был собран и собственно название так мы

его всегда видим

так и собственно пришли к тому что у нас

давят как уже сказал что все сервисы

одинаковые они никак не отличаются с

точки зрения эксплуатации поэтому это

все достаточно здорово то есть на выходе

у нас получился один бинарник и как бы

жизнь и жизнь стала с этим легче вот

соответственно плюсы не только да как

вам то что внука почему из докер никто

не запускает то что бинарник ты можешь

тоже запустить руками как бы

не произойдет теперь

нужно ушка с бинардиком то хорошо но

нужно доставить и запустить сервиса для

этого конечно многие

говорят что вот нужен докер потому что

докер это удобно докер это пакует и у

докера ysl адиваси прелести туристам

изоляции ресурсов и прочие штуки но

помимо всего прочего у докера есть

некоторые вверх от вот потому что там но

в строчке мы работаем со стороны

соотносить с кем работаем сеть эту все

google или там проблемы докеров сети в

любом случае вот и нам нужно естественно

проверенное и надежное решение и докер

он себя таким не показывал не то чтобы

не какие-то проблемы с скорее он слишком

большой и не нужно и у него есть именно

проблема производительности которая нам

не нужна а

чтоб что-то доставить надежно и

запустить казалось что все из

операционной системе мы работаем на

линуксе у нас везде ubuntu вот и

собственно как в любом

любой перцовки то есть от меня самый

распространенный пакетный менеджер от

который там существует уже достаточно

давно и систем д который в принципе

общих любое приложение которое есть в

системе запуская то есть внутри едет

системы с как были без него никуда вот

штуки

старые надежные и проверенные собственно

ну и в общем то еще ставить систему не

нужны никакую как бы дополнительный по

не тащим то есть средства у нас меньше

каких-то частей которые могут выйти из

строя это прям профит вот при этом

менеджер это необязательно об может быть

дату и может быть любой вот

внутрь зависимости от вашей операционной

системы то есть если у нас ubuntu стол

столкнуть раскат например да или там еще

что-то вы можете использовать как бы

разница абсолютно никакой нет

единственно что для сборки мы используем

фбн

вот нам лень конечно писать каждый раз

файлик или править их руками для сборки

для пакетов вот поэтому есть прекрасная

штука

по моему этот проект был релизер вот у

него есть она vpn он позволяет очень

просто в яму уфалей описать что вы

хотите видеть

за пакет как бы эоны васаби о том чем

может собирать как раз под любую

операционку то есть там не важно будет

это а пока бойлер pm

систем д в чем его плюсы вот во первых

сервис видно системе и мы это легко

мониторинг то есть мы на машину

закидываем экспортеры и даже если у нас

разработчик вдруг не написал себе

[музыка]

мониторил куда то есть у не добавлен

point или мы его не добавили там вскрыть

для про me to us are not of service

увидим потому что он собирает

стандартные метрики мы подхватился как

бы по названием всех видим в системе ну

и там упал не упал тоже видим там есть

изоляция ресурсов то есть если как бы

что докер нужен для изоляции ресурсов

это не совсем так можно так сказать вот

в систем да точно также прописываются

ограничения там подсыпал памятью и все

что вы хотите то есть там достаточно

гибко сделано

безопасность естественно то есть мы если

сервис например у нас не работает

девайсами какими-то то он до них

достучаться не сможет то есть вы это все

прописывается там же как бы это все

видно в том числе мы используем систем д

для задачи по расписанию то есть если

кто то помнит крон штука есть вот у

нас есть несколько задач которые мы

запускаем редко там на условном к этому

рассудке поэтому нет смысла висеть

сервису все оставшееся время так как бы

вот поэтому также 6 smd мы просто ставим

какую задачу как бы он запускает мы

производительность если у нас ничего нет

то у нас и ломаться нечему и ресурсы

есть тоже не чем потом как бы здесь мы

грубо говоря никакого выхода у нас нет

вот систем д он и так работает и я на

самом деле где-то читал и слышал людей

как раз им там что то делали они тоже

вернее один раз только слышал когда

жалуясь на систем dell людей он ел там

какое-то нереальное количество

не знаю как это сделать вот но в

принципе его практически нет но это

соответственно надежно потому что резки

эта штука не работает то у нас вообще

ничего не работает поэтому

вот все и

того в собственном и все рассказывают

про то что что-то вне да это мы

рассказываем про то что мы как бы и

внедряем вот мы выпилили как получили в

принципе ничего не делая вот абсолютно

еще даже не кого софте поставили у нас

получилось что у нас есть единый формат

пакетов и это как бы всё как бы с

доставкой тоже все ок у нас есть версии

армирование изоляция мы вот это вот все

то есть практически серебряная пуля

однако у нас еще были закрыты вопрос по

автоматизации

вот

обычно ну как обычно сейчас расскажу

наверно такой капитан очевидность

автоматизировать нужно все даже если у

вас есть один сервер вот это можно все

за автоматизировать потому что если он

сгорит потом вы руками еще не сделаете

ну то есть вы не восстановите то что там

было окружении какое там неважно почему

чем занимается вот для автоматизации

естественно мы выбрали ansi был вот он

уже был в тот момент потому как то

выглядел немножко странно вот почему бы

вы выбрали once полного первых бы а что

еще выбирать possible мы пользуемся

верно с самого момента того как был

первый камень это fancy был сделан то

есть там много лет его легко

поддерживать и и желание расширять

плагинами про легко поддерживать как бы

оставлю звездочку потому что все на

самом деле не очень так

если вы запустите ansi был у вас будет

от ну то есть поверьте кого поэтому раз

какое-то время мы возвращаемся к тому

что мы его чистим то есть переписываем

play булки удаляем всякого ненужную

ерунду которая там скопилось ненужные

там сервисы ну и проще вот эту вот

историю

lancia был нас все очень просто то есть

так у нас есть две команды по большому

счету да как бы разработчики и инженеры

которые поддерживают с тем

админы проще говоря вот то собственно

эксплуатации чем занимаются когда у нас

появляется сервер какое-то приходит и

когда к нему подвели сеть вот там

просто , базовую роль до который настоя

танцполу сво подключают добавляют нашей

базе торе и

выключает

root-доступ коллагеном до брата сашки и

на свои роли выключают доступ вообще

всем

вот и ставят для мониторинг и как бы это

not эксперт экспортер кабель из той

лодки для сбора логов собираем вообще

все логе в системе то есть не только наш

сервис вообще все что есть это бывает

очень нужна бывает нужно очень редко вот

но метко потому что вы одномоментно

можете посмотреть что сердцу восходило

системе

для разработчиков ansi был тоже как и

потому что отойди на репозиторий и чтобы

админы постоянно одни зависели от

разработчиков разработчики не зависеть

от админов админу тоже туда комитет вот

соответственно разработчики отвечают

полностью свои сервисы так сервиса

одинаковое все у нас вот твой ролику

сервисов тоже все одинаковые достаточно

в принципе скопипастить

поставить там свои настройки к тебе

нужны как бы и в принципе все ну и

соответственно различные правила

роутинга в джинсах a proxy как бы тоже

отвечает разработчики обмен туда даже не

лезет вот

соответственно разработчика может от

комитета добавить свой сервис собрать

его и сзади плоти админом для этого не

нужен вот поэтому админ у нас стал спать

спокойно хотя бы и не дергаться вот про

масштабирование то есть

это как бы была одной из задач системы

чтоб система масштабировались было

отказоустойчивая и собственно что такое

масштабирование когда отбирать как uber

на тесте потом of the spell все дела как

бы вот у вас там запустилась много там

сервисов как бы у вас пришло нагрузка и

у вас новый нарисовался вот то как бы

создание экземпляров сервиса на 1 ночь я

так как бы вообще не серьезно то есть

никакой не масштабирование и если вам

нужно

чтоб ориентир сервис обрабатывал больше

трафика до то

дайте мне больше трафика и он должен

держать его просто бы то есть не нужно

для этого создавать 2

ну и как бы выделенный балансировщик

тоже . отказа в любом случай у вас есть

где-то в системе условной какой-то

мастер значит у вас есть . отказа вот

такого тоже как бы допускать было нельзя

вот соответственно про масштабированию

решился вопрос достаточно просто ну как

бы как как в старой древние времена то

есть у нас все сервера разделено на

группу это апликэйшен сервера от очень

простые дешевые железяки и мы еще будем

их удешевлять потому что там не циpкa не

помять и тем более дисковая подсистема

никак не тратятся там тратится но не так

уж и много вы как поэтому

приложение нормально работают и как бы

ресурсы едят это сервера час который мы

производим полностью apple-1 потому что

мы занимаемся видео соответственно там

загружают видео и

на сервер отрываем совершенно другие

сетевые карты и tankadere и чтобы

просканировать видео вот и

соответственно там матч сервера из

которых мы раздаём то есть это все

сервера разной конфигурации в потому что

разные задачи раза на эти соответственно

решают все просто в каждой группе больше

чем один сервер вот если один сервер

например не справляется дата как бы

трафик будет еще и на втором

соответственно может доставлять там до

бесконечности если это необходимо такой

необходимости нет как таковой и то есть

только в некоторых группах серверов

например этот же потому что то силен как

бы то есть чем больше трафика тем больше

нам нужно серверов ну и соответственно

транскодирования то же самое докидываем

в группу они забирают свою задачу вот

отказоустойчивость за счет чего

собственно если модем про сервера

который был никита задачу в фоне то

соответственно то очереди вот тут

еще другого нет как бы и но все хорошо

работает вот днях и ттп трафика у нас

как бы такая двойная штука первые торги

nsp dns мы можем загнать человека

плюс-минус куда-то на точку ну например

там пользователи с россии они пойдут в

россии вот и уже на точке в россии

например в москве до 2 датацентра вот

там уже бюджетников на группах серверов

то есть например он пошел по какому-то и

печник у и он попадет там либо 1 либо в

другой дата-центр и соответственно там

он попадет на какой-то сервер вот если

вдруг у нас сервер сгорит вот или чет с

ним случится там bird отключится и

соответственно он из раздачу выпадает

там где-то за полторы секунды что у нас

принципе устрою то же самое как

включается если он там поднялся он

добавляется в роутинг вот

работает это хорошо больше вернемся

проделать dns до г воды у нас тоже свои

dns сервера и мы можем настраивать

достаточно тонко роутинг именно по делу

потому что

вот здесь мы кстати за велосипеде ли мы

написали свой dns сервер вот поэтому

можем там очень тонко настраивать

правило как бы как обрабатывать трафик

то есть ну и

создана за руль ивате и узоров вот это

нам сильно помогает потому что например

нас сейчас еще одна из задач

масштабирование сидена вот у нас есть

крупные клиенты для которых мы можем

оптимизировать свою структуру

инфраструктура вот и dns в этом случае

нам как бы сильно поможет то есть из

коробки такого решения никто не

предоставляет минут себя запилим

плюсы из того что у нас получилось

кстати неправильно таймер смотрел ладно

а плюс решение какие то есть почти

ничего не пришлось делать ну то есть

обычно все что-то не хотят делать потому

что что то нужно делать а мы наоборот

ничего не делали это надежно потому что

мы вместо того чтоб привносить что-то в

систему в нашу до бы наоборот внес

выкинули в принципе мы работаем на том

что дает из коробки операционной

системой больше то ничего не ставим вот

как бы достаточно просто нет никакого

вверх и да потому что

софт работает в окружении вот просто

поставил бёдрами запустил как есть

стальной то есть там уже ничего не

можешь приходить это все отлично

мониторится опять же мониторится не

потому что мы такие умные что-то там

написали сделали а потому что образ

стандартизировали подход там к метриками

к лагам ко всему остальному ну все логе

в одном месте это прям

спасибо локи сейчас потому что мы на

него перешли в какой-то момент на вообще

для фанов кисти и

это прям не стоит сравнивать ситуацию на

рынке условно говоря сейчас и то что

было десять лет назад сейчас

для эксплуатации прям есть все и

бесплатно вот минусы минусов для нас в

принципе нет

они могут бы для кого-то другого но для

нас здесь никаких минусов в том что

получилось нет и нас это все устраивает

и у

нас даже не что родом там через какой-то

мент будем что-то улучшать и улучшать

тоже ничего потому что в принципе ничего

нет мы все выкинули наоборот они

принесли вот

если придумать ну конечно они есть нет

of the sky link котором я говорил в

особенности кубер найти у нас свое

железо то есть мы не можем так хлопнуть

в ладоши у нас там появились какие-то

дополнительные ресурсы но если вы

например живете каком-то claude то там

так сделать можно вот и в принципе

сейчас по моему все

клады представляет предоставляют of the

sky link то есть скважины пришло больше

трафика не где-то запустит урумчи

виртуальную машину как бы когда трафик

упадет то машину можно удалить как бы и

соответственно кабинета в силе

сэкономить по ресурсам ну по деньгам

вот

может сломаться

ну как пакетный менеджер система

иногда бывают репозитории какой-то

существовало теперь он перестал

существовать да или там еще что-то нужно

руками заходить по этому в принципе мы

почти весь софт который у нас

использовать дополнительно этого графа

на лодке

вот эти экспортеры

там victory имея трикси вот эти вот

дополнительные совка того все таки у нас

есть которой пишем ним и мы его точно

также пикируем в пакетах если он даже

без пакетов был и складываем наш

репозитории то есть мы внешней

репозитории там только 2 джинсы

используем и

все

остальное все лежит у нас

[музыка]

еще из минусов да нельзя локально

сделать какой там кампус об и у тебя вся

система такая появилась как бы особенным

новичкам не очень наверное может быть

это удобно вот так сделал действительно

нельзя но это в принципе не нужно никому

не так уж по большому счету во первых у

нас действительно много сервисов но для

того чтобы на 1 работал конкретным там

какой-то сервис , тебе не нужно

поднимать абсолютно все то есть

достаточно что прививала база данных вот

и достаточно того что петя был поднят

один сервис внутри его поделил это за

камень и оно ушло и где-то там на

стоянке собралось она уже в окружении

всех сервисов можно посмотреть то есть

такая проблема как бы не то чтобы

проблемам опять же для нас вот ну и

соответственно из минусов нельзя

загуглить какой-нибудь химичат как бы

закрыть задачи то есть ли она попала

какая-то задача то он действительно

должен пойти что-то сделать да они зайти

настолько фол скопировать как бы сказать

вот смотрите я вам поставил мангу да как

отказоустойчивого вот и потом пришел

кто-нибудь шнур выдрал сервер обратно

ставила на вас больше никто не завелась

вот кстати реальный случай из жизни я

scared назад заводил и шью в по моему

кафку в этот пир в них по умолчанию

не знаю как сейчас конфигов

пути были указаны в tmp вот и у нас был

админы тогда работал в другой компания

вот у нас был обмен он потом уехал

работать фейсбук вот и

через какое-то время бы 100 как он уехал

работать в фейсбук у нас три бутылки

серверы мы узнали что у него все конфиги

были по умолчанию соответственно это все

хранилось тнп

вот я написал чувака

звуки пир они сказали мне не то типа не

проблема потому что весь чтобы поставить

звуки пир человек должен прочитать нашу

инструкцию и книгу

знаете вы не все читают они горят нее не

все нормально вот поэтому да когда

кто-то ставит химичат там тоже может

быть что-то написано не то как бы и

хотелось бы понимание как что человек

все-таки делает так мы такую возможность

человеку больше не даем ничего не делать

вот то в принципе спокойно стала в 7 так

это ты не только вот

плюс и неочевидные на самом деле еще

есть вот эти штуки так как она стала

простой и в принципе надежный то есть за

три года до условно говоря что я скажу

насчет сломается вот по вине

условного там нашего систем да и еще вот

штуки на которые мы условно работаем до

ни разу ничего не упало вот вообще

ничего то есть если мы где-то могли там

задан томится как бы это чисто наши

косяки то есть это чисто вот руками

разработчика либо там ну либо руками

разработчика было что-то каабу сломано

вот и за тепло и ну вот при этом как бы

есть всегда возможность откатиться назад

как бы в принципе обычно ничего не

происходит и самое страшное что может

быть это конечно deploy как всегда там

что-то могут сломать так оно в принципе

не ломается в этом есть минус

расслаблены и админы вот если раньше

например админ был в состоянии этом 24

на 7 вот и каждый alert а их было много

он видел как бы он его там смотрел как

бы его можно было сюда спаситель что-то

тебе отвечал вот

теперь наш админ там как бы машин днем

позвонить далее при этом написать ему

такую не типа отстань как бы я там в

электричке еду на дачу вот едет человек

надо челки как бы

30 мин едет а служба идет вот поэтому

есть некоторая расслабленность и это

иногда не очень хорошо ну как бы все

люди поэтому нормально к этому относятся

вот

штука теперь можно голосовать за доклады

вот так как никто не голосует как обычно

говорят то попросили вставить картинку

вот чтобы было видимо удобнее так по

времени мы примерно норм по этому

вопросу

1 спасибо

в целом звучит интересно классно сказал

про производительность тоже нет никаких

проблем то что мы ничего не запускаем

лишнего поэтому и не донес производителя

и

таким успехом можно просто ничего не

запускать лечение делать это же не будет

проблем с производителя за конечно

так окей вы задавайте свои вопросы на

помните человек без докеры живет поэтому

поосторожней здравствуйте сергей аксель

болт я уже разобрать про панировать на

по каждому пункту но не буду у

меня несколько мелких вопросов тут

наверное разве что не мы не педалируют

забит abs как у вас это происходит это

первый и второе у

скалирование у вас нет окей как сервис

discovery или его тоже нет сервис

discovery как относится к токи равале

купер notice у нас он есть сервис

discovery ну то есть если нам нужно

что-то найти куда то система может

завести вас есть ряд сервисов в котором

нужно действительно общении между собой

вот он кворумы выбирать и все такое но

они общаются между собой

технически это как закипит

нет технически низу кипер у нас есть

ну как бы мы используем библиотеку

как же называлась хэши карпа тоже

гашенную вот для общения между сервисами

это нужно то есть мы напрямую но это

что-то консулу ровд вот это то эта штука

есть в консоли да как вот он с ней

написано просто мы не используем консул

у нас нет мы не храним то где-то

какой-то стоит из состояния если нам

сервис нужно чтобы они между собой

общаются до выбора кворума то они делать

между собой не использую куда третью

систему но ровно так же как например что

сделает там

кафка да если раньше нужен был закипит а

сейчас мне нужен то же самое как бы тот

сам подход и первый вопрос праге tabs а

что вы имеете ввиду под гипсом ну что

гид это источник правда у вас я у нас

этот вид это источник правду ровно так

то есть у нас ничего никуда не может

уехать если ты что-то не заметил как бы

и соответственно

вот то есть эта вся история видно

то есть человек он может конечно

физически зайти на машину что там руками

сделать да как есть такое вот но никто

так не делать но соответственно должен

внести изменения в систему это установка

софта конфигурация софта неважно нашего

не нашего да ты должен что-то откормить

а потом это уедет как бы раз кажется

лыбу кикать идти ой да

спасибо больше

отчет

привет да спасибо за доклад вопрос

живете без каберне tissot в каберне что

хороший есть от scheduler то есть как

сами вы определяете вот какие ноты будут

за что отвечать и нагрузкой вот этой

рулите а

ну у нас на самом деле в этом плане все

будет сильно проще в каком у нас есть

капли cache серверов и декана группа вот

и все остальные как совершенно другие

задачи ским грн про транс caring то там

вообще сервера там с лидерскими картами

например далее там другие процесс стоят

нагретом интеррос с графикой вот в там

еще живет один сервисное он там этот

транс coding живет то же самое сопло 1го

например skype там что-то платить и к

нам например загружаете какое-то видео

либо на самом деле там же два сервиса

либо который может скачивать вот он там

просто вместе парами живут вот с apple

конечно все проще у нас на каждом

упрекаешь сервера запущенную вот эти вот

нормальное количество приложений как и

все то есть нам и ничего не schedule in

в том плане что они не едят только

ресурс у нас то что есть ресурсы то что

когда их сжирает это номер транс coding

она работать все через очереди

соответственно если машина снята сервис

занят да он там например там молотит

видос какие-то то есть я больше не

возьмется ответственности за дачу тут на

другую машину и

она как бы распределяется

прошло спасибо вот еще к предыдущему

просителю в ну как-то ж дополнение

большая как-то дать секретами рулите то

есть вот council of the discovery окей

понятно но вот секретами не до конца

понятным то есть и разработчики там

как-то в этом участвует все но зачем

возжечь волт для ansi было и все если

вам нужно что-то закрыть вы закрываете

единственное что у нас есть это пароли к

базе данных становится больше нет

никаких у нас вещей ну то есть которой

нужно прятать база данных при чем как бы

доступа тоже днем в ней

все эти она не смотрят хорошо спасибо

дастся михаил россельхозбанк смотрите

значит за один сервис один бин аль

реальный респект потому что у нас как

что-то похожее используется и это очень

здорово да значит есть четыре вопросика

первые значит admin 1 на 4 дата центра

это ну нормально он справляется да он

справляется у нас было два один ушел вот

мы искали долго админа вот у нас уже

тогда была в принципе я считаю бурга мы

уже работали до как бабушку берналь тот

момент вот мы наверно почти год искали

админа и практически все и

мы мы их не устраивали в том плане что

пришлось бы работать вот и

ресторане работать не хотели до админ

работать не особо хотели то есть не

хотели запускать какое-то там какой-то

ямал файл дает а вдруг все появилось как

бы да тут они таки не у вас типа нужно

то мы ее тут разбираться и там смотреть

как бы требование такие а еще нужны

дата-центр связистом диск оставить еще

как такая история вот и соответственно

мы искали так не то чтобы нам очень

нужна была но вялотекущее так как в

принципе

админ действительно справляется еще и на

даче ездят как бы вот поэтому

ну

не особо надо второй вопрос вы искали

что хранили метрики в про метался а он

сам про металла сбоку вернетесь развел

там тоже или он как-то standalone они

поверните конечно убер убер про металась

да не конечно стоит просто железяки тоже

у нас сервер который думает о нем

занимают цветан стоит только верните

структуре метрик с графом это мешок это

был мониторинг вас отдельно вынесен то

есть как прямо классно поддельные и вы

нам не нужно класс так как бы у на

вполне хватает одной машины чтобы он

у нас известили говорил все таки

прометею стоит на жесты скалку вернитесь

потом еще раз

по записи не нажата и то же то что то

нет я спросил про про металась в кубер

на эти слова завтра что я сказал к слову

кубер нильса потом культуры то метра

легко пирамида с тем чтобы конец у нас

так вместе все вот так вот упаковка чем

логе собирается локи логе логирование

анлоки а локи

дороге локи понял да он оказалась очень

таким приятным он как-то появился мы его

попробовали и нам прям вообще зашло вот

то есть там достаточно простые правила

для скриптинга и соответственно он

собирает абсолютно все метрики которые

есть системе и потом их видим если нам

это надо надо очень редко на самом деле

вот как бы но когда надо она есть

соответственно мы не храним их там

годами у нас много где маленький ретоне

потому что как бы и скаты у тебя что-то

сломалось ты грубо говоря не причинил

это в течение там или не обнаружил

проблем еще не двух дней значит ты не

проблема как бы ну условно говоря да вот

поэтому не тяни не нужно и 4 вопрос вы

говорили про очереди что за используете

для очередей нас

ну nas-сервер нас тренинг

он очень простой в том плане что как бы

он не совсем очереди он скорее как

средство доставки потому что нет

приоритетов нет ничего то есть это все

остальное это дело наших приложений

основан на принципе это и не нужно то

есть он умеет rome 2 штуки который

настраивает это доставить сообщение

вот и как бы за братка с тебе нужно

publish савской вот эту штуку и она

очень хорошо единственно с ним проблема

мы используем от streaming вот его уже

собираются не поддерживать какого-то

момента

но какие-то проблемы с ним не ощущаем

поэтому стрел сниму с поддержки как бы

одну ничего страшного плюс он написан

ногой в принципе мы можем тоже дайте

дописать счет понадобится вот у него

есть проблемы с производительностью вот

это у него есть

сильно

смотря с чем сравнивать и смотря как

сравнивать вот он работает старый

streaming в лук системах то есть у него

есть vtf файл торрент у тебя работает

один сервер до например группа идти не

важно сколько все серверов там когда у

тя клиентка напиться он просто получает

адрес сервера с которым он будет

работать я работал сюда что-то упало он

поступил подключиться к другому вот но в

этом случае может быть какая стоило тебя

работать сервер 1 и он сгорел на нем

были какие-то данные соответственно в

группе этих данных не появится если мы

его используем в режиме как у нас когда

у тебя на каждом сервере хранится копия

данных условно говоря сейчас горит

какой-то сервер то ничего не произойдет

трагичного вот то в этой штуке да потому

что он должен заниматься консенсус нами

то есть ему нужно

договориться с собой чтобы сообщить

достать связан от очень много ресурсов

тратится

подсыпал вот и тут мы хотим как бы

немножко сделать финт ушами потому что

но так как на самом деле от того что ты

провалена немножко как бы условно говоря

там надуманная то есть он езд ресурсов

но у нас они есть да то есть у нас не

сильно поэтому affected но мы хотим

некоторые вещи которые не критичны

давайте задачи потому что спонсировано

принес гарет кобыз мы их потеряем не

хранить на всех серверах просто прийти

на авто и все все понятно си больших еще

вопрос смотри по куку по центру то бред

и вот по поводу такого scheduling они

scheduling то есть я правильно понимаю

что грубо говоря любой горный экзешник в

транс кадири он все время смотрит какая

нагрузка и цепью если об этом

предположим 95 он просто ну отписывается

по большому счету от очереди к но только

у него нам не совсем так то есть если мы

говорим про in a trance calling the

service зная сколько у него ресурсов

есть которая может сожрать например это

сколько видеокарт ну к примеру в сервере

и сколько на одном от на видеокарте он

может запускать задачу вот как только он

этих задач набрал он просто ничего из

очереди не берет да смотри приехала

новое сервака в нем 40 видеокарт да и то

есть как бы получается конфигурационные

параметры все-таки разные то есть это не

вшиты в bino и а нет конечно мы это все

задаем ну во-первых некоторые можно

узнать даже не зашиваю какую

конфигурацию потому что сервис когда

поднимается множество спросить сколько у

тебя видеокарт и собственно понять вот

лимиты ну там они эмпирическим путем

были подобраны как бы поэтому и дальше

так и подбираются фишка же в том что

например

почему я говорю что как бы давно

проблемы существуют

микрочипами дарств года 2 уже точно

как-то все весь рынок штормит ну и как

бы и новые карты проявляя соответственно

нас есть там сервера в которой

видеокарты были куплены там условно там

пять лет назад вплоть до вот которые там

условно были вчера куплены это могут

быть разные карты и у них разная

производительность плюс это могут быть

не видеокарт это могут быть например

цепью windows key которые тоже кого

могут

с ускорением работать с аппаратным для

транс календарь вот у них совершенно

по-другому это также работают то есть

там другие лимиты ну и другое все

почему то есть некий магический

коэффициент до получать эти пять его

pride вычисляешь и как бы не слышно от

очереди если ничего нет да ты посмотрел

как бы это работает если там еще ресурсы

остается можем добавить с клиентом можно

убрать наверно примерно так и работает

один раз подобрали как бы она дальше по

штука какая реальная утилизация то есть

все равно наверное какая-то дырка

остается сколько на 80 процентов или

сколько ни если он transparent вскоре

всегда сотку неплохо не там просто фишка

так что как бы там по-другому нельзя там

нет 80 процентов умный а навалил как бы

тут он уже и и работают там единственное

что

раскодирование видео тебя есть два

процесса один декодирования другой как

бы конинк никулин группой вот декоре

дешево как бы да то есть там тебя

загрузка может быть там от несколько

процентов там дословно там не зная

максимально четко бывает ночью редко на

самом деле вот если мы берем 36 и 6 4

кодах постой да как бы он копится carbon

там практически decoding не трать но

самым корень как будто будет сотку

спасибо

привет red инфосистемы джет

вопрос такой по поводу того как например

у нас возникает ситуация

связанная с отказоустойчивостью и у нас

что-то падает на сколько быстро это

можно пережить вернуть какой-то сервис

например падает

в общем он упал должен но у сервиса

много причин например

ресурсов не хватило там нас взломали там

все что угодно может быть там пожарного

дни вот с пожаром соглашусь если сервис

по непонятным причинам падает значит его

нужно править как бы могут быть там

причины у нас либо что-то сгорело либо у

нас что то не так железякой например у

нас стучит память это такая ну либо с

материнской платой у нас

такие проблемы бывают либо там с диском

что случилось как бы с у тебя сервер

стучал грубо когда он не может работать

по какой-то причине он lip ну условно

назовем сгорел вот то

когда приедет новый мы его накатим то

есть вот сервера если у нас уже вот она

туда сеть то накатить туда занимают но

секунд 15

ну то есть накатка операционную систему

и приносит после когда операционную

систему сеть уже есть как бы дату там

быстро достаточно

но операционных систем чем накатывается

админом накатывается но я имею тут там к

ним и не боимся но я там или еще у нас

нет у нас нет да у нас нет автоматизации

накатывание операционная система потому

что это не самое частое задачи как бы

ринатом решается и иногда да вот 2 2

штуки которые не автоматизированы эта

сеть потому что нужно физически прийти в

этот центр поставить сервер как бы и

воткнуть его вот и стресс накатали

операционная система у нас нет паркинг

потому вводим то не знаю 100 машин в

день до поэтому у нас

админ должную камень поставь

ну хорошо немного можно переформулирую

вопрос пришел там админ да на работу и

решил ручками пояса что-то поправить аня

и выяснилось что что-то не то он

поправил и при раскатке новой версии

что-то сломалось как быстро можно будет

это исправить

ну во первых у нас нет такой практики

чтобы эти руками кто-то что-то поправить

вот а если нам нужно откатиться он также

мгновенно откатались потому что все же

пакеты которые системе существует у нас

какая фишка я такого кого-то видел что

например когда мы сделаем круто сборку

приложения

делается например сборка в какой-то

версии а потом когда под каким оно

катится под coin там условного мастера

куда потом порежу эту ветку вот чё там

кататься на простом случае не понятно в

наш 100 че как вы например можем тогда

все что угодно причем это мастер не

мастер ветки там то есть какой-то branch

до моего то героем вот и он собственно и

там написано stretching мы его

посмотрели всякий собственно ровно тот

же бинарник да он там лежит

в репозитории вот он уедет она

production если нам нужно его откатить

мы просто меняем версию и он делает

даунгрейд

с базой данных то же самое есть там

миграции который наказывает и вперед

есть которая в какой-то назад ну окей

немного может быть еще переформулирую

вопрос да пришел какой-то зловред не в

операционную систему внес какое-то

изменение

при перекатки этого не будет заметно и

на самом деле достаточно часто кейс при

атаке какие-то закладки

оставляют их даже незаметны ну да

возможно такое ну то есть я имею что

такая ситуация в пользу возможно что у

вас хакнули что-то вам сломали вот ну я

имею ввиду

в этом плане был бы было бы удобно

автоматизировать именно перед

разворачивания полная например

операционной системой совсем со всеми

приложениями носа до кого наверное чем

он намекает есть например атомарной

операционной системы типа fedora core

курили и смотрели в их стороны не не

смотрели

мы на посмотрим часто сонгюль сторону

debian о том что там еще меньше всего

чем вы будете вот там она операционных

систем то особо не нужно было запустить

наш binary

спасибо ну то есть если говорить да вот

именно

потом о том что вы говорите ну как у нас

нет острой необходимости то сейчас я на

данный момент не вижу

сожаление есть но наверное

метро до всем нужно так сказать

звучит слегка угрожающе как будто вы

что-то знаете дома бы когда мне

показывать листок пока мы тут выступает

необходимость появилась просто он еще об

этом не знает

окей так вопросов больше нету так так

пожалуйста не очень долго и ты не очень

долго отвечала и время еще есть в один

следующий доклад за ума профилак а потом

туда видео я надеюсь ни у кого и он

последний вопрос если возможно я за

право вот прям в уголке

история вот про резервирования которую

вы рассказывали с ги один из ее бы

терпение кастом она

правильное хорошая вопрос в том как в

текущей вашей архитектуре вы

резервируйте уровень приложения то есть

то что происходит со не кастом понятном

и

публично с при земля им трафик по

кратчайшему маршруту все это проходит

через бордо роутер и вот она оказалась

наконец-то в нашем дата-центре и когда в

текущей архитектуре есть какие-то

проблемы с applications уровнем вот где

именно там резервирования для нас просто

больше чем один сервер если больше чем

один больше не работает то есть мы

приземлили в дата-центр трафик unicast и

вот там она сломалась что происходит

дальше

если не работает дата центра или

приложений если сервер отключился по

какой-то причине как бы там отключился

бёрд как будем финансирует его больше

нет почти нет они есть у вас есть что то

что выполнять или мышки на то где стоит

бёртон как бы занимается би джи пи но за

ним есть еще какой-то applications луне

у нас на каждом сервере просто стоит

бёрд который должен включить или

выключить вот в трестом себя там

анонсируют как бы когда он выпадает то

трафика на него просто не идет то есть у

вас на каждом из applications and

соответственно birds сколько бы их ни

было и все это она носит

понятно спасибо ну их не так уж и много

то есть у нас в москве сейчас три

наверное стоит и

давайте попробуем реально короткие

вопросы короткий ответ на это на самом

деле даже не вопрос я просто хотел

сказать спасибо за доклад очень крутой

если что-то меня раздражают нашу

industry так это количество овир

инжиниринга карга культе зма и fanboys

то вот это очень свежий на мой взгляд

доплатой этого очень не хватает спасибо

все новое это хорошо забытое старое

ждать

нам да я тут как бы немножко а правда в

том числе там просить по все остальное

нам просто

как почему нам это удобно да у нас есть

админ который действительно админ вот

который может он съездить диск поменять

там или еще что сделать с ручками в том

плане вот у нас есть очень хороший

сетевой инженер вот у нас есть сторож

инженер поэтому нас разработчики очень

грамотно и поэтому как бы с этим список

спокойно потом нормально мне кажется ты

вызываешь негатив людей тем что вы

живете без decker вас все хорошо

но я-то я убежден в том что из докер а

можно хорошо жить так как бы наверное я

просто я слушал исполнен как человек

когда было открытие я там сидел и прям

там на нашей машине на которые сирены

билде докер образы вычищал crash докер

образов муж то место на сервер кончилось

просто вот и этой проблемы бы не было бы

если мне было бы докеры я на тебя смотрю

и думаю блин а может я зря страдаю я все

же убежден что не зря и просто ты

чего-то не знаешь скоро ты поймешь что

надо было все-таки закирова работать

такие спасибо тебе большое спасибо

большое за вопрос и


